<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Monday, Apr 18</title>

<script src="site_libs/header-attrs-2.13/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics 436/516</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="lectures.html">Lectures</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Monday, Apr 18</h1>

</div>


<p>You can also download a <a href="lecture-04-18-2022.pdf">PDF</a> copy
of this lecture.</p>
<div id="sequential-and-binary-regression-models"
class="section level2">
<h2>Sequential and Binary Regression Models</h2>
<p>A sequential regression model can sometimes be estimated using
several binary regression models.</p>
<p><strong>Example</strong>: Consider again the <code>pneumo</code>
data.</p>
<pre class="r"><code>library(VGAM)
pneumo</code></pre>
<pre><code>  exposure.time normal mild severe
1           5.8     98    0      0
2          15.0     51    2      1
3          21.5     34    6      3
4          27.5     35    5      8
5          33.5     32   10      9
6          39.5     23    7      8
7          46.0     12    6     10
8          51.5      4    2      5</code></pre>
<pre class="r"><code># sequential regression model
m &lt;- vglm(cbind(normal, mild, severe) ~ exposure.time, 
  family = cratio(link = &quot;logitlink&quot;), data = pneumo)
summary(m)</code></pre>
<pre><code>
Call:
vglm(formula = cbind(normal, mild, severe) ~ exposure.time, family = cratio(link = &quot;logitlink&quot;), 
    data = pneumo)

Coefficients: 
                Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept):1    -3.9664     0.4189   -9.47  &lt; 2e-16 ***
(Intercept):2    -1.1133     0.7664   -1.45    0.146    
exposure.time:1   0.0963     0.0124    7.79  6.9e-15 ***
exposure.time:2   0.0355     0.0206    1.72    0.085 .  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Names of linear predictors: logitlink(P[Y&gt;1|Y&gt;=1]), logitlink(P[Y&gt;2|Y&gt;=2])

Residual deviance: 13.29 on 12 degrees of freedom

Log-likelihood: -29.22 on 12 degrees of freedom

Number of Fisher scoring iterations: 6 

Warning: Hauck-Donner effect detected in the following estimate(s):
&#39;(Intercept):1&#39;</code></pre>
<p>This model can be estimated using <em>two</em> logistic regression
models. The first is a model for whether a miner will develop
pneumoconiosis (i.e., mild or severe). This logistic regression model
can be estimated as follows.</p>
<pre class="r"><code>m1 &lt;- glm(cbind(mild + severe, normal) ~ exposure.time, family = binomial, data = pneumo)
summary(m1)$coefficients</code></pre>
<pre><code>              Estimate Std. Error z value  Pr(&gt;|z|)
(Intercept)   -3.96635    0.41893  -9.468 2.857e-21
exposure.time  0.09627    0.01236   7.786 6.898e-15</code></pre>
<p>Next we have the model for whether a miner with pneumoconiosis will
develop severe pneumoconiosis (rather than mild). The logistic
regression model for this probability can be estimated by effectively
ignoring any observations where pneumoconiosis did not progress to mild
or severe (i.e., exclude cases where it was normal).</p>
<pre class="r"><code>m2 &lt;- glm(cbind(severe, mild) ~ exposure.time, family = binomial, data = pneumo)
summary(m2)$coefficients</code></pre>
<pre><code>              Estimate Std. Error z value Pr(&gt;|z|)
(Intercept)   -1.11342     0.8625  -1.291   0.1967
exposure.time  0.03547     0.0235   1.509   0.1312</code></pre>
<p>We <em>cannot</em> estimate a sequential regression model with
separate binary models if we want to constrain some parameters to be
equal across the “steps” of the model (e.g., if we wanted to assume that
the odds ratio for the effect of exposure was the same at each step as
done below using the <code>parallel = TRUE</code> option.</p>
<pre class="r"><code>m &lt;- vglm(cbind(normal, mild, severe) ~ exposure.time, 
  family = cratio(link = &quot;logitlink&quot;, parallel = TRUE), data = pneumo)
summary(m)</code></pre>
<pre><code>
Call:
vglm(formula = cbind(normal, mild, severe) ~ exposure.time, family = cratio(link = &quot;logitlink&quot;, 
    parallel = TRUE), data = pneumo)

Coefficients: 
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept):1  -3.6077     0.3542  -10.19  &lt; 2e-16 ***
(Intercept):2  -2.8605     0.4426   -6.46  1.0e-10 ***
exposure.time   0.0849     0.0104    8.13  4.2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Names of linear predictors: logitlink(P[Y&gt;1|Y&gt;=1]), logitlink(P[Y&gt;2|Y&gt;=2])

Residual deviance: 18.3 on 13 degrees of freedom

Log-likelihood: -31.73 on 13 degrees of freedom

Number of Fisher scoring iterations: 5 

Warning: Hauck-Donner effect detected in the following estimate(s):
&#39;(Intercept):1&#39;</code></pre>
</div>
<div id="proportional-odds-models" class="section level2">
<h2>Proportional Odds Models</h2>
<p>The logistic regression model for a binary response <span
class="math inline">\(Y_i = 0,1\)</span> can be written as <span
class="math display">\[
\log\left[\frac{P(Y_i=1)}{1-P(Y_i=1)}\right] =
\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}.
\]</span> This can also be written as <span class="math display">\[
\log\left[\frac{P(Y_i&gt;0)}{1-P(Y_i&gt;0)}\right] =
\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}.
\]</span></p>
<p>Now let the response variable <span class="math inline">\(Y_i = 1, 2,
\dots, R\)</span> denote <span class="math inline">\(R\)</span> ordered
response categories where order is implied by <span
class="math inline">\(Y_i\)</span>. A <em>proportional odds model</em>
is a logistic regression model for each of the <span
class="math inline">\(R-1\)</span> possible “dichotomizations” of the
categories such that <span class="math display">\[
\log\left[\frac{P(Y_i&gt;y)}{1-P(Y_i&gt;y)}\right] =
\beta_0^{(y)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}
\]</span> for <span class="math inline">\(y = 1, 2, \dots, R-1\)</span>.
This defines a <em>system</em> of equations for each possible dichotomy.
For example, suppose <span class="math inline">\(R=4\)</span> and so
<span class="math inline">\(Y_i = 1, 2, 3, 4\)</span>. The model is then
written as <span class="math display">\[\begin{align*}
\log\left[\frac{P(Y_i &gt; 1)}{1-P(Y_i &gt; 1)}\right] &amp; =
\beta_0^{(1)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}, \\
\log\left[\frac{P(Y_i &gt; 2)}{1-P(Y_i &gt; 2)}\right] &amp; =
\beta_0^{(2)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}, \\
\log\left[\frac{P(Y_i &gt; 3)}{1-P(Y_i &gt; 3)}\right] &amp; =
\beta_0^{(3)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}.
\end{align*}\]</span> The odds are proportional because (omitting the
<span class="math inline">\(i\)</span> subscript for simplicity) <span
class="math display">\[
    \frac{P(Y&gt;y)}{1-P(Y&gt;y)} =
    e^{\beta_0^{(y)}}e^{\beta_1 x_{1}} \cdots e^{\beta_k x_{k}},
\]</span> and so the odds ratio when we compare the odds at <span
class="math inline">\(x_1 = x_a\)</span> to <span
class="math inline">\(x_1 = x_b\)</span>, <span class="math display">\[
  \frac{e^{\beta_0^{(y)}}e^{\beta_1 x_{a}} \cdots e^{\beta_k
x_{k}}}{e^{\beta_0^{(y)}}e^{\beta_1 x_{b}} \cdots e^{\beta_k x_{k}}} =
e^{\beta_1}
\]</span> <em>does not depend on</em> <span
class="math inline">\(y\)</span> (i.e., it does not depend how we
dichotomize <span class="math inline">\(Y\)</span>).</p>
<p>The system of equations allows us to express the probability of each
response category as a function of the explanatory variables and
parameters. From <span class="math display">\[
\log\left[\frac{P(Y_i&gt;y)}{1-P(Y_i&gt;y)}\right] =
\beta_0^{(y)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}
\]</span> we get <span class="math display">\[
    P(Y_i &gt; y) = \frac{\exp(\beta_0^{(y)} + \beta_1 x_{i1} + \cdots +
\beta_k x_{ik})}{1 + \exp(\beta_0^{(y)} + \beta_1 x_{i1} + \cdots +
\beta_k x_{ik})},
\]</span> and then <span class="math display">\[
    P(Y_i = y) = P(Y_i &gt; y-1) - P(Y_i &gt; y),
\]</span> where <span class="math inline">\(P(Y_i &gt; 0) = 1\)</span>
and <span class="math inline">\(P(Y_i &gt; R) = 0\)</span> by
definition.</p>
<p>The distribution of a categorical response variable is assumed to be
a <em>multinomial distribution</em>. The binomial distribution is a
special case for when there are only <span
class="math inline">\(R=2\)</span> categories.</p>
<p><strong>Example</strong>: Recall the <code>bliss</code> data that we
used to demonstrate logistic regression.</p>
<pre class="r"><code>library(trtools) # for bliss data
library(ggrepel) # for geom_repel_label

bliss$proportion &lt;- paste(bliss$dead, &quot;/&quot;, bliss$exposed, sep = &quot;&quot;)
bliss$alive &lt;- bliss$exposed - bliss$dead
bliss</code></pre>
<pre><code>   concentration dead exposed proportion alive
1          49.06    2      29       2/29    27
2          49.06    4      30       4/30    26
3          52.99    7      30       7/30    23
4          52.99    6      30       6/30    24
5          56.91    9      28       9/28    19
6          56.91    9      34       9/34    25
7          60.84   14      27      14/27    13
8          60.84   14      29      14/29    15
9          64.76   23      30      23/30     7
10         64.76   29      33      29/33     4
11         68.69   29      31      29/31     2
12         68.69   24      28      24/28     4
13         72.61   29      30      29/30     1
14         72.61   32      32      32/32     0
15         76.54   29      29      29/29     0
16         76.54   31      31      31/31     0</code></pre>
<pre class="r"><code>p &lt;- ggplot(bliss, aes(x = concentration, y = dead/exposed)) +
  geom_point() + ylim(0, 1) + theme_minimal() + 
  geom_label_repel(aes(label = proportion), box.padding = 0.75) + 
  labs(x = &quot;Concentration of Carbon Disulphide (mg/liter)&quot;,
    y = &quot;Proportion of Beetles Dying&quot;)
plot(p)</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-6-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>m &lt;- glm(cbind(dead, alive) ~ concentration, family = binomial, data = bliss)
summary(m)$coefficients</code></pre>
<pre><code>              Estimate Std. Error z value  Pr(&gt;|z|)
(Intercept)   -14.8084    1.28976  -11.48 1.633e-30
concentration   0.2492    0.02138   11.65 2.250e-31</code></pre>
<p>The <code>vglm</code> function from the <strong>VGAM</strong> package
can be used to estimate a proportional odds model, but logistic
regression is a special case when there are only <span
class="math inline">\(R=2\)</span> response categories.</p>
<pre class="r"><code>library(VGAM) # for the vglm function and others
m &lt;- vglm(cbind(alive, dead) ~ concentration, family = propodds, data = bliss)
cbind(coef(m), confint(m))</code></pre>
<pre><code>                          2.5 %   97.5 %
(Intercept)   -14.8084 -17.3363 -12.2806
concentration   0.2492   0.2073   0.2911</code></pre>
<p>But note that we specify the <em>order</em> of the response
categories in <code>cbind</code> from left to right when using
<code>vglm</code>, which is opposite of how it is done when using
<code>glm</code>.</p>
<p>Here we can plot the probabilities of the two categories as a
function of concentration.</p>
<pre class="r"><code>d &lt;- data.frame(concentration = seq(49, 77, length = 100))
d &lt;- cbind(d, predict(m, newdata = d, type = &quot;response&quot;))
head(d)</code></pre>
<pre><code>  concentration  alive    dead
1         49.00 0.9308 0.06920
2         49.28 0.9261 0.07388
3         49.57 0.9212 0.07884
4         49.85 0.9159 0.08412
5         50.13 0.9103 0.08971
6         50.41 0.9044 0.09563</code></pre>
<pre class="r"><code>library(tidyr)
d &lt;- d %&gt;% pivot_longer(cols = c(dead,alive), 
  names_to = &quot;state&quot;, values_to = &quot;probability&quot;)
head(d)</code></pre>
<pre><code># A tibble: 6 x 3
  concentration state probability
          &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;
1          49   dead       0.0692
2          49   alive      0.931 
3          49.3 dead       0.0739
4          49.3 alive      0.926 
5          49.6 dead       0.0788
6          49.6 alive      0.921 </code></pre>
<pre class="r"><code>p &lt;- ggplot(d, aes(x = concentration, y = probability)) + 
  geom_line(aes(color = state)) + 
  ylim(0, 1) + theme_minimal() + theme(legend.position = c(0.1, 0.6)) + 
  labs(x = &quot;Concentration of Carbon Disulphide (mg/liter)&quot;, 
    y = &quot;Probability&quot;, color = &quot;State&quot;)
plot(p)</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-8-1.png" width="100%" style="display: block; margin: auto;" />
<strong>Example</strong>: Consider again the <code>pneumo</code> data
frame included with the <strong>VGAM</strong> package.</p>
<pre class="r"><code>print(pneumo)</code></pre>
<pre><code>  exposure.time normal mild severe
1           5.8     98    0      0
2          15.0     51    2      1
3          21.5     34    6      3
4          27.5     35    5      8
5          33.5     32   10      9
6          39.5     23    7      8
7          46.0     12    6     10
8          51.5      4    2      5</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" />
We can estimate a proportional odds model for these data as follows.</p>
<pre class="r"><code>m &lt;- vglm(cbind(normal, mild, severe) ~ exposure.time, family = propodds, data = pneumo)
summary(m)</code></pre>
<pre><code>
Call:
vglm(formula = cbind(normal, mild, severe) ~ exposure.time, family = propodds, 
    data = pneumo)

Coefficients: 
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept):1 -3.95572    0.26269   -15.1   &lt;2e-16 ***
(Intercept):2 -4.86892    0.29628   -16.4   &lt;2e-16 ***
exposure.time  0.09590    0.00749    12.8   &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Names of linear predictors: logitlink(P[Y&gt;=2]), logitlink(P[Y&gt;=3])

Residual deviance: 13.4 on 13 degrees of freedom

Log-likelihood: -29.28 on 13 degrees of freedom

Number of Fisher scoring iterations: 18 

Warning: Hauck-Donner effect detected in the following estimate(s):
&#39;(Intercept):2&#39;


Exponentiated coefficients:
exposure.time 
        1.101 </code></pre>
<p>That “exponentiated coefficient” is the odds ratio for the effect of
exposure time. We can also get that with a confidence interval as
follows.</p>
<pre class="r"><code>exp(cbind(coef(m), confint(m)))</code></pre>
<pre><code>                          2.5 %  97.5 %
(Intercept):1 0.019145 0.011441 0.03204
(Intercept):2 0.007682 0.004298 0.01373
exposure.time 1.100650 1.084618 1.11692</code></pre>
<pre class="r"><code>d &lt;- data.frame(exposure.time = seq(5, 52, length = 100))
d &lt;- cbind(d, predict(m, newdata = d, type = &quot;response&quot;))
head(d)</code></pre>
<pre><code>  exposure.time normal    mild  severe
1         5.000 0.9700 0.01774 0.01226
2         5.475 0.9686 0.01853 0.01282
3         5.949 0.9672 0.01935 0.01341
4         6.424 0.9658 0.02021 0.01402
5         6.899 0.9642 0.02111 0.01467
6         7.374 0.9626 0.02204 0.01534</code></pre>
<pre class="r"><code>library(tidyr)
d &lt;- d %&gt;% pivot_longer(cols = c(normal, mild, severe), 
  names_to = &quot;condition&quot;, values_to = &quot;probability&quot;)
head(d)</code></pre>
<pre><code># A tibble: 6 x 3
  exposure.time condition probability
          &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;
1          5    normal         0.970 
2          5    mild           0.0177
3          5    severe         0.0123
4          5.47 normal         0.969 
5          5.47 mild           0.0185
6          5.47 severe         0.0128</code></pre>
<p>And then we can plot as usual. Here I have specified an order of the
categories so that the colors are consistent with the plot of the raw
data.</p>
<pre class="r"><code>d$condition &lt;- factor(d$condition, levels = c(&quot;severe&quot;,&quot;mild&quot;,&quot;normal&quot;))
p &lt;- ggplot(d, aes(x = exposure.time, y = probability)) + 
  geom_line(aes(color = condition)) + 
  ylim(0, 1) + theme_minimal() + theme(legend.position = c(0.1, 0.6)) + 
  labs(x = &quot;Exposure (years)&quot;, y = &quot;Probability&quot;, color = &quot;Condition&quot;)
plot(p)</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-14-1.png" width="100%" style="display: block; margin: auto;" />
<img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-15-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Another way to view the model is through <em>cumulative</em>
probabilities that reflect the dichotomization.</p>
<pre class="r"><code>d &lt;- data.frame(exposure.time = seq(5, 52, length = 100))
d &lt;- cbind(d, predict(m, newdata = d, type = &quot;response&quot;))

p &lt;- ggplot(d, aes(x = exposure.time, y = mild + severe)) + 
  geom_line() + ylim(0,1) + theme_minimal() + 
  labs(x = &quot;Exposure (years)&quot;, y = &quot;Probability&quot;)
p1 &lt;- p + ggtitle(&quot;Probability of Mild or Severe&quot;)

p &lt;- ggplot(d, aes(x = exposure.time, y = severe)) + 
  geom_line() + ylim(0,1) + theme_minimal() + 
  labs(x = &quot;Exposure (years)&quot;, y = &quot;Probability&quot;)
p2 &lt;- p + ggtitle(&quot;Probability of Severe&quot;)

cowplot::plot_grid(p1, p2)</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-16-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Data that are not in aggregated form require a slightly different
approach to enforce the ordering of the response categories.</p>
<p><strong>Example</strong>: Consider the data frame
<code>impairment</code> from the <strong>trtools</strong> package.</p>
<pre class="r"><code>library(trtools)
head(impairment,3)</code></pre>
<pre><code>  impairment  ses events
1       none high      1
2       none high      9
3       none high      4</code></pre>
<pre class="r"><code>summary(impairment)</code></pre>
<pre><code>    impairment   ses         events    
 impaired: 9   high:22   Min.   :0.00  
 mild    :12   low :18   1st Qu.:2.00  
 moderate: 7             Median :4.00  
 none    :12             Mean   :4.28  
                         3rd Qu.:6.25  
                         Max.   :9.00  </code></pre>
<p>The ordering of the levels is not consistent with the ordering of
impairment.</p>
<pre class="r"><code>levels(impairment$impairment)</code></pre>
<pre><code>[1] &quot;impaired&quot; &quot;mild&quot;     &quot;moderate&quot; &quot;none&quot;    </code></pre>
<p>But the ordering can be changed using <code>factor</code>.</p>
<pre class="r"><code>impairment$impairment &lt;- factor(impairment$impairment,
  levels = c(&quot;none&quot;,&quot;mild&quot;,&quot;moderate&quot;,&quot;impaired&quot;), ordered = TRUE)
levels(impairment$impairment)</code></pre>
<pre><code>[1] &quot;none&quot;     &quot;mild&quot;     &quot;moderate&quot; &quot;impaired&quot;</code></pre>
<p>Now we can estimate a proportional odds model.</p>
<pre class="r"><code>m &lt;- vglm(impairment ~ ses + events, family = propodds, data = impairment)
cbind(coef(m), confint(m))</code></pre>
<pre><code>                        2.5 %  97.5 %
(Intercept):1 -0.8290 -1.7234  0.0654
(Intercept):2 -2.3237 -3.2651 -1.3823
(Intercept):3 -3.3202 -4.4298 -2.2106
seslow         1.1113  0.4004  1.8223
events         0.3187  0.1808  0.4567</code></pre>
<p>Applying the exponential function provides odds ratios.</p>
<pre class="r"><code>exp(cbind(coef(m), confint(m)))</code></pre>
<pre><code>                        2.5 % 97.5 %
(Intercept):1 0.43648 0.17846 1.0676
(Intercept):2 0.09791 0.03819 0.2510
(Intercept):3 0.03614 0.01192 0.1096
seslow        3.03846 1.49243 6.1860
events        1.37540 1.19816 1.5788</code></pre>
<p>We can plot the estimated probabilities as we did in the previous
example.</p>
<pre class="r"><code>d &lt;- expand.grid(ses = c(&quot;low&quot;,&quot;high&quot;), events = seq(0, 9, length = 100))
d &lt;- cbind(d, predict(m, newdata = d, type = &quot;response&quot;))
head(d)</code></pre>
<pre><code>   ses  events   none   mild moderate impaired
1  low 0.00000 0.4299 0.3408  0.13033  0.09896
2 high 0.00000 0.6961 0.2147  0.05430  0.03488
3  low 0.09091 0.4228 0.3428  0.13288  0.10157
4 high 0.09091 0.6900 0.2185  0.05569  0.03587
5  low 0.18182 0.4157 0.3446  0.13545  0.10424
6 high 0.18182 0.6837 0.2223  0.05711  0.03689</code></pre>
<pre class="r"><code>library(tidyr)
d &lt;- d %&gt;% pivot_longer(cols = c(none, mild, moderate, impaired),
  names_to = &quot;impairment&quot;, values_to = &quot;probability&quot;)
head(d)</code></pre>
<pre><code># A tibble: 6 x 4
  ses   events impairment probability
  &lt;fct&gt;  &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;
1 low        0 none            0.430 
2 low        0 mild            0.341 
3 low        0 moderate        0.130 
4 low        0 impaired        0.0990
5 high       0 none            0.696 
6 high       0 mild            0.215 </code></pre>
<p>For our plot it would be nice to have the levels of impairment
ordered. We can do this by (re)creating the factor and putting the
levels in the desired order. Note that <code>ordered = TRUE</code> isn’t
necessary here.</p>
<pre class="r"><code>d$impairment &lt;- factor(d$impairment,
  levels = c(&quot;none&quot;,&quot;mild&quot;,&quot;moderate&quot;,&quot;impaired&quot;))
p &lt;- ggplot(d, aes(x = events, y = probability, color = impairment)) + 
  geom_line() + ylim(0,1) + theme_minimal() + facet_wrap(~ ses) + 
  labs(x = &quot;Events&quot;, y = &quot;Probability&quot;, color = &quot;Impairment&quot;)
plot(p)</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-23-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-interval-censored-latent-variable-derivation"
class="section level2">
<h2>The Interval-Censored Latent Variable Derivation</h2>
<p>Assume a linear model for a <em>latent</em> (i.e., unobserved)
response variable <span class="math inline">\(Z_i\)</span> such that
<span class="math display">\[
    Z_i = \beta_0 + \beta_1 x_{i1} + \dots + \beta_k x_{ik} +
\epsilon_i,
\]</span> and assume that <span class="math inline">\(Y_i\)</span>
arises from interval-censoring of <span
class="math inline">\(Z_i\)</span>. For example, with <span
class="math inline">\(R\)</span> = 4 intervals we would have <span
class="math display">\[
    Y_i =
    \begin{cases}
        1, &amp; \text{if $Z_i \le \delta_{1}$}, \\
        2, &amp; \text{if $\delta_{1} &lt; Z_i \le \delta_{2}$}, \\
        3, &amp; \text{if $\delta_{2} &lt; Z_i \le \delta_{3}$}, \\
        4, &amp; \text{if $\delta_{3} &lt; Z_i$},
    \end{cases}
\]</span> where <span class="math inline">\(\delta_1 &lt; \delta_2 &lt;
\delta_3\)</span>.</p>
<p>If the distribution of <span class="math inline">\(Z_i\)</span> is
<em>logistic</em> then the model for <span
class="math inline">\(Y_i\)</span> is a proportional odds model. Other
models can be derived by assuming different distributions of <span
class="math inline">\(Z_i\)</span>. However if the “thresholds” (i.e,
<span class="math inline">\(\delta_1, \delta_2, \dots,
\delta_{R-1}\)</span>) are unknown, then the origin and scale of <span
class="math inline">\(Z_i\)</span> are not uniquely defined. This can be
resolved by setting <span class="math inline">\(\beta_0\)</span> = 0 and
the variance/scale parameter of <span
class="math inline">\(\epsilon_i\)</span> to one.</p>
<p><strong>Example</strong>: We can see the connection between
interval-censoring and a proportional odds model using simulated
data.</p>
<pre class="r"><code># create some data
set.seed(123)
x &lt;- seq(-3, 3, length = 1000)
z &lt;- x + rlogis(length(x))
y &lt;- cut(z, c(-Inf, -1, 1, Inf), labels = c(&quot;low&quot;,&quot;medium&quot;,&quot;high&quot;))
d &lt;- data.frame(x = x, z = z, y = y)</code></pre>
<p><img src="lecture-04-18-2022_files/figure-html/unnamed-chunk-25-1.png" width="100%" style="display: block; margin: auto;" />
If we <em>know</em> that <span class="math inline">\(Y_i\)</span> is
interval-censored at <span class="math inline">\(Y\)</span> = -1 and
<span class="math inline">\(Y\)</span> = 1 then we can estimate this
model using <code>survreg</code> since it will handle the censoring.</p>
<pre class="r"><code>library(dplyr)
d &lt;- d %&gt;% 
   mutate(lower = case_when(y == &quot;medium&quot; ~ -1, y == &quot;high&quot; ~ 1)) %&gt;% 
   mutate(upper = case_when(y == &quot;low&quot; ~ -1, y == &quot;medium&quot; ~ 1))</code></pre>
<p>Note that <code>case_when</code> will return <code>NA</code> values
for other cases, which is what we want. Here are a few observations.</p>
<pre class="r"><code>d[c(1,500,1000),]</code></pre>
<pre><code>             x       z      y lower upper
1    -3.000000 -3.9072    low    NA    -1
500  -0.003003  1.3035   high     1    NA
1000  3.000000  0.8972 medium    -1     1</code></pre>
<p>Estimate a model for an interval-censored logistic-distributed
response variable.</p>
<pre class="r"><code>library(survival)</code></pre>
<pre><code>Warning: package &#39;survival&#39; was built under R version 4.1.3</code></pre>
<pre class="r"><code>m &lt;- survreg(Surv(lower, upper, type = &quot;interval2&quot;) ~ x, dist = &quot;logistic&quot;, data = d)
summary(m)$table</code></pre>
<pre><code>               Value Std. Error       z         p
(Intercept) -0.06696    0.07299 -0.9173 3.590e-01
x            1.05888    0.05962 17.7615 1.405e-70
Log(scale)   0.08994    0.05595  1.6074 1.080e-01</code></pre>
<p>If we <em>do not know</em> where <span
class="math inline">\(Y_i\)</span> is censored (but assume it is at the
same values for all observations) then we can estimate the model using
<code>vglm</code>.</p>
<pre class="r"><code>d$y &lt;- factor(d$y, levels = c(&quot;low&quot;,&quot;medium&quot;,&quot;high&quot;), ordered = TRUE)
m &lt;- vglm(y ~ x, family = propodds, data = d)
cbind(coef(m), confint(m))</code></pre>
<pre><code>                        2.5 %  97.5 %
(Intercept):1  0.8528  0.6985  1.0071
(Intercept):2 -0.9752 -1.1323 -0.8181
x              0.9678  0.8896  1.0459</code></pre>
<p>Note that the estimates of <span
class="math inline">\(\beta_1\)</span> are <em>similar</em> but not
identical. This is due to having different information. In the
proportional odds model the thresholds are <em>unknown</em> and must be
estimated, whereas in the “survival” model they were treated as
<em>known</em>.</p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
