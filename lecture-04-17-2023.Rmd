---
output:
  html_document: 
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "04-17-2023"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
output:
  html_document: 
    theme: readable
  pdf_document: default
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, out.width = "100%", fig.align = "center", cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"), comment = "")
```

```{r packages, echo = FALSE}
library(tidyverse)
suppressWarnings(library(kableExtra))
```

```{r options, echo = FALSE}
options(digits = 4, width = 100)
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

## Sequential and Binary Regression Models

A sequential regression model can sometimes be estimated using several binary regression models.

**Example**: Consider again the `pneumo` data.
```{r}
library(VGAM)
pneumo

# sequential regression model
m <- vglm(cbind(normal, mild, severe) ~ exposure.time, 
  family = cratio(link = "logitlink"), data = pneumo)
summary(m)
```
This model can be estimated using *two* logistic regression models. The first is a model for whether a miner will develop pneumoconiosis (i.e., mild or severe). This logistic regression model can be estimated as follows.
```{r}
m1 <- glm(cbind(mild + severe, normal) ~ exposure.time, family = binomial, data = pneumo)
summary(m1)$coefficients
```
Next we have the model for whether a miner with pneumoconiosis will develop severe pneumoconiosis (rather than mild). The logistic regression model for this probability can be estimated by effectively ignoring any observations where pneumoconiosis did not progress to mild or severe (i.e., exclude cases where it was normal).  
```{r}
m2 <- glm(cbind(severe, mild) ~ exposure.time, family = binomial, data = pneumo)
summary(m2)$coefficients
```
We *cannot* estimate a sequential regression model with separate binary models if we want to constrain some parameters to be equal across the "steps" of the model (e.g., if we wanted to assume that the odds ratio for the effect of exposure was the same at each step as done below using the `parallel = TRUE` option.
```{r}
m <- vglm(cbind(normal, mild, severe) ~ exposure.time, 
  family = cratio(link = "logitlink", parallel = TRUE), data = pneumo)
summary(m)
```

## Proportional Odds Models

The logistic regression model for a binary response $Y_i = 0,1$ can be written as
$$
\log\left[\frac{P(Y_i=1)}{1-P(Y_i=1)}\right] = 
\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}.
$$
This can also be written as
$$
\log\left[\frac{P(Y_i>0)}{1-P(Y_i>0)}\right] = 
\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}.
$$

Now let the response variable $Y_i = 1, 2, \dots, R$ denote $R$ ordered response categories where order is implied by $Y_i$. A *proportional odds model* is a logistic regression model for each of the $R-1$ possible "dichotomizations" of the categories such that
$$
\log\left[\frac{P(Y_i>y)}{1-P(Y_i>y)}\right] = 
\beta_0^{(y)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}
$$
for $y = 1, 2, \dots, R-1$. This defines a *system* of equations for each possible dichotomy. For example, suppose $R=4$ and so $Y_i = 1, 2, 3, 4$. The model is then written as
\begin{align*}
\log\left[\frac{P(Y_i > 1)}{1-P(Y_i > 1)}\right] & = 
\beta_0^{(1)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}, \\
\log\left[\frac{P(Y_i > 2)}{1-P(Y_i > 2)}\right] & = 
\beta_0^{(2)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}, \\
\log\left[\frac{P(Y_i > 3)}{1-P(Y_i > 3)}\right] & = 
\beta_0^{(3)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}.
\end{align*}
The odds are proportional because (omitting the $i$ subscript for simplicity)
$$
	\frac{P(Y>y)}{1-P(Y>y)} = 
	e^{\beta_0^{(y)}}e^{\beta_1 x_{1}} \cdots e^{\beta_k x_{k}},
$$
and so the odds ratio when we compare the odds at $x_1 = x_a$ to $x_1 = x_b$, 
$$
  \frac{e^{\beta_0^{(y)}}e^{\beta_1 x_{a}} \cdots e^{\beta_k x_{k}}}{e^{\beta_0^{(y)}}e^{\beta_1 x_{b}} \cdots e^{\beta_k x_{k}}} = e^{\beta_1}
$$
*does not depend on* $y$ (i.e., it does not depend how we dichotomize $Y$). 

The system of equations allows us to express the probability of each response category as a function of the explanatory variables and parameters. From
$$
\log\left[\frac{P(Y_i>y)}{1-P(Y_i>y)}\right] = 
\beta_0^{(y)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}
$$
we get
$$
	P(Y_i > y) = \frac{\exp(\beta_0^{(y)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik})}{1 + \exp(\beta_0^{(y)} + \beta_1 x_{i1} + \cdots + \beta_k x_{ik})},
$$
and then
$$
	P(Y_i = y) = P(Y_i > y-1) - P(Y_i > y),
$$
where $P(Y_i > 0) = 1$ and $P(Y_i > R) = 0$ by definition. 

The distribution of a categorical response variable is assumed to be a *multinomial distribution*. The binomial distribution is a special case for when there are only $R=2$ categories.

**Example**: Recall the `bliss` data that we used to demonstrate logistic regression.
```{r, message = FALSE}
library(trtools) # for bliss data
library(ggrepel) # for geom_repel_label

bliss$proportion <- paste(bliss$dead, "/", bliss$exposed, sep = "")
bliss$alive <- bliss$exposed - bliss$dead
bliss

p <- ggplot(bliss, aes(x = concentration, y = dead/exposed)) +
  geom_point() + ylim(0, 1) + theme_minimal() + 
  geom_label_repel(aes(label = proportion), box.padding = 0.75) + 
  labs(x = "Concentration of Carbon Disulphide (mg/liter)",
    y = "Proportion of Beetles Dying")
plot(p)
m <- glm(cbind(dead, alive) ~ concentration, family = binomial, data = bliss)
summary(m)$coefficients
```
The `vglm` function from the **VGAM** package can be used to estimate a proportional odds model, but logistic regression is a special case when there are only $R=2$ response categories.
```{r, message = FALSE}
library(VGAM) # for the vglm function and others
m <- vglm(cbind(alive, dead) ~ concentration, family = propodds, data = bliss)
cbind(coef(m), confint(m))
```
But note that we specify the *order* of the response categories in `cbind` from left to right when using `vglm`, which is opposite of how it is done when using `glm`. 

Here we can plot the probabilities of the two categories as a function of concentration.
```{r}
d <- data.frame(concentration = seq(49, 77, length = 100))
d <- cbind(d, predict(m, newdata = d, type = "response"))
head(d)
library(tidyr)
d <- d %>% pivot_longer(cols = c(dead,alive), 
  names_to = "state", values_to = "probability")
head(d)
p <- ggplot(d, aes(x = concentration, y = probability)) + 
  geom_line(aes(color = state)) + 
  ylim(0, 1) + theme_minimal() + theme(legend.position = c(0.1, 0.6)) + 
  labs(x = "Concentration of Carbon Disulphide (mg/liter)", 
    y = "Probability", color = "State")
plot(p)
```
**Example**: Consider again the `pneumo` data frame included with the **VGAM** package.
```{r}
print(pneumo)
```
```{r, echo = FALSE}
d <- pneumo
d$total <- with(d, normal + mild + severe)
d <- tidyr::gather(d, key = "condition", value = "frequency", normal, mild, severe)
d$p <- with(d, paste(frequency, "/", total, sep = ""))
d$condition <- factor(d$condition, levels = c("severe","mild","normal"))
p <- ggplot(d, aes(x = exposure.time, y = frequency/total, color = condition))
p <- p + geom_point() + ylim(0, 1) + theme_minimal() + theme(legend.position = c(0.9, 0.8))
p <- p + geom_label_repel(aes(label = p), box.padding = 0.75, show.legend = FALSE)
p <- p + labs(x = "Exposure (years)", y = "Proportion", color = "Condition")
plot(p)
```
We can estimate a proportional odds model for these data as follows.
```{r}
m <- vglm(cbind(normal, mild, severe) ~ exposure.time, family = propodds, data = pneumo)
summary(m)
```
That "exponentiated coefficient" is the odds ratio for the effect of exposure time. We can also get that with a confidence interval as follows.
```{r}
exp(cbind(coef(m), confint(m)))
```
```{r}
d <- data.frame(exposure.time = seq(5, 52, length = 100))
d <- cbind(d, predict(m, newdata = d, type = "response"))
head(d)
library(tidyr)
d <- d %>% pivot_longer(cols = c(normal, mild, severe), 
  names_to = "condition", values_to = "probability")
head(d)
```
And then we can plot as usual. Here I have specified an order of the categories so that the colors are consistent with the plot of the raw data.
```{r}
d$condition <- factor(d$condition, levels = c("severe","mild","normal"))
p <- ggplot(d, aes(x = exposure.time, y = probability)) + 
  geom_line(aes(color = condition)) + 
  ylim(0, 1) + theme_minimal() + theme(legend.position = c(0.1, 0.6)) + 
  labs(x = "Exposure (years)", y = "Probability", color = "Condition")
plot(p)
```
```{r, message = FALSE, echo = FALSE}
d <- pneumo
d$total <- with(d, normal + mild + severe)
d <- tidyr::gather(d, key = "condition", value = "frequency", normal, mild, severe)
d$p <- with(d, paste(frequency, "/", total, sep = ""))
d$condition <- factor(d$condition, levels = c("severe","mild","normal"))

p <- p + geom_point(aes(x = exposure.time, y = frequency/total, color = condition),
  inherit.aes = FALSE, data = d) + ylim(0, 1)
p <- p + geom_label_repel(aes(x = exposure.time, y = frequency/total, label = p, color = condition), data = d, inherit.aes = FALSE, box.padding = 0.75, show.legend = FALSE)
plot(p)
```

Another way to view the model is through *cumulative* probabilities that reflect the dichotomization.
```{r}
d <- data.frame(exposure.time = seq(5, 52, length = 100))
d <- cbind(d, predict(m, newdata = d, type = "response"))

p <- ggplot(d, aes(x = exposure.time, y = mild + severe)) + 
  geom_line() + ylim(0,1) + theme_minimal() + 
  labs(x = "Exposure (years)", y = "Probability")
p1 <- p + ggtitle("Probability of Mild or Severe")

p <- ggplot(d, aes(x = exposure.time, y = severe)) + 
  geom_line() + ylim(0,1) + theme_minimal() + 
  labs(x = "Exposure (years)", y = "Probability")
p2 <- p + ggtitle("Probability of Severe")

cowplot::plot_grid(p1, p2)
```

Data that are not in aggregated form require a slightly different approach to enforce the ordering of the response categories.

**Example**: Consider the data frame `impairment` from the **trtools** package. 
```{r}
library(trtools)
head(impairment,3)
summary(impairment)
```
The ordering of the levels is not consistent with the ordering of impairment.
```{r}
levels(impairment$impairment)
```
But the ordering can be changed using `factor`.
```{r}
impairment$impairment <- factor(impairment$impairment,
  levels = c("none","mild","moderate","impaired"), ordered = TRUE)
levels(impairment$impairment)
```
Now we can estimate a proportional odds model.
```{r}
m <- vglm(impairment ~ ses + events, family = propodds, data = impairment)
cbind(coef(m), confint(m))
```
Applying the exponential function provides odds ratios.
```{r}
exp(cbind(coef(m), confint(m)))
```
We can plot the estimated probabilities as we did in the previous example.
```{r}
d <- expand.grid(ses = c("low","high"), events = seq(0, 9, length = 100))
d <- cbind(d, predict(m, newdata = d, type = "response"))
head(d)
library(tidyr)
d <- d %>% pivot_longer(cols = c(none, mild, moderate, impaired),
  names_to = "impairment", values_to = "probability")
head(d)
```
For our plot it would be nice to have the levels of impairment ordered. We can do this by (re)creating the factor and putting the levels in the desired order. Note that `ordered = TRUE` isn't necessary here. 
```{r}
d$impairment <- factor(d$impairment,
  levels = c("none","mild","moderate","impaired"))
p <- ggplot(d, aes(x = events, y = probability, color = impairment)) + 
  geom_line() + ylim(0,1) + theme_minimal() + facet_wrap(~ ses) + 
  labs(x = "Events", y = "Probability", color = "Impairment")
plot(p)
```

## The Interval-Censored Latent Variable Derivation

Assume a linear model for a *latent* (i.e., unobserved) response variable $Z_i$ such that 
$$
	Z_i = \beta_0 + \beta_1 x_{i1} + \dots + \beta_k x_{ik} + \epsilon_i,
$$
and assume that $Y_i$ arises from interval-censoring of $Z_i$. For example, with $R$ = 4 intervals we would have
$$
	Y_i = 
	\begin{cases}
		1, & \text{if $Z_i \le \delta_{1}$}, \\
		2, & \text{if $\delta_{1} < Z_i \le \delta_{2}$}, \\
		3, & \text{if $\delta_{2} < Z_i \le \delta_{3}$}, \\
		4, & \text{if $\delta_{3} < Z_i$},
	\end{cases}
$$
where $\delta_1 < \delta_2 < \delta_3$. 

If the distribution of $Z_i$ is *logistic* then the model for $Y_i$ is a proportional odds model. Other models can be derived by assuming different distributions of $Z_i$. However if the "thresholds" (i.e, $\delta_1, \delta_2, \dots, \delta_{R-1}$) are unknown, then the origin and scale of $Z_i$ are not uniquely defined. This can be resolved by setting $\beta_0$ = 0 and the variance/scale parameter of $\epsilon_i$ to one. 

**Example**: We can see the connection between interval-censoring and a proportional odds model using simulated data.
```{r}
# create some data
set.seed(123)
x <- seq(-3, 3, length = 1000)
z <- x + rlogis(length(x))
y <- cut(z, c(-Inf, -1, 1, Inf), labels = c("low","medium","high"))
d <- data.frame(x = x, z = z, y = y)
```
```{r, echo = FALSE, fig.height = 6}
p <- ggplot(d, aes(x = x, y = z, color = factor(y))) + geom_point(alpha = 0.5)
p <- p + geom_hline(aes(yintercept = -1), lty = 3)
p <- p + geom_hline(aes(yintercept =  1), lty = 3)
p <- p + geom_abline(aes(intercept = 0, slope = 1))
p <- p + labs(x = "x", y = "Z", color = "Y") + theme_minimal() 
p <- p + scale_y_continuous(breaks = seq(-10, 7, by = 1))
p <- p + theme(legend.position = c(0.9, 0.2))
plot(p)
```
If we *know* that $Y_i$ is interval-censored at $Y$ = -1 and $Y$ = 1 then we can estimate this model using `survreg` since it will handle the censoring. 
```{r}
library(dplyr)
d <- d %>% 
   mutate(lower = case_when(y == "medium" ~ -1, y == "high" ~ 1)) %>% 
   mutate(upper = case_when(y == "low" ~ -1, y == "medium" ~ 1))
```
Note that `case_when` will return `NA` values for other cases, which is what we want. Here are a few observations.
```{r}
d[c(1,500,1000),]
```
Estimate a model for an interval-censored logistic-distributed response variable.
```{r, message = FALSE}
library(survival)
m <- survreg(Surv(lower, upper, type = "interval2") ~ x, dist = "logistic", data = d)
summary(m)$table
```
If we *do not know* where $Y_i$ is censored (but assume it is at the same values for all observations) then we can estimate the model using `vglm`.
```{r}
d$y <- factor(d$y, levels = c("low","medium","high"), ordered = TRUE)
m <- vglm(y ~ x, family = propodds, data = d)
cbind(coef(m), confint(m))
```
Note that the estimates of $\beta_1$ are *similar* but not identical. This is due to having different information. In the proportional odds model the thresholds are *unknown* and must be estimated, whereas in the "survival" model they were treated as *known*. 