---
output:
  html_document: 
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "02-28-2024"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(comment = "", echo = TRUE, fig.height = 4, message = FALSE, out.width = "100%", fig.align = "center", cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages, echo = FALSE}
library(tidyverse)
suppressWarnings(library(kableExtra))
```

```{r utilities, echo = FALSE}
source("../../utilities.R")
```

```{r options, echo = FALSE}
options(digits = 4, width = 100)
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`


## Parameter Interpretation With Log Link Functions

A GLM with a log link function, like a Poisson regression model, has the form
$$
  \log E(Y_i) = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik},
$$
or
$$
  E(Y_i) = \exp(\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}),
$$

which can also be written as a "multiplicative model" of the form
$$
  E(Y_i) = e^{\beta_0}e^{\beta_1 x_{i1}}e^{\beta_2 x_{i2}} \cdots e^{\beta_k x_{ik}}.
$$
Recall that $e^{a+b} = e^ae^b$. For this reason the parameters $\beta_1, \beta_2, \dots, \beta_k$ or linear functions thereof are not interpreted the same way as in the *additive* model
$$
  E(Y_i) = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik},
$$
but they are still relatively easy to interpret in terms of *multiplicative* rather than *additive* changes in $E(Y)$.

## Rate Ratios (Quantitative Explanatory Variable)

Consider the model
$$
	\log E(Y) = \beta_0 + \beta_1 x, 
$$
and let
$$
	\log E(Y_a) = \beta_0 + \beta_1 (x+1) \ \ \ \text{and} \ \ \ \log E(Y_b) = \beta_0 + \beta_1 x
$$
for an arbitrary value of $x$. Then the *difference* in the log of the expected values is
$$
	\log E(Y_a) - \log E(Y_b) = \underbrace{\beta_0 + \beta_1 (x+1)}_{\log E(Y_a)} - \underbrace{(\beta_0 + \beta_1 x)}_{\log E(Y_b)} = \beta_1,
$$
meaning that $\beta_1$ is the *additive* change in $\log E(Y)$ per unit increase in $x$.

Now consider the same model written as
$$
	E(Y) = e^{\beta_0}e^{\beta_1 x},
$$
and let
$$
	E(Y_a) = e^{\beta_0}e^{\beta_1 (x+1)} \ \ \ \text{and} \ \ \ 
	E(Y_b) = e^{\beta_0}e^{\beta_1 x}
$$
for an arbitrary value of $x$. Then the *ratio* of the expected values is
$$
	\frac{E(Y_a)}{E(Y_b)} = \frac{\overbrace{e^{\beta_0}e^{\beta_1 (x+1)}}^{E(Y_a)}}{\underbrace{e^{\beta_0}e^{\beta_1 x}}_{E(Y_b)}} = \frac{e^{\beta_0}e^{\beta_1 x}e^{\beta_1}}{e^{\beta_0}e^{\beta_1 x}} = e^{\beta_1} \Rightarrow E(Y_a) = E(Y_b)e^{\beta_1},
$$
so that $E(Y)$ changes by a *factor* of $e^{\beta_1}$ per unit increase in $x$. The "exponentiated" parameter, $e^{\beta_1}$, is sometimes called a "rate ratio" because it is often the ratio of two rates when the counts are per unit space, time, or something else.

**Example**: Consider again the `ceriodaphniastrain` data and model.
```{r, message = FALSE}
library(trtools)
ceriodaphniastrain$strainf <- factor(ceriodaphniastrain$strain, 
  labels = c("a","b"))
m <- glm(count ~ concentration + strainf, 
  family = poisson, data = ceriodaphniastrain) # log link is default
cbind(summary(m)$coefficients, confint(m))
exp(cbind(coef(m), confint(m))) # coef extracts the parameter estimates only
```
Note: It only makes sense to apply the exponential function to the point estimates and the endpoints of the confidence interval. A standard error of $e^{\hat\beta_1}$ could be obtained, but it is **not** equal to the exponentiated standard error of $\hat\beta_1$. A test concerning $e^{\beta_1}$ can be done using either the confidence interval or by stated the hypotheses in terms of $\beta_1$ (e.g., the null hypothesis that $e^{\beta_1} = 1$ is the same as the null hypothesis that $\beta_1 = 0$).

Another approach is to use `lincon` and the `tf` (transformation function) argument.
```{r}
lincon(m, tf = exp)
```
Note that the confidence interval endpoints are not quite the same as what we obtained using `confint`. This is because `confint` and `lincon` use different approaches to confidence intervals (more on that later). 

**Example**: Consider a model for the expected number of matings of African elephants as a function of age.
```{r, message = FALSE}
library(Sleuth3)
head(case2201)
m <- glm(Matings ~ Age, family = poisson, data = case2201)
cbind(summary(m)$coefficients, confint(m))
exp(cbind(m$coefficients, confint(m))) 
```

## Percent Change (Quantitative Explanatory Variable)

The *percent change* in the expected response is 
$$
  100\% \times \left[\frac{E(Y_a)-E(Y_b)}{E(Y_b)}\right] = 100\% \times \left[E(Y_a)/E(Y_b) - 1\right],
$$  
where $E(Y_a)$ and $E(Y_b)$ are the expected responses at two different points ($a$ and $b$) defined in terms of the explanatory variable(s). 

1. Note that if this is *positive* then it is a percent *increase*, whereas if it is negative then it is a percent *decrease*. 

0. The ratio $E(Y_a)/E(Y_b)$ is the *rate ratio*.  

**Example**: Suppose we have the model $\log E(Y) = \beta_0 + \beta_1 x$ where $x$ is a quantitative variable and $\beta_1 = 0.22$. Then $e^{\beta_1} \approx `r round(exp(0.22), 2)`$. So when $x$ increases by one unit (i.e., to $x + 1$), --- i.e., from $E(Y_b) = e^{\beta_0}e^{\beta_1x}$ to $E(Y_a) = e^{\beta_0}e^{\beta_1(x+1)}$ then the expected response *increases* by a *factor* of
$$
  E(Y_a)/E(Y_b) = e^{\beta_1} \approx 1.25,
$$
and because
$$
  100\% \times \left[1.25 - 1\right] = 25\%.
$$  
we can say that it *increases* by 25%. 

**Example**: Consider again the model for the elephant matings data.
```{r}
m <- glm(Matings ~ Age, family = poisson, data = case2201)
exp(cbind(m$coefficients, confint(m))) 
```
The percent change in the expected count per unit (year) increase in Age is approximately 100%(1.07 - 1) = 7% (i.e., a 7% increase). 

**Example**: Suppose we have the model $\log E(Y) = \beta_0 + \beta_1 x$ where $x$ is a quantitative variable and $\beta_1 = -0.22$. Then $e^{\beta_1} \approx `r round(exp(-0.22), 2)`$. So when $x$ increases by one unit (i.e., to $x + 1$), --- i.e., from $E(Y_b) = e^{\beta_0}e^{\beta_1x}$ to $E(Y_a) = e^{\beta_0}e^{\beta_1(x+1)}$ then the expected response *decreases* by a *factor* of
$$
  E(Y_a)/E(Y_b) = e^{\beta_1} \approx 0.8,
$$
or because 
$$
  100\% \times \left[0.8 - 1\right] = -20\%
$$  
we can say that it *decreases* by 20%. 

**Example**: Consider again the model for the `ceriodaphniastrain` data.
```{r}
m <- glm(count ~ concentration + strainf, family = poisson, data = ceriodaphniastrain) 
exp(cbind(coef(m), confint(m)))
```
The percent change in the expected count per unit increase in concentration is approximately 100%(0.21 - 1) = -79% (i.e., a 79% decrease or reduction). 

## Rate Ratios (Categorical Explanatory Variable)

Consider the model
$$
	\log E(Y) = \beta_0 + \beta_1 x, \ \ \text{or, equivalently,} \ \ 
	E(Y) = e^{\beta_0}e^{\beta_1 x},
$$
where 
$$
	x = 
	\begin{cases}
		1, & \text{if the observation is in group $a$}, \\
		0, & \text{if the observation is in group $b$}.
	\end{cases}
$$
Then
$$
	E(Y) = 
	\begin{cases}
		e^{\beta_0}e^{\beta_1}, & \text{if the observation is in group $a$}, \\
		e^{\beta_0}, & \text{if the observation is in group $b$}.
	\end{cases}
$$
Let 
$$
  E(Y_a) = e^{\beta_0}e^{\beta_1} \ \ \ \text{and} \ \ \ E(Y_b) = e^{\beta_0}.
$$
Then the *ratio* of the expected values is
$$
	\frac{E(Y_a)}{E(Y_b)} = \frac{e^{\beta_0}e^{\beta_1}}{e^{\beta_0}} = e^{\beta_1} \Leftrightarrow E(Y_a) = E(Y_b)e^{\beta_1}
$$
so that $E(Y_a)$ is $e^{\beta_1}$ times that of $E(Y_b)$. Also
$$
	\frac{E(Y_b)}{E(Y_a)} = \frac{e^{\beta_0}}{e^{\beta_0}e^{\beta_1}} = \frac{1}{e^{\beta_1}} = e^{-\beta_1}.
$$
so that $E(Y_b)$ is $1/e^{\beta_1}$ times that of $E(Y_a)$.

**Example**: Consider again the `ceriodaphniastrain` data and model.
```{r, message = FALSE}
m <- glm(count ~ concentration + strainf, 
  family = poisson, data = ceriodaphniastrain) 
cbind(summary(m)$coefficients, confint(m))
exp(cbind(coef(m), confint(m)))
```
Alternatively we can parameterize the model.
```{r, message = FALSE}
ceriodaphniastrain$strainf <- relevel(ceriodaphniastrain$strainf, ref = "b")
m <- glm(count ~ concentration + strainf, 
  family = poisson, data = ceriodaphniastrain) 
cbind(summary(m)$coefficients, confint(m))
exp(cbind(coef(m), confint(m)))
```

**Example**: Consider these data from a stratified random sampling design and a Poisson regression model.
```{r, message = FALSE, fig.height = 4}
library(trtools)
library(ggplot2) 
p <- ggplot(daphniastrat, aes(x = layer, y = count)) + 
  geom_dotplot(binaxis = "y", binwidth = 1, stackdir = "center") + 
  labs(x = "Layer", y = "Number of Daphnia") + theme_minimal()
plot(p)
daphniastrat$layer <- relevel(daphniastrat$layer, ref = "thermocline")
m <- glm(count ~ layer, family = poisson, data = daphniastrat)
summary(m)$coefficients
exp(cbind(coef(m), confint(m)))
```

## Percent Larger/Smaller (Categorical Explanatory Variable)

The *percent change* in the expected response is 
$$
  100\% \times \left[\frac{E(Y_a)-E(Y_b)}{E(Y_b)}\right] = 100\% \times \left[E(Y_a)/E(Y_b) - 1\right],
$$  
where $E(Y_a)$ and $E(Y_b)$ are the expected responses at two different points ($a$ and $b$) defined in terms of the explanatory variable(s). 

1. Note that if this is *positive* then $E(Y_a)$ is that percent *larger* than $E(Y_b)$, whereas if this is *negative* then $E(Y_b)$ is that percent *smaller* than $E(Y_a)$. 

0. The ratio $E(Y_a)/E(Y_b)$ is the *rate ratio*.  

**Example**: Suppose we have the model $\log E(Y) = \beta_0 + \beta_1 x$ where $x$ is an indicator variable for category $a$ and $\beta_1 = 0.22$. Then $e^{\beta_1} \approx `r round(exp(0.22), 2)`$, $E(Y_a) = e^{\beta_0}e^{\beta_1}$ and $E(Y_b) = e^{\beta_0}$, and $E(Y_a)$ is about 1.25 times *larger* than $E(Y_b)$ because
$$
  E(Y_a)/E(Y_b) = e^{\beta_1} \approx 1.25,
$$
and because
$$
  100\% \times \left[1.25 - 1\right] = 25\%.
$$  
we can say that $E(Y_a)$ is about 25% *larger* than $E(Y_b)$. 

**Example**: Suppose we have the model $\log E(Y) = \beta_0 + \beta_1 x$ where $x$ is an indicator variable for category $a$ and $\beta_1 = -0.22$. Then $e^{\beta_1} \approx `r round(exp(-0.22), 2)`$, $E(Y_a) = e^{\beta_0}e^{\beta_1}$ and $E(Y_b) = e^{\beta_0}$, and $E(Y_a)$ is about 0.8 times *smaller* than $E(Y_b)$ because
$$
  E(Y_a)/E(Y_b) = e^{\beta_1} \approx 0.8,
$$
and because
$$
  100\% \times \left[0.8 - 1\right] = -20\%.
$$  
we can say that $E(Y_a)$ is about 20\% *smaller* than $E(Y_b)$. 

**Example**: Consider again the model for the daphnia data.
```{r}
exp(cbind(coef(m), confint(m)))
```
The expected number of daphnia per liter in the epilimnion layer is estimated to be about 100%(1.73-1) = 73% more than in the thermocline layer. And because 100%(0.15-1) = -85% we estimate that the the expected number of daphia per liter in the hypolimnion layer is 85% less than it is in the thermocline layer.

## Contrasts With Log Link Functions

With a log link function a "contrast" as produced by the `contrast` function has the general form 
$$
  \log E(Y_a) - \log E(Y_b) = \log\left[\frac{E(Y_a)}{E(Y_b)}\right],
$$
where the indices $a$ and $b$ denote specific values of the explanatory variables. If we apply the exponential function to the contrast then it becomes
$$
  \exp[\log E(Y_a) - \log E(Y_b)] = \frac{E(Y_a)}{E(Y_b)},
$$
So applying the exponential function to contrasts allows us to interpret them as ratios. 

**Example**: Consider again the stratified random sampling design. Suppose we want to compare the epilimnion and thermocline layers to the hypolimnion layer. We can use `contrast` and apply the exponential function (`exp` in R) through the argument `tf` (for "transformation function"). Note that this function is only applied to the estimates and the confidence intervals.
```{r}
trtools::contrast(m,
    a = list(layer = c("epilimnion","thermocline")),
    b = list(layer = "hypolimnion"),
    cnames = c("epil vs hypo","therm vs hypo"))
trtools::contrast(m,
    a = list(layer = c("epilimnion","thermocline")),
    b = list(layer = "hypolimnion"),
    cnames = c("epil/hypo","therm/hypo"), tf = exp)
```
The following gives us inferences for the *logarithm* of the expected count for each layer.
```{r}
trtools::contrast(m, a = list(layer = c("epilimnion","thermocline","hypolimnion")),
    cnames = c("epilimnion","thermocline","hypolimnion"))
```
To produce the estimates of the expected counts we need to apply the exponential function. 
```{r}
trtools::contrast(m, a = list(layer = c("epilimnion","thermocline","hypolimnion")),
    cnames = c("epilimnion","thermocline","hypolimnion"), tf = exp)
```
The **emmeans** package can also produce inferences for expected counts and rate ratios for categorical explanatory variables if we specify `type = "response"`. 
```{r}
library(emmeans)
emmeans(m, ~ layer, type = "response")
pairs(emmeans(m, ~ layer), type = "response", adjust = "none", infer = TRUE)
```
Another tool that you can use if you want inferences about the expected response is the `glmint` function from the **trtools** package.
```{r}
d <- data.frame(layer = c("epilimnion","thermocline","hypolimnion"))
glmint(m, newdata = d) # syntax similar to predict and nlsint
```

**Example**: Consider again the model for the `ceriodaphniastrain` data. Consider first the effect of increasing concentration by one percent.
```{r}
m <- glm(count ~ concentration + strainf, 
    family = poisson, data = ceriodaphniastrain)
summary(m)$coefficients
exp(cbind(coef(m), confint(m)))
```
We can estimate the rate ratio for a one unit increase in concentration for each strain.
```{r}
trtools::contrast(m,
    a = list(concentration = 1, strainf = c("a","b")),
    b = list(concentration = 0, strainf = c("a","b")),
    cnames = c("a","b"), tf = exp)
```
Here is how we can do that with the **emmeans** package. This statement will give us the expected response for concentrations one unit apart for each strain.
```{r}
emmeans(m, ~concentration|strainf, 
  at = list(concentration = c(1,0)), type = "response")
```
Now we can compare them.
```{r}
pairs(emmeans(m, ~concentration|strainf, 
  at = list(concentration = c(1,0)), 
  type = "response"), infer = TRUE)
```
We can estimate the rate ratio comparing the strains at difference concentrations. 
```{r}
trtools::contrast(m,
    a = list(concentration = c(0, 1, 2), strainf = "a"),
    b = list(concentration = c(0, 1, 2), strainf = "b"),
    cnames = c("0%", "1%", "2%"), tf = exp)
```
We can also use `contrast` to estimate the expected count for, say, strain `a` at different concentration values.
```{r}
trtools::contrast(m, a = list(concentration = c(0, 1, 2), strainf = "a"), 
  cnames = c("0%", "1%", "2%"), tf = exp)
```
We can also use the **emmeans** package for inferences about expected counts and rate ratios for categorical explanatory variables.
```{r}
library(emmeans)
emmeans(m, ~ strainf, type = "response",
  at = list(concentration = 0))
pairs(emmeans(m, ~ strainf, type = "response",
  at = list(concentration = 0)), reverse = TRUE)
```
Now suppose we add an interaction between concentration and strain.
```{r}
m <- glm(count ~ concentration + strainf + concentration:strainf, 
    family = poisson, data = ceriodaphniastrain)
summary(m)$coefficients
trtools::contrast(m,
    a = list(concentration = 1, strainf = c("a","b")),
    b = list(concentration = 0, strainf = c("a","b")),
    cnames = c("a","b"), tf = exp)
trtools::contrast(m,
    a = list(concentration = c(0, 1, 2), strainf = "a"),
    b = list(concentration = c(0, 1, 2), strainf = "b"),
    cnames = c("0%", "1%", "2%"), tf = exp)
```
Now the rate ratio for concentration depends on strain and the rate ratio for strain depends on concentration when there is an interaction term. 


