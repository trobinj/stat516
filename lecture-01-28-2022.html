<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Friday, Jan 28</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics 436/516</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="lectures.html">Lectures</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Friday, Jan 28</h1>

</div>


<p>You can also download a <a href="lecture-01-28-2022.pdf">PDF</a> copy of this lecture.</p>
<div id="confidence-intervals-and-significance-tests" class="section level2">
<h2>Confidence Intervals and Significance Tests</h2>
<p>A significance test can be used to derive a confidence interval, and a confidence interval can be used to conduct a significance test. If we have hypotheses for a two-sided test like <span class="math display">\[
  H_0\!: \beta_j = c \ \ \text{and} \ \ H_a\!: \beta_j \neq c, 
\]</span> then we reject <span class="math inline">\(H_0\)</span> if and only if the confidence interval for <span class="math inline">\(\beta_j\)</span> does not contain <span class="math inline">\(c\)</span>, with a couple of caveats.</p>
<ol style="list-style-type: decimal">
<li><p>The confidence level must be <span class="math inline">\((1-\alpha)100\)</span>% (<span class="math inline">\(\alpha\)</span> is the <em>significance level</em>).</p></li>
<li><p>The test is two-sided (but one-sided tests match one-sided confidence intervals).</p></li>
</ol>
<p>A confidence interval with confidence level <span class="math inline">\((1-\alpha)100\)</span>% effectively defines all values of the parameter that <em>would not be rejected</em> in a two-sided test with significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>Note that this also applies to a linear function of model parameters (<span class="math inline">\(\ell\)</span>). So if we have the hypotheses <span class="math display">\[
  H_0\!: \ell = c \ \ \text{and} \ \ H_a\!: \ell \neq c, 
\]</span> then we reject <span class="math inline">\(H_0\)</span> if and only if the confidence interval for <span class="math inline">\(\ell\)</span> does not contain <span class="math inline">\(c\)</span>.</p>
<p><strong>Example</strong>: Consider again the model for the <code>anorexia</code> data, but parameterized to compare the two treatment conditions against the control so that the model is <span class="math display">\[
  E(Y_i) = 
  \begin{cases}
    \beta_0, &amp; \text{if the $i$-th observation is under the control condition}, \\
    \beta_0 + \beta_1, &amp; \text{if $i$-th observation under cognitive behavioral therapy}, \\
    \beta_0 + \beta_2, &amp; \text{if the $i$-th observations is under family therapy}. \\
  \end{cases}
\]</span></p>
<pre class="r"><code>library(MASS) # for anorexia data
anorexia$change &lt;- anorexia$Postwt - anorexia$Prewt
anorexia$Treat &lt;- relevel(anorexia$Treat, ref = &quot;Cont&quot;)
m &lt;- lm(change ~ Treat, data = anorexia)
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>            Estimate Std. Error t value Pr(&gt;|t|)   2.5 % 97.5 %
(Intercept)   -0.450      1.476 -0.3048 0.761447 -3.3954  2.495
TreatCBT       3.457      2.033  1.7001 0.093608 -0.5994  7.513
TreatFT        7.715      2.348  3.2854 0.001602  3.0302 12.399</code></pre>
<p>We can produce the same inferences using <code>contrast</code>.</p>
<pre class="r"><code>library(trtools)
contrast(m, 
  a = list(Treat = c(&quot;CBT&quot;,&quot;FT&quot;)),
  b = list(Treat = &quot;Cont&quot;),
  cnames = c(&quot;Cognitive vs Control&quot;, &quot;Family vs Control&quot;))</code></pre>
<pre><code>                     estimate    se   lower  upper tvalue df   pvalue
Cognitive vs Control    3.457 2.033 -0.5994  7.513  1.700 69 0.093608
Family vs Control       7.715 2.348  3.0302 12.399  3.285 69 0.001602</code></pre>
</div>
<div id="joint-hypotheses" class="section level1">
<h1>Joint Hypotheses</h1>
<p><strong>Example</strong>: Consider the following model and hypotheses for the <code>anorexia</code> data.</p>
<pre class="r"><code>library(MASS) # for anorexia data
anorexia$change &lt;- anorexia$Postwt - anorexia$Prewt
m.anorexia &lt;- lm(change ~ Treat, data = anorexia)
summary(m.anorexia)$coefficients</code></pre>
<pre><code>            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)    3.007      1.398   2.151  0.03499
TreatCont     -3.457      2.033  -1.700  0.09361
TreatFT        4.258      2.300   1.852  0.06838</code></pre>
<p>The model is therefore <span class="math display">\[
  E(Y_i) = 
  \begin{cases}
    \beta_0, &amp; \text{if the $i$-th observation is under cognitive behavioral therapy}, \\
    \beta_0 + \beta_1, &amp; \text{if $i$-th observation is under the control condition}, \\
    \beta_0 + \beta_2, &amp; \text{if the $i$-th observations is under family therapy}. \\
  \end{cases}
\]</span> In some cases we might be testing hypothesis like <span class="math inline">\(H_0: \beta_2 = 0\)</span> or <span class="math inline">\(H_0: \beta_1 - \beta_2 = 0\)</span>. But in other cases we might be testing what is sometimes called a <em>joint</em> hypothesis such as <span class="math display">\[
  H_0\!: \beta_1 = 0 \text{ and } \beta_2 = 0 \ \ \text{versus} \ \ 
  H_a\!: \text{not both $\beta_1 = 0$ and $\beta_2 = 0$}.
\]</span> What does it imply if both <span class="math inline">\(\beta_1 = 0\)</span> and <span class="math inline">\(\beta_2 = 0\)</span>?</p>
<p><strong>Example</strong>: Consider the following model for the <code>whiteside</code> data.</p>
<pre class="r"><code>m.insulation &lt;- lm(Gas ~ Insul + Temp + Insul:Temp, data = whiteside)
summary(m.insulation)$coefficients</code></pre>
<pre><code>                Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)       6.8538    0.13596  50.409 7.997e-46
InsulAfter       -2.1300    0.18009 -11.827 2.316e-16
Temp             -0.3932    0.02249 -17.487 1.976e-23
InsulAfter:Temp   0.1153    0.03211   3.591 7.307e-04</code></pre>
<p>The model is therefore <span class="math display">\[
E(Y_i) = 
\begin{cases}
        \beta_0 + \beta_2 t_i, &amp; \text{if $i$-th observation is before insulation}, \\
        \beta_0 + \beta_1 + (\beta_2 + \beta_3) t_i, &amp; \text{if $i$-th observation is after insulation}.
\end{cases}
\]</span> We might test a single null hypothesis that the rate of change in expected gas consumption with respect to temperature is the same before and after insulation — i.e., <span class="math inline">\(H_0: \beta_3 = 0\)</span>. But consider the joint hypothesis <span class="math display">\[
  H_0\!: \beta_1 = 0 \text{ and } \beta_3 = 0 \ \ \text{versus} \ \ 
  H_a\!: \text{not both $\beta_1 = 0$ and $\beta_3 = 0$}.
\]</span> What does it imply if both <span class="math inline">\(\beta_1 = 0\)</span> and <span class="math inline">\(\beta_3 = 0\)</span>?</p>
<div id="the-analysis-of-variance-calculations" class="section level2">
<h2>The “Analysis of Variance” Calculations</h2>
<p>Calculations for inference for linear models is often based on the sums of squares decomposition <span class="math display">\[
    \underbrace{\sum_{i=1}^n (y_i - \bar{y})^2}_{\text{total}} = \underbrace{\sum_{i=1}^n (\hat{y}_i - \bar{y})^2}_{\text{model/regression}} + \underbrace{\sum_{i=1}^n (y_i - \hat{y}_i)^2}_{\text{error/residual}},
\]</span> where <span class="math inline">\(\hat{y}_i = \hat\beta_0 + \hat\beta_1x_{i1} + \cdots + \hat\beta_kx_{ik}\)</span>, and the degrees of freedom decomposition <span class="math display">\[
    \underbrace{n-1}_{\text{total}} = \underbrace{p - 1}_{\text{model/regression}} + \underbrace{n - p}_{\text{error/residual}},
\]</span> where <span class="math inline">\(p\)</span> is the number of <span class="math inline">\(\beta_j\)</span> parameters, and <span class="math inline">\(p = k + 1\)</span> if the model includes a <span class="math inline">\(\beta_0\)</span>. (Note: If the <span class="math inline">\(\beta_0\)</span> parameter is omitted from the model, the total degrees of freedom becomes <span class="math inline">\(n\)</span> and the model/regression degrees of freedom becomes <span class="math inline">\(p\)</span>.)</p>
<p>A <em>mean square</em> is a variance-like quantity that is a sum of squares divided by its corresponding degrees of freedom.</p>
<p>Tests can be conducted using the <span class="math inline">\(F\)</span> test statistic which can be written as <span class="math display">\[
F = \frac{(\text{RSS}_{\text{null}} - \text{RSS}_{\text{full}})/(\text{RDF}_{\text{null}} - \text{RDF}_{\text{full}})}{\text{RSS}_{\text{full}}/\text{RDF}_{\text{full}}},
\]</span> where <span class="math inline">\(\text{RSS}\)</span> and <span class="math inline">\(\text{RDF}\)</span> refer to the <em>residual</em> sum of squares and degrees of freedom, respectively. The degrees of freedom for the <span class="math inline">\(F\)</span> distribution are <span class="math inline">\(\text{RDF}_{\text{null}} - \text{RDF}_{\text{full}}\)</span> (numerator) and <span class="math inline">\(\text{RSS}_{\text{full}}\)</span> (denominator). The <em>full</em> model is the model we are using, and the <em>null</em> (aka “reduced”) model is what the full model reduces to <em>if the null hypothesis is true</em>. The <span class="math inline">\(F\)</span> test statistic can be used for tests of individual and joint hypotheses in linear models.</p>
</div>
<div id="using-the-anova-function" class="section level2">
<h2>Using the <code>anova</code> Function</h2>
<p>The <code>anova</code> function is particularly useful for testing joint hypothesis, although it can also be used to test single hypotheses.</p>
<p>Applying <code>anova</code> to a single model will produce the RSS and RDF in the <code>Residuals</code> row.</p>
<pre class="r"><code>anova(m.anorexia)</code></pre>
<pre><code>Analysis of Variance Table

Response: change
          Df Sum Sq Mean Sq F value Pr(&gt;F)   
Treat      2    615   307.3    5.42 0.0065 **
Residuals 69   3911    56.7                  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>To conduct a test, the recommended approach is to apply <code>anova</code> to a null model and the full model.</p>
<pre class="r"><code>m.full &lt;- lm(change ~ Treat, data = anorexia)
m.null &lt;- lm(change ~ 1, data = anorexia) # use ~ 1 if no explanatory variables
anova(m.null, m.full)</code></pre>
<pre><code>Analysis of Variance Table

Model 1: change ~ 1
Model 2: change ~ Treat
  Res.Df  RSS Df Sum of Sq    F Pr(&gt;F)   
1     71 4525                            
2     69 3911  2       615 5.42 0.0065 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>m.full &lt;- lm(Gas ~ Insul + Temp + Insul:Temp, data = whiteside)
m.null &lt;- lm(Gas ~ Temp, data = whiteside)
anova(m.null, m.full)</code></pre>
<pre><code>Analysis of Variance Table

Model 1: Gas ~ Temp
Model 2: Gas ~ Insul + Temp + Insul:Temp
  Res.Df  RSS Df Sum of Sq   F Pr(&gt;F)    
1     54 40.0                            
2     52  5.4  2      34.6 166 &lt;2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The <code>anova</code> function can also do a test concerning a single parameter. Here are two approaches to testing the null hypothesis that <span class="math inline">\(\beta_3 = 0\)</span> in the model <span class="math display">\[
E(Y_i) = 
\begin{cases}
        \beta_0 + \beta_2 t_i, &amp; \text{if $i$-th observation is before insulation}, \\
        \beta_0 + \beta_1 + (\beta_2 + \beta_3) t_i, &amp; \text{if $i$-th observation is after insulation}.
\end{cases}
\]</span></p>
<pre class="r"><code>m.full &lt;- lm(Gas ~ Insul + Temp + Insul:Temp, data = whiteside)
m.null &lt;- lm(Gas ~ Insul + Temp, data = whiteside)
anova(m.null, m.full)</code></pre>
<pre><code>Analysis of Variance Table

Model 1: Gas ~ Insul + Temp
Model 2: Gas ~ Insul + Temp + Insul:Temp
  Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    
1     53 6.77                              
2     52 5.43  1      1.34 12.9 0.00073 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(m.full)$coefficients</code></pre>
<pre><code>                Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)       6.8538    0.13596  50.409 7.997e-46
InsulAfter       -2.1300    0.18009 -11.827 2.316e-16
Temp             -0.3932    0.02249 -17.487 1.976e-23
InsulAfter:Temp   0.1153    0.03211   3.591 7.307e-04</code></pre>
<p>Comment: When conducting a test concerning one parameter (or a single linear function of the model parameters), the <span class="math inline">\(F\)</span> and <span class="math inline">\(t\)</span> test statistics have the relationship <span class="math inline">\(t^2 = F\)</span> and produce the same p-values.</p>
</div>
<div id="example-three-approaches-to-one-test" class="section level2">
<h2>Example: Three Approaches to One Test</h2>
<p>Consider again the model for the <code>anorexia</code> data, but suppose we parameterized the model differently.</p>
<pre class="r"><code>anorexia$Treat &lt;- relevel(anorexia$Treat, ref = &quot;Cont&quot;)
m.anorexia &lt;- lm(change ~ Treat, data = anorexia)
summary(m.anorexia)$coefficients</code></pre>
<pre><code>            Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)   -0.450      1.476 -0.3048 0.761447
TreatCBT       3.457      2.033  1.7001 0.093608
TreatFT        7.715      2.348  3.2854 0.001602</code></pre>
<p>The model is therefore <span class="math display">\[
  E(Y_i) = 
  \begin{cases}
    \beta_0, &amp; \text{if the $i$-th observation is from the control group}, \\
    \beta_0 + \beta_1, &amp; \text{if the $i$-th observation is from the cognitive-behavioral therapy group}, \\
    \beta_0 + \beta_2, &amp; \text{if the $i$-th observations is from the family therapy group}. \\
  \end{cases}
\]</span> Now consider a test of the null hypothesis that the expected weight change is the same regardless of which of the two therapies (i.e., cognitive-behavioral or family) is used. This is the null hypothesis that <span class="math inline">\(\beta_1 = \beta_2\)</span> or, equivalently, <span class="math inline">\(\beta_1 - \beta_2 = 0\)</span>.</p>
<ol style="list-style-type: decimal">
<li><p>Using <code>lincon</code> we can test this null hypothesis as follows.</p>
<pre class="r"><code>m &lt;- lm(change ~ Treat, data = anorexia)
trtools::lincon(m, a = c(0, 1, -1))</code></pre>
<pre><code>           estimate  se  lower  upper tvalue df  pvalue
(0,1,-1),0   -4.258 2.3 -8.845 0.3299 -1.852 69 0.06838</code></pre>
<p>This is because the null hypothesis can be written as <span class="math display">\[
  \ell = 0 \times \beta_0 + 1 \times \beta_1 + (-1) \times \beta_2 = \beta_1 - \beta_2.
\]</span></p></li>
<li><p>Using <code>contrast</code> we can test this null hypothesis as follows.</p>
<pre class="r"><code>m &lt;- lm(change ~ Treat, data = anorexia)
trtools::contrast(m, a = list(Treat = &quot;CBT&quot;), b = list(Treat = &quot;FT&quot;))</code></pre>
<pre><code> estimate  se  lower  upper tvalue df  pvalue
   -4.258 2.3 -8.845 0.3299 -1.852 69 0.06838</code></pre></li>
<li><p>Using <code>anova</code> we can test this null hypothesis as follows.</p>
<pre class="r"><code>anorexia$therapy &lt;- ifelse(anorexia$Treat == &quot;Cont&quot;, &quot;control&quot;, &quot;therapy&quot;)
head(anorexia)</code></pre>
<pre><code>  Treat Prewt Postwt change therapy
1  Cont  80.7   80.2   -0.5 control
2  Cont  89.4   80.1   -9.3 control
3  Cont  91.8   86.4   -5.4 control
4  Cont  74.0   86.3   12.3 control
5  Cont  78.1   76.1   -2.0 control
6  Cont  88.3   78.1  -10.2 control</code></pre>
<pre class="r"><code>tail(anorexia)</code></pre>
<pre><code>   Treat Prewt Postwt change therapy
67    FT  82.1   95.5   13.4 therapy
68    FT  77.6   90.7   13.1 therapy
69    FT  83.5   92.5    9.0 therapy
70    FT  89.9   93.8    3.9 therapy
71    FT  86.0   91.7    5.7 therapy
72    FT  87.3   98.0   10.7 therapy</code></pre>
<pre class="r"><code>m.full &lt;- lm(change ~ Treat, data = anorexia)
m.null &lt;- lm(change ~ therapy, data = anorexia)
anova(m.null, m.full)</code></pre>
<pre><code>Analysis of Variance Table

Model 1: change ~ therapy
Model 2: change ~ Treat
  Res.Df  RSS Df Sum of Sq    F Pr(&gt;F)  
1     70 4105                           
2     69 3911  1       194 3.43  0.068 .
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Note that the null model can be written as <span class="math display">\[
  E(Y_i) = 
  \begin{cases}
 \beta_0, &amp; \text{if the $i$-th observation is from the control group}, \\
 \beta_0 + \beta_1, &amp; \text{if the $i$-th observation is from the therapy group},
  \end{cases}
\]</span> or <span class="math display">\[
  E(Y_i) = 
  \begin{cases}
 \beta_0, &amp; \text{if the $i$-th observation is from the control group}, \\
 \beta_0 + \beta_1, &amp; \text{if the $i$-th observation is from the cognitive-behavioral therapy group}, \\
 \beta_0 + \beta_1, &amp; \text{if the $i$-th observations is from the family therapy group}. \\
  \end{cases}
\]</span> So this model is effectively equivalent to the full model with <span class="math inline">\(\beta_1 = \beta_2\)</span>.</p></li>
</ol>
</div>
<div id="the-trouble-with-anova-tables" class="section level2">
<h2>The Trouble with ANOVA Tables</h2>
<p>I <em>do not</em> recommended trying to produce tests by applying <code>anova</code> to a <em>single</em> model object. While it can produce desired tests <em>in some cases</em> and <em>if used correctly</em>, it often produces confusing results. For example, the following produces a test of the null hypothesis <span class="math inline">\(H_0: \beta_1 = 0, \beta_2 = 0\)</span> for the <code>anorexia</code> model.</p>
<pre class="r"><code>m &lt;- lm(change ~ Treat, data = anorexia)
anova(m)</code></pre>
<pre><code>Analysis of Variance Table

Response: change
          Df Sum Sq Mean Sq F value Pr(&gt;F)   
Treat      2    615   307.3    5.42 0.0065 **
Residuals 69   3911    56.7                  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>But the tests shown here are maybe not what you think they are.</p>
<pre class="r"><code>m &lt;- lm(Gas ~ Insul + Temp + Insul:Temp, data = whiteside)
anova(m)</code></pre>
<pre><code>Analysis of Variance Table

Response: Gas
           Df Sum Sq Mean Sq F value  Pr(&gt;F)    
Insul       1   22.3    22.3   214.2 &lt; 2e-16 ***
Temp        1   45.9    45.9   439.9 &lt; 2e-16 ***
Insul:Temp  1    1.3     1.3    12.9 0.00073 ***
Residuals  52    5.4     0.1                    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><em>If you know what you are doing</em>, there are alternatives to <code>anova</code> that are perhaps better (e.g., the <code>Anova</code> function from the <strong>car</strong> package), but almost always there is a more clear approach using two models in <code>anova</code>, using <code>contrast</code> or <code>lincon</code>, or using the <strong>emmeans</strong> package (which we will discuss later).</p>
<p><strong>Note</strong>: Another potentially confusing test is one that appears at the bottom of <code>summary</code>. It tests the null hypothesis that all <span class="math inline">\(\beta_j\)</span> (except <span class="math inline">\(\beta_0\)</span>) equal zero. For the model for the <code>anorexia</code> data it is the same as the test conducted earlier.</p>
<pre class="r"><code>m &lt;- lm(change ~ Treat, data = anorexia)
summary(m)</code></pre>
<pre><code>
Call:
lm(formula = change ~ Treat, data = anorexia)

Residuals:
   Min     1Q Median     3Q    Max 
-12.56  -4.54  -1.01   3.85  17.89 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)    -0.45       1.48   -0.30   0.7614   
TreatCBT        3.46       2.03    1.70   0.0936 . 
TreatFT         7.71       2.35    3.29   0.0016 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 7.53 on 69 degrees of freedom
Multiple R-squared:  0.136, Adjusted R-squared:  0.111 
F-statistic: 5.42 on 2 and 69 DF,  p-value: 0.0065</code></pre>
<p>But for the model for the <code>whiteside</code> data the utility of this test is questionable.</p>
<pre class="r"><code>m &lt;- lm(Gas ~ Insul + Temp + Insul:Temp, data = whiteside)
summary(m)</code></pre>
<pre><code>
Call:
lm(formula = Gas ~ Insul + Temp + Insul:Temp, data = whiteside)

Residuals:
    Min      1Q  Median      3Q     Max 
-0.9780 -0.1801  0.0376  0.2093  0.6380 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       6.8538     0.1360   50.41  &lt; 2e-16 ***
InsulAfter       -2.1300     0.1801  -11.83  2.3e-16 ***
Temp             -0.3932     0.0225  -17.49  &lt; 2e-16 ***
InsulAfter:Temp   0.1153     0.0321    3.59  0.00073 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 0.323 on 52 degrees of freedom
Multiple R-squared:  0.928, Adjusted R-squared:  0.924 
F-statistic:  222 on 3 and 52 DF,  p-value: &lt;2e-16</code></pre>
<p>Just because R gives you output does not mean it is useful!</p>
<p><strong>Note</strong>: The <code>Residual standard error</code> showns by <code>summary</code> is the square root of the residual/error mean square (i.e., the square root of the ratio of the residual sum of squares to the residual degrees of freedom). The degrees of freedom shown after <code>Residual standard error</code> is the residual degrees of freedom.</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
