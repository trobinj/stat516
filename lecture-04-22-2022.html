<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Friday, Apr 22</title>

<script src="site_libs/header-attrs-2.13/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics 436/516</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="lectures.html">Lectures</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Friday, Apr 22</h1>

</div>


<p>You can also download a <a href="lecture-04-22-2022.pdf">PDF</a> copy
of this lecture.</p>
<div id="the-incidental-parameter-problem" class="section level2">
<h2>The Incidental Parameter Problem</h2>
<p>Some kinds of designs result in a “factor” with a relatively large
number of levels, where each level corresponds to an
experimental/observational unit. This can arise for a variety of
reasons. Such designs include <em>repeated measures</em>,
<em>longitudinal data</em>, <em>panel data</em>, <em>multilevel
data</em>, <em>pseudo-replication</em>, <em>within-subjects
factors</em>, <em>dependent samples</em>, and <em>clustered data</em> to
name a few (these are not mutually exclusive). Having a factor with a
large number of levels can cause complications. This is known in
econometrics as the “incidental parameter problem.”</p>
<p><strong>Example</strong>: Consider a study of the running times of
three routes from home to second base on a baseball diamond.
<img src="lecture-04-22-2022_files/figure-html/unnamed-chunk-2-1.png" width="60%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>library(trtools)
head(baserun)</code></pre>
<pre><code>  round narrow wide
1  5.40   5.50 5.55
2  5.85   5.70 5.75
3  5.20   5.60 5.50
4  5.55   5.50 5.40
5  5.90   5.85 5.70
6  5.45   5.55 5.60</code></pre>
<p>There is a considerable “effect” for the player. Players who are
relatively fast/slow on one route tend to also be relatively fast/slow
on the other routes.</p>
<pre class="r"><code>p &lt;- ggplot(baserun, aes(x = round, y = narrow)) + theme_minimal()
p &lt;- p + geom_point() + xlim(4.9,6.3) + ylim(4.95,6.3)
p1 &lt;- p

p &lt;- ggplot(baserun, aes(x = round, y = wide)) + theme_minimal()
p &lt;- p + geom_point() + xlim(4.9,6.3) + ylim(4.95,6.3)
p2 &lt;- p

p &lt;- ggplot(baserun, aes(x = narrow, y = wide)) + theme_minimal()
p &lt;- p + geom_point() + xlim(4.9,6.3) + ylim(4.95,6.3)
p3 &lt;- p

cowplot::plot_grid(p1, p2, p3, align = &quot;h&quot;, ncol = 3)</code></pre>
<p><img src="lecture-04-22-2022_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" />
These data are in what is sometimes called “wide form” where there are
multiple observations per unit (player) in a single row. For plotting
and modeling it is often useful to “reshape” the data into “long form”
with one observation of the response variable (running time) per
row.</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
baselong &lt;- baserun %&gt;% mutate(player = factor(letters[1:n()])) %&gt;% 
  pivot_longer(cols = c(round, narrow, wide), 
    names_to = &quot;route&quot;, values_to = &quot;time&quot;)
head(baselong)</code></pre>
<pre><code># A tibble: 6 × 3
  player route   time
  &lt;fct&gt;  &lt;chr&gt;  &lt;dbl&gt;
1 a      round   5.4 
2 a      narrow  5.5 
3 a      wide    5.55
4 b      round   5.85
5 b      narrow  5.7 
6 b      wide    5.75</code></pre>
<pre class="r"><code>p &lt;- ggplot(baselong, aes(x = route, y = time)) +
  geom_line(aes(group = player), size = 0.25, alpha = 0.5) +
  geom_point() + theme_minimal() + 
  labs(x = &quot;Route Type&quot;, y = &quot;Time (sec)&quot;)
plot(p)</code></pre>
<p><img src="lecture-04-22-2022_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" />
Again note that there appears to be a “player effect” in that the
players show similar results over the routes.</p>
<p>What <em>could</em> we do (but not necessarily what we
<em>should</em> do) in modeling these data.</p>
<p>We could ignore the effect of player.</p>
<pre class="r"><code>m &lt;- lm(time ~ route, data = baselong)
summary(m)$coefficients</code></pre>
<pre><code>             Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)  5.534091    0.05718 96.7838 3.047e-70
routeround   0.009091    0.08086  0.1124 9.108e-01
routewide   -0.075000    0.08086 -0.9275 3.572e-01</code></pre>
<p>Or we could model the effect of player as a factor.</p>
<pre class="r"><code>m &lt;- lm(time ~ route + player, data = baselong)
summary(m)$coefficients</code></pre>
<pre><code>              Estimate Std. Error    t value  Pr(&gt;|t|)
(Intercept)  5.505e+00    0.05205  1.058e+02 1.320e-52
routeround   9.091e-03    0.02603  3.493e-01 7.286e-01
routewide   -7.500e-02    0.02603 -2.882e+00 6.208e-03
playerb      2.833e-01    0.07048  4.020e+00 2.366e-04
playerc     -5.000e-02    0.07048 -7.094e-01 4.820e-01
playerd      1.139e-15    0.07048  1.615e-14 1.000e+00
playere      3.333e-01    0.07048  4.729e+00 2.550e-05
playerf      5.000e-02    0.07048  7.094e-01 4.820e-01
playerg     -1.000e-01    0.07048 -1.419e+00 1.633e-01
playerh     -5.000e-02    0.07048 -7.094e-01 4.820e-01
playeri     -3.500e-01    0.07048 -4.966e+00 1.189e-05
playerj      3.000e-01    0.07048  4.256e+00 1.140e-04
playerk     -3.000e-01    0.07048 -4.256e+00 1.140e-04
playerl      6.667e-02    0.07048  9.459e-01 3.496e-01
playerm     -1.667e-02    0.07048 -2.365e-01 8.142e-01
playern     -4.833e-01    0.07048 -6.858e+00 2.323e-08
playero     -1.667e-02    0.07048 -2.365e-01 8.142e-01
playerp      1.667e-02    0.07048  2.365e-01 8.142e-01
playerq      8.406e-16    0.07048  1.193e-14 1.000e+00
playerr      1.667e-02    0.07048  2.365e-01 8.142e-01
players     -8.333e-02    0.07048 -1.182e+00 2.437e-01
playert      6.667e-02    0.07048  9.459e-01 3.496e-01
playeru      1.500e-01    0.07048  2.128e+00 3.923e-02
playerv      8.000e-01    0.07048  1.135e+01 2.238e-14</code></pre>
<p>Or maybe we could do something else?</p>
<p><strong>Example</strong>: Consider the following data from a
meta-analysis of 26 studies of the effect of nicotine gum on smoking
cessation.</p>
<pre class="r"><code>library(HSAUR3) # for the data
head(smoking)</code></pre>
<pre><code>             qt  tt qc  tc
Blondal89    37  92 24  90
Campbell91   21 107 21 105
Fagerstrom82 30  50 23  50
Fee82        23 180 15 172
Garcia89     21  68  5  38
Garvey00     75 405 17 203</code></pre>
<p>Here <code>qt</code> and <code>tc</code> are the total number of
subjects in the treatment and control groups, respectively, and
<code>tt</code> and <code>tc</code> are the total number of subjects in
the treatment and control groups, respectively.</p>
<p>These data require some rearranging prior to plotting and analysis.
(Note: I’m using <code>dplyr::select</code> rather than just
<code>select</code> because of a conflict with a function of the same
name with another package I have loaded.)</p>
<pre class="r"><code>library(dplyr)  
library(tidyr) 
quitsmoke &lt;- smoking
quitsmoke$study &lt;- rownames(quitsmoke)
quitsmoke.quits &lt;- quitsmoke %&gt;% dplyr::select(study, qt, qc) %&gt;% 
  rename(gum = qt, control = qc) %&gt;%
  pivot_longer(cols = c(gum,control), 
    names_to = &quot;treatment&quot;, values_to = &quot;quit&quot;)
head(quitsmoke.quits)</code></pre>
<pre><code># A tibble: 6 × 3
  study        treatment  quit
  &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;
1 Blondal89    gum          37
2 Blondal89    control      24
3 Campbell91   gum          21
4 Campbell91   control      21
5 Fagerstrom82 gum          30
6 Fagerstrom82 control      23</code></pre>
<pre class="r"><code>quitsmoke.total &lt;- quitsmoke %&gt;% dplyr::select(study, tt, tc) %&gt;% 
  rename(gum = tt, control = tc) %&gt;%
  pivot_longer(cols = c(gum,control), names_to = &quot;treatment&quot;, values_to = &quot;total&quot;)
head(quitsmoke.total)</code></pre>
<pre><code># A tibble: 6 × 3
  study        treatment total
  &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;
1 Blondal89    gum          92
2 Blondal89    control      90
3 Campbell91   gum         107
4 Campbell91   control     105
5 Fagerstrom82 gum          50
6 Fagerstrom82 control      50</code></pre>
<pre class="r"><code>quitsmoke &lt;- full_join(quitsmoke.quits, quitsmoke.total) %&gt;% mutate(study = factor(study)) %&gt;% arrange(study)
head(quitsmoke)</code></pre>
<pre><code># A tibble: 6 × 4
  study        treatment  quit total
  &lt;fct&gt;        &lt;chr&gt;     &lt;int&gt; &lt;int&gt;
1 Blondal89    gum          37    92
2 Blondal89    control      24    90
3 Campbell91   gum          21   107
4 Campbell91   control      21   105
5 Fagerstrom82 gum          30    50
6 Fagerstrom82 control      23    50</code></pre>
<pre class="r"><code>p &lt;- ggplot(quitsmoke, aes(x = study, y = quit/total, 
  size = total, fill = treatment)) + geom_point(pch = 21) + 
  coord_flip() + guides(size = &quot;none&quot;) +
  scale_fill_manual(values = c(&quot;White&quot;,&quot;Black&quot;)) + theme_minimal() + 
  labs(x = NULL, y = &quot;Proportion of Patients Quitting&quot;, 
    fill = &quot;Treatment:&quot;) + theme(legend.position = &quot;top&quot;)
plot(p)</code></pre>
<p><img src="lecture-04-22-2022_files/figure-html/unnamed-chunk-9-1.png" width="100%" style="display: block; margin: auto;" />
The studies may vary considerably in terms of (a) the proportion of
subjects that quit overall and (b) the effectiveness of the gum
treatment relative to the control condition.</p>
<p>What <em>could</em> we do (but not necessarily what we
<em>should</em> do) in modeling these data.</p>
<p>We could ignore the effect of study.</p>
<pre class="r"><code>m &lt;- glm(cbind(quit, total - quit) ~ treatment, 
  family = binomial, data = quitsmoke)
summary(m)$coefficients</code></pre>
<pre><code>             Estimate Std. Error z value   Pr(&gt;|z|)
(Intercept)   -1.4503    0.04901 -29.594 1.762e-192
treatmentgum   0.5071    0.06309   8.038  9.112e-16</code></pre>
<p>Or we could model the main effect of study.</p>
<pre class="r"><code>m &lt;- glm(cbind(quit, total - quit) ~ treatment + study, 
  family = binomial, data = quitsmoke)
summary(m)$coefficients</code></pre>
<pre><code>                  Estimate Std. Error z value  Pr(&gt;|z|)
(Intercept)       -0.95611    0.16223 -5.8935 3.782e-09
treatmentgum       0.51478    0.06571  7.8337 4.738e-15
studyCampbell91   -0.72182    0.23458 -3.0771 2.090e-03
studyFagerstrom82  0.82087    0.25660  3.1990 1.379e-03
studyFee82        -1.44471    0.23392 -6.1760 6.575e-10
studyGarcia89     -0.51371    0.27679 -1.8560 6.346e-02
studyGarvey00     -1.13119    0.19513 -5.7970 6.750e-09
studyGross95      -0.57476    0.23716 -2.4235 1.537e-02
studyHall85        0.11322    0.28635  0.3954 6.926e-01
studyHall87       -0.08874    0.24238 -0.3661 7.143e-01
studyHall96       -0.36356    0.22648 -1.6052 1.084e-01
studyHjalmarson84 -0.54554    0.23002 -2.3717 1.771e-02
studyHuber88       0.16466    0.25162  0.6544 5.128e-01
studyJarvis82     -0.32539    0.26384 -1.2333 2.175e-01
studyJensen91      0.18524    0.19887  0.9314 3.516e-01
studyKillen84     -0.05394    0.30863 -0.1748 8.613e-01
studyKillen90     -0.71634    0.17393 -4.1186 3.812e-05
studyMalcolm80    -2.28969    0.37670 -6.0784 1.214e-09
studyMcGovern92   -0.02349    0.20432 -0.1150 9.085e-01
studyNakamura90   -0.16186    0.32479 -0.4984 6.182e-01
studyNiaura94     -2.22602    0.37765 -5.8945 3.759e-09
studyPirie92      -0.15991    0.19132 -0.8358 4.033e-01
studyPuska79      -0.59867    0.22560 -2.6536 7.963e-03
studySchneider85  -0.41647    0.33913 -1.2281 2.194e-01
studyTonnesen88   -0.13127    0.25883 -0.5072 6.120e-01
studyVilla99       0.50932    0.33548  1.5182 1.290e-01
studyZelman92      0.08506    0.25163  0.3380 7.353e-01</code></pre>
<p>We could also model an interaction of the treatment with the
study.</p>
<pre class="r"><code>m &lt;- glm(cbind(quit, total - quit) ~ treatment * study, 
  family = binomial, data = quitsmoke)
summary(m)$coefficients</code></pre>
<pre><code>                                Estimate Std. Error   z value  Pr(&gt;|z|)
(Intercept)                    -1.011601     0.2384 -4.243904 2.197e-05
treatmentgum                    0.615186     0.3194  1.925966 5.411e-02
studyCampbell91                -0.374693     0.3411 -1.098520 2.720e-01
studyFagerstrom82               0.851258     0.3706  2.297064 2.162e-02
studyFee82                     -1.336595     0.3604 -3.709126 2.080e-04
studyGarcia89                  -0.875469     0.5358 -1.633834 1.023e-01
studyGarvey00                  -1.380932     0.3479 -3.969605 7.199e-05
studyGross95                   -0.885519     0.4985 -1.776429 7.566e-02
studyHall85                     0.056089     0.4419  0.126927 8.990e-01
studyHall87                    -0.338326     0.3831 -0.883128 3.772e-01
studyHall96                     0.026317     0.3254  0.080884 9.355e-01
studyHjalmarson84              -0.646627     0.3622 -1.785045 7.425e-02
studyHuber88                   -0.482324     0.4100 -1.176276 2.395e-01
studyJarvis82                  -0.682995     0.4340 -1.573798 1.155e-01
studyJensen91                   0.354821     0.3332  1.064752 2.870e-01
studyKillen84                   0.164303     0.5431  0.302551 7.622e-01
studyKillen90                  -0.494459     0.2602 -1.899981 5.744e-02
studyMalcolm80                 -2.660471     0.6314 -4.213818 2.511e-05
studyMcGovern92                 0.234572     0.3055  0.767904 4.425e-01
studyNakamura90                -0.597837     0.5448 -1.097331 2.725e-01
studyNiaura94                  -2.044756     0.5644 -3.622682 2.916e-04
studyPirie92                   -0.157780     0.2881 -0.547567 5.840e-01
studyPuska79                   -0.465665     0.3396 -1.371344 1.703e-01
studySchneider85               -0.374693     0.5149 -0.727661 4.668e-01
studyTonnesen88                -0.217065     0.4056 -0.535119 5.926e-01
studyVilla99                    0.541597     0.4683  1.156483 2.475e-01
studyZelman92                   0.213093     0.3706  0.574934 5.653e-01
treatmentgum:studyCampbell91   -0.638716     0.4699 -1.359285 1.741e-01
treatmentgum:studyFagerstrom82 -0.049378     0.5156 -0.095762 9.237e-01
treatmentgum:studyFee82        -0.187742     0.4742 -0.395873 6.922e-01
treatmentgum:studyGarcia89      0.466259     0.6334  0.736093 4.617e-01
treatmentgum:studyGarvey00      0.295743     0.4273  0.692111 4.889e-01
treatmentgum:studyGross95       0.349557     0.5756  0.607252 5.437e-01
treatmentgum:studyHall85        0.095203     0.5827  0.163387 8.702e-01
treatmentgum:studyHall87        0.422366     0.4997  0.845244 3.980e-01
treatmentgum:studyHall96       -0.755913     0.4542 -1.664447 9.602e-02
treatmentgum:studyHjalmarson84  0.159542     0.4712  0.338590 7.349e-01
treatmentgum:studyHuber88       1.177232     0.5377  2.189539 2.856e-02
treatmentgum:studyJarvis82      0.586934     0.5539  1.059684 2.893e-01
treatmentgum:studyJensen91     -0.254387     0.4191 -0.607000 5.439e-01
treatmentgum:studyKillen84     -0.327504     0.6621 -0.494666 6.208e-01
treatmentgum:studyKillen90     -0.404172     0.3504 -1.153314 2.488e-01
treatmentgum:studyMalcolm80     0.643954     0.7908  0.814266 4.155e-01
treatmentgum:studyMcGovern92   -0.460208     0.4107 -1.120609 2.625e-01
treatmentgum:studyNakamura90    0.725988     0.6912  1.050312 2.936e-01
treatmentgum:studyNiaura94     -0.318839     0.7592 -0.419943 6.745e-01
treatmentgum:studyPirie92      -0.003513     0.3863 -0.009096 9.927e-01
treatmentgum:studyPuska79      -0.236532     0.4544 -0.520520 6.027e-01
treatmentgum:studySchneider85  -0.076189     0.6849 -0.111241 9.114e-01
treatmentgum:studyTonnesen88    0.138056     0.5294  0.260782 7.943e-01
treatmentgum:studyVilla99      -0.049872     0.6749 -0.073900 9.411e-01
treatmentgum:studyZelman92     -0.236532     0.5046 -0.468741 6.393e-01</code></pre>
<p>Or maybe we could do something else?</p>
<p><strong>Example</strong>: Consider the following data from a study of
the growth of Sitka spruce trees under two experimental conditions.</p>
<pre class="r"><code>library(MASS)
head(Sitka, 10) # note that size is on log scale</code></pre>
<pre><code>   size Time tree treat
1  4.51  152    1 ozone
2  4.98  174    1 ozone
3  5.41  201    1 ozone
4  5.90  227    1 ozone
5  6.15  258    1 ozone
6  4.24  152    2 ozone
7  4.20  174    2 ozone
8  4.68  201    2 ozone
9  4.92  227    2 ozone
10 4.96  258    2 ozone</code></pre>
<pre class="r"><code>p &lt;- ggplot(Sitka, aes(x = Time, y = exp(size))) + 
  geom_line(aes(group = tree), alpha = 0.75, size = 0.1) + 
  facet_wrap(~ treat) + geom_point(size = 0.5) + 
  labs(y = &quot;Size (height times squared diameter)&quot;, 
    x = &quot;Days Since January 1, 1988&quot;) + theme_minimal()
plot(p)</code></pre>
<p><img src="lecture-04-22-2022_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" />
Note that trees vary considerably in terms of their growth
trajectories.</p>
<p>What <em>could</em> we do (but not necessarily what we
<em>should</em> do) in modeling these data.</p>
<p>We could ignore the effect of tree.</p>
<pre class="r"><code>m &lt;- lm(exp(size) ~ Time * treat, data = Sitka)
summary(m)$coefficients</code></pre>
<pre><code>                 Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)     -305.1231    52.7109  -5.789 1.458e-08
Time               2.5093     0.2561   9.799 2.029e-20
treatozone       110.6754    63.7554   1.736 8.336e-02
Time:treatozone   -0.7881     0.3097  -2.544 1.133e-02</code></pre>
<p>Or we could model the effect of tree.</p>
<pre class="r"><code>Sitka$tree &lt;- factor(Sitka$tree)
m &lt;- lm(exp(size) ~ Time * treat + Time * tree, data = Sitka)
summary(m)$coefficients</code></pre>
<pre><code>                  Estimate Std. Error   t value  Pr(&gt;|t|)
(Intercept)     -1.974e+02    48.0069  -4.11226 5.405e-05
Time             1.408e+00     0.2332   6.03958 5.931e-09
treatozone      -2.912e+02    67.8920  -4.28865 2.618e-05
tree2            4.279e+02    67.8920   6.30301 1.412e-09
tree3            3.970e+02    67.8920   5.84783 1.642e-08
tree4            3.780e+02    67.8920   5.56735 6.985e-08
tree5           -1.316e+02    67.8920  -1.93822 5.378e-02
tree6            1.408e+02    67.8920   2.07383 3.918e-02
tree7            3.721e+02    67.8920   5.48016 1.084e-07
tree8            2.970e+02    67.8920   4.37387 1.829e-05
tree9            6.928e-01    67.8920   0.01020 9.919e-01
tree10           4.328e+02    67.8920   6.37442 9.499e-10
tree11           3.807e+02    67.8920   5.60680 5.715e-08
tree12           2.502e+02    67.8920   3.68495 2.835e-04
tree13           2.475e+02    67.8920   3.64509 3.285e-04
tree14           3.652e+02    67.8920   5.37941 1.791e-07
tree15           5.513e+02    67.8920   8.11978 2.555e-14
tree16           3.864e+02    67.8920   5.69212 3.691e-08
tree17           3.966e+02    67.8920   5.84235 1.690e-08
tree18           4.356e+02    67.8920   6.41580 7.540e-10
tree19           4.143e+02    67.8920   6.10243 4.227e-09
tree20           3.509e+02    67.8920   5.16904 4.998e-07
tree21           3.698e+02    67.8920   5.44752 1.277e-07
tree22           3.207e+02    67.8920   4.72312 3.979e-06
tree23           2.703e+02    67.8920   3.98059 9.144e-05
tree24           4.809e+02    67.8920   7.08401 1.587e-11
tree25           2.202e+02    67.8920   3.24404 1.348e-03
tree26           3.694e+02    67.8920   5.44055 1.322e-07
tree27           2.629e+02    67.8920   3.87247 1.394e-04
tree28           3.235e+02    67.8920   4.76549 3.287e-06
tree29           4.926e+01    67.8920   0.72562 4.688e-01
tree30           2.900e+02    67.8920   4.27110 2.817e-05
tree31           3.625e+02    67.8920   5.33967 2.179e-07
tree32           3.192e+02    67.8920   4.70104 4.393e-06
tree33           3.228e+02    67.8920   4.75483 3.449e-06
tree34           3.562e+02    67.8920   5.24674 3.433e-07
tree35           1.630e+02    67.8920   2.40061 1.714e-02
tree36           4.550e+02    67.8920   6.70248 1.483e-10
tree37          -8.903e+01    67.8920  -1.31131 1.910e-01
tree38           1.929e+02    67.8920   2.84066 4.894e-03
tree39           1.368e+02    67.8920   2.01454 4.508e-02
tree40           3.077e+02    67.8920   4.53271 9.242e-06
tree41          -1.973e+02    67.8920  -2.90579 4.010e-03
tree42           3.191e+02    67.8920   4.70040 4.406e-06
tree43           2.338e+02    67.8920   3.44344 6.790e-04
tree44           3.063e+02    67.8920   4.51129 1.014e-05
tree45           4.260e+02    67.8920   6.27499 1.648e-09
tree46           2.801e+02    67.8920   4.12501 5.133e-05
tree47           3.289e+02    67.8920   4.84461 2.293e-06
tree48           3.643e+02    67.8920   5.36604 1.914e-07
tree49           4.055e+02    67.8920   5.97237 8.497e-09
tree50           3.933e+02    67.8920   5.79232 2.196e-08
tree51           3.517e+02    67.8920   5.18101 4.719e-07
tree52           2.664e+02    67.8920   3.92443 1.140e-04
tree53           4.724e+02    67.8920   6.95807 3.347e-11
tree54           3.553e+02    67.8920   5.23390 3.654e-07
tree55           1.225e+02    67.8920   1.80458 7.241e-02
tree56          -4.331e+02    67.8920  -6.37975 9.221e-10
tree57           8.878e+01    67.8920   1.30764 1.923e-01
tree58          -1.151e+02    67.8920  -1.69465 9.146e-02
tree59          -2.000e+02    67.8920  -2.94616 3.538e-03
tree60          -1.659e+02    67.8920  -2.44333 1.528e-02
tree61          -4.666e+02    67.8920  -6.87237 5.534e-11
tree62          -2.055e+01    67.8920  -0.30272 7.624e-01
tree63           1.116e+01    67.8920   0.16441 8.695e-01
tree64           1.743e+02    67.8920   2.56720 1.087e-02
tree65          -4.367e+01    67.8920  -0.64325 5.207e-01
tree66           8.094e+00    67.8920   0.11922 9.052e-01
tree67          -1.051e+02    67.8920  -1.54801 1.230e-01
tree68          -2.049e+02    67.8920  -3.01786 2.824e-03
tree69          -1.764e+02    67.8920  -2.59776 9.971e-03
tree70          -7.682e+01    67.8920  -1.13154 2.590e-01
tree71          -2.491e+02    67.8920  -3.66955 3.001e-04
tree72          -9.720e+01    67.8920  -1.43172 1.535e-01
tree73          -3.402e+02    67.8920  -5.01033 1.063e-06
tree74          -1.164e+02    67.8920  -1.71433 8.778e-02
tree75          -9.117e+01    67.8920  -1.34293 1.806e-01
tree76          -1.130e+01    67.8920  -0.16645 8.679e-01
tree77           1.336e+02    67.8920   1.96726 5.032e-02
tree78          -3.176e+02    67.8920  -4.67841 4.861e-06
Time:treatozone  2.284e+00     0.3298   6.92483 4.069e-11
Time:tree2      -2.875e+00     0.3298  -8.71844 5.009e-16
Time:tree3      -2.695e+00     0.3298  -8.17016 1.846e-14
Time:tree4      -2.382e+00     0.3298  -7.22182 6.948e-12
Time:tree5       7.245e-01     0.3298   2.19679 2.900e-02
Time:tree6      -7.954e-01     0.3298  -2.41183 1.663e-02
Time:tree7      -2.413e+00     0.3298  -7.31591 3.932e-12
Time:tree8      -1.984e+00     0.3298  -6.01477 6.775e-09
Time:tree9       2.843e-01     0.3298   0.86199 3.896e-01
Time:tree10     -2.976e+00     0.3298  -9.02271 6.442e-17
Time:tree11     -2.571e+00     0.3298  -7.79504 2.025e-13
Time:tree12     -1.596e+00     0.3298  -4.83862 2.356e-06
Time:tree13     -1.537e+00     0.3298  -4.66113 5.250e-06
Time:tree14     -2.270e+00     0.3298  -6.88393 5.172e-11
Time:tree15     -3.608e+00     0.3298 -10.93813 8.237e-23
Time:tree16     -2.719e+00     0.3298  -8.24443 1.140e-14
Time:tree17     -2.382e+00     0.3298  -7.22131 6.970e-12
Time:tree18     -3.216e+00     0.3298  -9.75136 4.171e-19
Time:tree19     -2.932e+00     0.3298  -8.88966 1.586e-16
Time:tree20     -2.249e+00     0.3298  -6.81802 7.598e-11
Time:tree21     -2.471e+00     0.3298  -7.49216 1.337e-12
Time:tree22     -2.335e+00     0.3298  -7.08091 1.616e-11
Time:tree23     -1.807e+00     0.3298  -5.47996 1.085e-07
Time:tree24     -3.526e+00     0.3298 -10.69227 4.959e-22
Time:tree25     -1.856e+00     0.3298  -5.62600 5.182e-08
Time:tree26     -2.744e+00     0.3298  -8.32071 6.939e-15
Time:tree27     -1.919e+00     0.3298  -5.81946 1.905e-08
Time:tree28     -2.034e+00     0.3298  -6.16742 2.971e-09
Time:tree29     -7.204e-02     0.3298  -0.21842 8.273e-01
Time:tree30     -1.418e+00     0.3298  -4.29893 2.508e-05
Time:tree31     -2.592e+00     0.3298  -7.85878 1.354e-13
Time:tree32     -2.065e+00     0.3298  -6.26045 1.785e-09
Time:tree33     -2.003e+00     0.3298  -6.07233 4.973e-09
Time:tree34     -2.406e+00     0.3298  -7.29509 4.461e-12
Time:tree35     -4.642e-01     0.3298  -1.40749 1.606e-01
Time:tree36     -3.141e+00     0.3298  -9.52223 2.072e-18
Time:tree37      1.177e+00     0.3298   3.56966 4.326e-04
Time:tree38     -1.310e+00     0.3298  -3.97191 9.462e-05
Time:tree39     -5.341e-01     0.3298  -1.61936 1.067e-01
Time:tree40     -2.079e+00     0.3298  -6.30474 1.398e-09
Time:tree41      1.636e+00     0.3298   4.96135 1.337e-06
Time:tree42     -2.073e+00     0.3298  -6.28455 1.563e-09
Time:tree43     -1.618e+00     0.3298  -4.90595 1.729e-06
Time:tree44     -2.231e+00     0.3298  -6.76407 1.039e-10
Time:tree45     -3.171e+00     0.3298  -9.61599 1.078e-18
Time:tree46     -1.813e+00     0.3298  -5.49839 9.895e-08
Time:tree47     -2.234e+00     0.3298  -6.77472 9.769e-11
Time:tree48     -2.715e+00     0.3298  -8.23303 1.228e-14
Time:tree49     -2.981e+00     0.3298  -9.03704 5.844e-17
Time:tree50     -2.937e+00     0.3298  -8.90612 1.419e-16
Time:tree51     -2.610e+00     0.3298  -7.91242 9.634e-14
Time:tree52     -2.001e+00     0.3298  -6.06620 5.140e-09
Time:tree53     -3.369e+00     0.3298 -10.21559 1.548e-20
Time:tree54     -2.536e+00     0.3298  -7.68847 3.954e-13
Time:tree55     -1.729e-01     0.3298  -0.52409 6.007e-01
Time:tree56      3.545e+00     0.3298  10.74990 3.260e-22
Time:tree57     -1.251e-01     0.3298  -0.37938 7.047e-01
Time:tree58      1.250e+00     0.3298   3.79115 1.903e-04
Time:tree59      1.411e+00     0.3298   4.27870 2.729e-05
Time:tree60      1.627e+00     0.3298   4.93380 1.519e-06
Time:tree61      4.085e+00     0.3298  12.38687 1.672e-27
Time:tree62      3.715e-01     0.3298   1.12633 2.612e-01
Time:tree63     -4.085e-02     0.3298  -0.12386 9.015e-01
Time:tree64     -1.181e+00     0.3298  -3.58083 4.155e-04
Time:tree65      4.166e-01     0.3298   1.26329 2.077e-01
Time:tree66      6.261e-03     0.3298   0.01898 9.849e-01
Time:tree67      1.716e+00     0.3298   5.20262 4.252e-07
Time:tree68      1.511e+00     0.3298   4.58163 7.462e-06
Time:tree69      1.501e+00     0.3298   4.55058 8.549e-06
Time:tree70      1.075e+00     0.3298   3.25801 1.286e-03
Time:tree71      2.398e+00     0.3298   7.27149 5.147e-12
Time:tree72      1.238e+00     0.3298   3.75322 2.196e-04
Time:tree73      3.602e+00     0.3298  10.92026 9.389e-23
Time:tree74      1.051e+00     0.3298   3.18550 1.639e-03
Time:tree75      6.025e-01     0.3298   1.82687 6.898e-02
Time:tree76      9.330e-02     0.3298   0.28289 7.775e-01
Time:tree77     -8.044e-01     0.3298  -2.43887 1.547e-02
Time:tree78      2.343e+00     0.3298   7.10522 1.398e-11</code></pre>
<p>Or maybe we could do something else?</p>
</div>
<div id="marginal-models-and-generalized-estimating-equations"
class="section level2">
<h2>Marginal Models and Generalized Estimating Equations</h2>
<p>A marginal model <em>ignores</em> the many-leveled factor. One
approach to estimating such models is to use what can be viewed as an
extension of quasi-likelihood called <em>generalized estimating
equations</em> (GEE). This approach actually involves two parts.</p>
<ol style="list-style-type: decimal">
<li><p>Estimate the model using generalized estimating equations. This
uses an iterative generalized least squares that uses an estimated
“working” correlation structure. This can be viewed as an extension of
the iteratively weighted least squares algorithm we used
earlier.</p></li>
<li><p>Compute <em>robust</em> estimates of standard errors to account
for heteroscedasticity and correlations among observations. These are
designed to deal with the fact that our observations are not
independent.</p></li>
</ol>
<p><strong>Example</strong>: Consider two approaches to the
<code>baserun</code> data: ignoring the player effect entirely and a
marginal model with inferences based on GEE.</p>
<pre class="r"><code>library(geepack)

# generalized linear model, but same as lm(time ~ route, data = baselong)
m.glm &lt;- glm(time ~ route, family = gaussian(link = identity), data = baselong)

# generalized estimating equations
m.gee &lt;- geeglm(time ~ route, family = gaussian(link = identity),
  id = player, corstr = &quot;exchangeable&quot;, data = baselong)</code></pre>
<p>Note: The data <em>must</em> be sorted by the <code>id</code>
variable, and the <code>id</code> variable must be a <em>factor</em> or
a <em>number</em> (not <em>character</em>).</p>
<p>Comparing inferences for the model parameters.</p>
<pre class="r"><code>summary(m.glm)$coefficients</code></pre>
<pre><code>             Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)  5.534091    0.05718 96.7838 3.047e-70
routeround   0.009091    0.08086  0.1124 9.108e-01
routewide   -0.075000    0.08086 -0.9275 3.572e-01</code></pre>
<pre class="r"><code>summary(m.gee)</code></pre>
<pre><code>
Call:
geeglm(formula = time ~ route, family = gaussian(link = identity), 
    data = baselong, id = player, corstr = &quot;exchangeable&quot;)

 Coefficients:
            Estimate  Std.err     Wald Pr(&gt;|W|)    
(Intercept)  5.53409  0.05411 10461.38  &lt; 2e-16 ***
routeround   0.00909  0.02564     0.13     0.72    
routewide   -0.07500  0.01839    16.63  4.6e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation structure = exchangeable 
Estimated Scale Parameters:

            Estimate Std.err
(Intercept)   0.0687  0.0278
  Link = identity 

Estimated Correlation Parameters:
      Estimate Std.err
alpha    0.896  0.0585
Number of clusters:   22  Maximum cluster size: 3 </code></pre>
<p>Comparing inferences for the expected time for each route.</p>
<pre class="r"><code>library(emmeans)

emmeans(m.glm, ~route)</code></pre>
<pre><code> route  emmean     SE df lower.CL upper.CL
 narrow   5.53 0.0572 63     5.42     5.65
 round    5.54 0.0572 63     5.43     5.66
 wide     5.46 0.0572 63     5.34     5.57

Confidence level used: 0.95 </code></pre>
<pre class="r"><code>emmeans(m.gee, ~route)</code></pre>
<pre><code> route  emmean     SE  df asymp.LCL asymp.UCL
 narrow   5.53 0.0541 Inf      5.43      5.64
 round    5.54 0.0566 Inf      5.43      5.65
 wide     5.46 0.0568 Inf      5.35      5.57

Covariance estimate used: vbeta 
Confidence level used: 0.95 </code></pre>
<pre class="r"><code>trtools::contrast(m.glm, a = list(route = c(&quot;narrow&quot;,&quot;round&quot;,&quot;wide&quot;)))</code></pre>
<pre><code> estimate     se lower upper tvalue df   pvalue
     5.53 0.0572  5.42  5.65   96.8 63 3.05e-70
     5.54 0.0572  5.43  5.66   96.9 63 2.75e-70
     5.46 0.0572  5.34  5.57   95.5 63 7.16e-70</code></pre>
<pre class="r"><code>trtools::contrast(m.gee, a = list(route = c(&quot;narrow&quot;,&quot;round&quot;,&quot;wide&quot;)))</code></pre>
<pre><code> estimate     se lower upper tvalue df   pvalue
     5.53 0.0541  5.43  5.64  102.3 63 9.59e-72
     5.54 0.0566  5.43  5.66   97.9 63 1.48e-70
     5.46 0.0568  5.35  5.57   96.1 63 4.88e-70</code></pre>
<p>Comparing inferences for the <em>differences</em> in expected time
between routes.</p>
<pre class="r"><code>pairs(emmeans(m.glm, ~route), adjust = &quot;none&quot;, infer = TRUE)</code></pre>
<pre><code> contrast       estimate     SE df lower.CL upper.CL t.ratio p.value
 narrow - round  -0.0091 0.0809 63  -0.1707    0.152  -0.112  0.9110
 narrow - wide    0.0750 0.0809 63  -0.0866    0.237   0.927  0.3570
 round - wide     0.0841 0.0809 63  -0.0775    0.246   1.040  0.3020

Confidence level used: 0.95 </code></pre>
<pre class="r"><code>pairs(emmeans(m.gee, ~route), adjust = &quot;none&quot;, infer = TRUE)</code></pre>
<pre><code> contrast       estimate     SE  df asymp.LCL asymp.UCL z.ratio p.value
 narrow - round  -0.0091 0.0256 Inf   -0.0593    0.0412  -0.350  0.7230
 narrow - wide    0.0750 0.0184 Inf    0.0389    0.1111   4.080  &lt;.0001
 round - wide     0.0841 0.0307 Inf    0.0239    0.1443   2.740  0.0060

Confidence level used: 0.95 </code></pre>
<pre class="r"><code>trtools::contrast(m.glm, 
  a = list(route = c(&quot;narrow&quot;,&quot;narrow&quot;,&quot;round&quot;)),
  b = list(route = c(&quot;round&quot;,&quot;wide&quot;,&quot;wide&quot;)),
  cnames = c(&quot;narrow - round&quot;,&quot;narrow - wide&quot;,&quot;round - wide&quot;))</code></pre>
<pre><code>               estimate     se   lower upper tvalue df pvalue
narrow - round -0.00909 0.0809 -0.1707 0.153 -0.112 63  0.911
narrow - wide   0.07500 0.0809 -0.0866 0.237  0.927 63  0.357
round - wide    0.08409 0.0809 -0.0775 0.246  1.040 63  0.302</code></pre>
<pre class="r"><code>trtools::contrast(m.gee, 
  a = list(route = c(&quot;narrow&quot;,&quot;narrow&quot;,&quot;round&quot;)),
  b = list(route = c(&quot;round&quot;,&quot;wide&quot;,&quot;wide&quot;)),
  cnames = c(&quot;narrow - round&quot;,&quot;narrow - wide&quot;,&quot;round - wide&quot;))</code></pre>
<pre><code>               estimate     se   lower  upper tvalue df  pvalue
narrow - round -0.00909 0.0256 -0.0603 0.0421 -0.355 63 0.72410
narrow - wide   0.07500 0.0184  0.0382 0.1118  4.077 63 0.00013
round - wide    0.08409 0.0307  0.0227 0.1455  2.737 63 0.00805</code></pre>
<p><strong>Example</strong>: Consider two approaches to the
<code>smoking</code> data: ignoring the study effect entirely and a
marginal model with inferences based on GEE.</p>
<pre class="r"><code>head(quitsmoke)</code></pre>
<pre><code># A tibble: 6 × 4
  study        treatment  quit total
  &lt;fct&gt;        &lt;chr&gt;     &lt;int&gt; &lt;int&gt;
1 Blondal89    gum          37    92
2 Blondal89    control      24    90
3 Campbell91   gum          21   107
4 Campbell91   control      21   105
5 Fagerstrom82 gum          30    50
6 Fagerstrom82 control      23    50</code></pre>
<pre class="r"><code>m.glm &lt;- glm(cbind(quit, total - quit) ~ treatment,
  family = binomial, data = quitsmoke)
m.gee &lt;- geeglm(cbind(quit, total - quit) ~ treatment, 
  family = binomial, data = quitsmoke,
  id = study, corstr = &quot;exchangeable&quot;)</code></pre>
<p>Comparing inferences for the model parameters.</p>
<pre class="r"><code>summary(m.glm)$coefficients</code></pre>
<pre><code>             Estimate Std. Error z value  Pr(&gt;|z|)
(Intercept)    -1.450     0.0490  -29.59 1.76e-192
treatmentgum    0.507     0.0631    8.04  9.11e-16</code></pre>
<pre class="r"><code>summary(m.gee)</code></pre>
<pre><code>
Call:
geeglm(formula = cbind(quit, total - quit) ~ treatment, family = binomial, 
    data = quitsmoke, id = study, corstr = &quot;exchangeable&quot;)

 Coefficients:
             Estimate Std.err  Wald Pr(&gt;|W|)    
(Intercept)    -1.444   0.116 155.5  &lt; 2e-16 ***
treatmentgum    0.501   0.078  41.2  1.4e-10 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation structure = exchangeable 
Estimated Scale Parameters:

            Estimate Std.err
(Intercept)   0.0601  0.0158
  Link = identity 

Estimated Correlation Parameters:
      Estimate Std.err
alpha    0.445   0.229
Number of clusters:   26  Maximum cluster size: 2 </code></pre>
<p>Estimating the probability of quitting.</p>
<pre class="r"><code>emmeans(m.glm, ~treatment, type = &quot;response&quot;)</code></pre>
<pre><code> treatment prob      SE  df asymp.LCL asymp.UCL
 control   0.19 0.00754 Inf     0.176     0.205
 gum       0.28 0.00801 Inf     0.265     0.296

Confidence level used: 0.95 
Intervals are back-transformed from the logit scale </code></pre>
<pre class="r"><code>emmeans(m.gee, ~treatment, type = &quot;response&quot;)</code></pre>
<pre><code> treatment  prob     SE  df asymp.LCL asymp.UCL
 control   0.191 0.0179 Inf     0.158     0.229
 gum       0.280 0.0255 Inf     0.233     0.333

Covariance estimate used: vbeta 
Confidence level used: 0.95 
Intervals are back-transformed from the logit scale </code></pre>
<pre class="r"><code>trtools::contrast(m.glm, a = list(treatment = c(&quot;control&quot;,&quot;gum&quot;)),
  tf = plogis, cnames = c(&quot;control&quot;,&quot;gum&quot;))</code></pre>
<pre><code>        estimate lower upper
control     0.19 0.176 0.205
gum         0.28 0.265 0.296</code></pre>
<pre class="r"><code>trtools::contrast(m.gee, a = list(treatment = c(&quot;control&quot;,&quot;gum&quot;)),
  tf = plogis, cnames = c(&quot;control&quot;,&quot;gum&quot;))</code></pre>
<pre><code>        estimate lower upper
control    0.191 0.158 0.229
gum        0.280 0.233 0.333</code></pre>
<p>Estimating the odds ratio for the effect of the gum treatment.</p>
<pre class="r"><code>pairs(emmeans(m.glm, ~treatment, type = &quot;response&quot;), 
  reverse = TRUE, infer = TRUE)</code></pre>
<pre><code> contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 gum / control       1.66 0.105 Inf      1.47      1.88    1   8.040  &lt;.0001

Confidence level used: 0.95 
Intervals are back-transformed from the log odds ratio scale 
Tests are performed on the log odds ratio scale </code></pre>
<pre class="r"><code>pairs(emmeans(m.gee, ~treatment, type = &quot;response&quot;), 
  reverse = TRUE, infer = TRUE)</code></pre>
<pre><code> contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 gum / control       1.65 0.129 Inf      1.42      1.92    1   6.420  &lt;.0001

Confidence level used: 0.95 
Intervals are back-transformed from the log odds ratio scale 
Tests are performed on the log odds ratio scale </code></pre>
<pre class="r"><code>trtools::contrast(m.glm, tf = exp,
  a = list(treatment = &quot;gum&quot;),
  b = list(treatment = &quot;control&quot;))</code></pre>
<pre><code> estimate lower upper
     1.66  1.47  1.88</code></pre>
<pre class="r"><code>trtools::contrast(m.gee, tf = exp,
  a = list(treatment = &quot;gum&quot;),
  b = list(treatment = &quot;control&quot;))</code></pre>
<pre><code> estimate lower upper
     1.65  1.42  1.92</code></pre>
<p><strong>Example</strong>: Consider two approaches to the
<code>Sitka</code> data.</p>
<pre class="r"><code>m.glm &lt;- glm(exp(size) ~ Time * treat,
  family = gaussian(link = identity), data = Sitka)
m.gee &lt;- geeglm(exp(size) ~ Time * treat, 
  family = gaussian(link = identity), data = Sitka,
  id = tree, corstr = &quot;exchangeable&quot;)</code></pre>
<p>Comparing inferences for the model parameters.</p>
<pre class="r"><code>summary(m.glm)$coefficients</code></pre>
<pre><code>                Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)     -305.123     52.711   -5.79 1.46e-08
Time               2.509      0.256    9.80 2.03e-20
treatozone       110.675     63.755    1.74 8.34e-02
Time:treatozone   -0.788      0.310   -2.54 1.13e-02</code></pre>
<pre class="r"><code>summary(m.gee)</code></pre>
<pre><code>
Call:
geeglm(formula = exp(size) ~ Time * treat, family = gaussian(link = identity), 
    data = Sitka, id = tree, corstr = &quot;exchangeable&quot;)

 Coefficients:
                Estimate  Std.err  Wald Pr(&gt;|W|)    
(Intercept)     -305.123   32.737 86.87   &lt;2e-16 ***
Time               2.509    0.264 90.62   &lt;2e-16 ***
treatozone       110.675   38.775  8.15   0.0043 ** 
Time:treatozone   -0.788    0.306  6.62   0.0101 *  
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation structure = exchangeable 
Estimated Scale Parameters:

            Estimate Std.err
(Intercept)    11432    2036
  Link = identity 

Estimated Correlation Parameters:
      Estimate Std.err
alpha    0.752  0.0189
Number of clusters:   79  Maximum cluster size: 5 </code></pre>
<p>Estimating the growth rate in each treatment condition.</p>
<pre class="r"><code>trtools::contrast(m.glm,
  a = list(Time = 250, treat = c(&quot;control&quot;,&quot;ozone&quot;)),
  b = list(Time = 150, treat = c(&quot;control&quot;,&quot;ozone&quot;)),
  cnames = c(&quot;control&quot;,&quot;ozone&quot;))</code></pre>
<pre><code>        estimate   se lower upper tvalue  df   pvalue
control      251 25.6   201   301   9.80 391 2.03e-20
ozone        172 17.4   138   206   9.88 391 1.08e-20</code></pre>
<pre class="r"><code>trtools::contrast(m.gee,
  a = list(Time = 250, treat = c(&quot;control&quot;,&quot;ozone&quot;)),
  b = list(Time = 150, treat = c(&quot;control&quot;,&quot;ozone&quot;)),
  cnames = c(&quot;control&quot;,&quot;ozone&quot;))</code></pre>
<pre><code>        estimate   se lower upper tvalue  df   pvalue
control      251 26.4   199   303   9.52 391 1.84e-19
ozone        172 15.6   141   203  11.03 391 8.23e-25</code></pre>
<pre class="r"><code># Note: We can estimate the growth rates (per day) 
# using emtrends from the emmeans package.
emtrends(m.glm, ~ treat, var = &quot;Time&quot;)</code></pre>
<pre><code> treat   Time.trend    SE  df lower.CL upper.CL
 control       2.51 0.256 391     2.01     3.01
 ozone         1.72 0.174 391     1.38     2.06

Confidence level used: 0.95 </code></pre>
<pre class="r"><code>emtrends(m.gee, ~ treat, var = &quot;Time&quot;)</code></pre>
<pre><code> treat   Time.trend    SE  df asymp.LCL asymp.UCL
 control       2.51 0.264 Inf      1.99      3.03
 ozone         1.72 0.156 Inf      1.42      2.03

Covariance estimate used: vbeta 
Confidence level used: 0.95 </code></pre>
<p>Comparing the growth rates between the treatment conditions.</p>
<pre class="r"><code>trtools::contrast(m.glm,
  a = list(Time = 250, treat = &quot;control&quot;),
  b = list(Time = 150, treat = &quot;control&quot;),
  u = list(Time = 250, treat = &quot;ozone&quot;),
  v = list(Time = 150, treat = &quot;ozone&quot;))</code></pre>
<pre><code> estimate se lower upper tvalue  df pvalue
     78.8 31  17.9   140   2.54 391 0.0113</code></pre>
<pre class="r"><code>trtools::contrast(m.gee,
  a = list(Time = 250, treat = &quot;control&quot;),
  b = list(Time = 150, treat = &quot;control&quot;),
  u = list(Time = 250, treat = &quot;ozone&quot;),
  v = list(Time = 150, treat = &quot;ozone&quot;))</code></pre>
<pre><code> estimate   se lower upper tvalue  df pvalue
     78.8 30.6  18.6   139   2.57 391 0.0105</code></pre>
<pre class="r"><code>pairs(emtrends(m.glm, ~ treat, var = &quot;Time&quot;))</code></pre>
<pre><code> contrast        estimate   SE  df t.ratio p.value
 control - ozone    0.788 0.31 391   2.544  0.0113</code></pre>
<pre class="r"><code>pairs(emtrends(m.gee, ~ treat, var = &quot;Time&quot;))</code></pre>
<pre><code> contrast        estimate    SE  df z.ratio p.value
 control - ozone    0.788 0.306 Inf   2.573  0.0101</code></pre>
</div>
<div id="limitations-of-marginal-models-and-gee" class="section level2">
<h2>Limitations of Marginal Models and GEE</h2>
<ol style="list-style-type: decimal">
<li><p>Performs best when the data are relatively “shallow” meaning that
there are many units (e.g., players, studies, or trees) but relatively
few observations per unit (e.g., routes, treatment conditions, time
points).</p></li>
<li><p>Difficult to use with “unbalanced” data where not every unit is
observed at the same “points” (e.g., routes, treatments, time
points).</p></li>
<li><p>Inefficient if the (working) correlation structure is a poor
approximation.</p></li>
<li><p>Limited to “marginal inferences” in that it cannot tell us much
about the variation among units (in contrast to models with “random
effects” which we will discuss later).</p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
