<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Friday, Feb 24</title>

<script src="site_libs/header-attrs-2.20/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics 436/516</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="lectures.html">Lectures</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Friday, Feb 24</h1>

</div>


<p>You can also download a <a href="lecture-02-24-2023.pdf">PDF</a> copy
of this lecture.</p>
<div id="the-michaelis-menten-model" class="section level2">
<h2>The Michaelis-Menten Model</h2>
<p>The Michaelis-Menten model is perhaps the quintessential example of
an application of nonlinear regression. It is from biochemistry and
concerns the relationship between the (expected) rate of an enzymatic
reaction to the concentration of an enzymatic substrate (i.e., the
material of the reaction). As a nonlinear regression model the
Michaelis-Menten model can be written as <span class="math display">\[
  E(R) = \frac{\alpha s}{\lambda + s},
\]</span> where <span class="math inline">\(Y\)</span> is the reaction
rate and <span class="math inline">\(x\)</span> is the substrate
concentration.<a href="#fn1" class="footnote-ref"
id="fnref1"><sup>1</sup></a></p>
<p>The two parameters of this model, <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\lambda\)</span>, are interpretable in terms of
the relationship between the expected reaction rate and substrate
concentration. The <span class="math inline">\(\alpha\)</span> parameter
is the maximum expected reaction rate (i.e., the upper asymptote as
<span class="math inline">\(s \rightarrow \infty\)</span>), and <span
class="math inline">\(\lambda\)</span> is the value of <span
class="math inline">\(x\)</span> at which the reaction rate is half of
<span class="math inline">\(\alpha\)</span> (i.e., a “half-life”
parameter) so smaller values of <span
class="math inline">\(\lambda\)</span> mean that the curve is
approaching <span class="math inline">\(\alpha\)</span> “faster” as
<span class="math inline">\(s\)</span> increases.<a href="#fn2"
class="footnote-ref" id="fnref2"><sup>2</sup></a> Note also that if
<span class="math inline">\(s = 0\)</span> then <span
class="math inline">\(E(R) = 0\)</span> so the curve is constrained to
have an “intercept” of zero, which makes sense in the context of enzyme
kinetics. The plot below shows an example of the model where <span
class="math inline">\(\alpha\)</span> = 300 and <span
class="math inline">\(\lambda\)</span> = 0.5.
<img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-2-1.png" width="100%" style="display: block; margin: auto;" />
To estimate <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\lambda\)</span> the typical method is to conduct
a series of assays, varying substrate concentration and recording the
reaction rate at each concentration, and then using nonlinear regression
to estimate <span class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\lambda\)</span>. In the following problems you
will be using data in the data frame <code>Puromycin</code>. It is
included with R so there is no package to load. These data are from a
study that observed reaction rates at several substrate concentrations,
but also for cells that were treated with puromycin (an antibiotic).
Before starting you can familiarize yourself with the data by simply
typing <code>Puromycin</code> at the console prompt (it is not a large
data set).</p>
<ol style="list-style-type: decimal">
<li><p>To get started we will first ignore the experimental manipulation
of treated cells with puromycin. The R code below will estimate the
<em>linear</em> model <span class="math inline">\(E(R_i) = \beta_0 +
\beta_1 s_i\)</span> using <code>nls</code> and plot this model with the
data.</p>
<pre class="r"><code>library(ggplot2)
m &lt;- nls(rate ~ b0 + b1 * conc, start = c(b0 = 0, b1 = 0), data = Puromycin)

d &lt;- expand.grid(conc = seq(0, 1.2, length = 100), state = c(&quot;treated&quot;,&quot;untreated&quot;))
d$yhat &lt;- predict(m, newdata = d)

p &lt;- ggplot(Puromycin, aes(x = conc, y = rate)) + 
  geom_point(aes(color = state)) + geom_line(aes(y = yhat), data = d) + 
  labs(x = &quot;Substrate Concentration (ppm)&quot;, 
    y = &quot;Reaction Rate (counts/min)&quot;, color = &quot;Cell State&quot;) + 
  theme_minimal() + theme(legend.position = c(0.8,0.2))
plot(p)</code></pre>
<p><img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-3-1.png" width="100%" style="display: block; margin: auto;" />
Clearly the linear model is not a good model for the data. Cut-and-paste
the R code above and modify it to replace the linear model with the
Michaelis-Menten model (ignoring the experimental manipulation for now).
To specify starting values for <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\lambda\)</span>, look at the plot of the data and
try to guess their approximate values. Remember that <span
class="math inline">\(\alpha\)</span> is the asymptote and <span
class="math inline">\(\lambda\)</span> is the concentration at which the
(expected) reaction rate is half way between zero and the asymptote.</p>
<p><strong>Solution</strong>: We might estimate the nonlinear model as
follows, using the figure to guess starting values for <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\lambda\)</span>.</p>
<pre class="r"><code>m &lt;- nls(rate ~ alpha * conc / (lambda + conc), data = Puromycin,
  start = list(alpha = 200, lambda = 0.1))
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>        Estimate Std. Error t value  Pr(&gt;|t|)      2.5%     97.5%
alpha  190.80620    8.76458  21.770 6.835e-16 172.68402 210.97021
lambda   0.06039    0.01077   5.608 1.449e-05   0.03981   0.08881</code></pre>
<p>We can plot the model as follows by “adding” to the code above.</p>
<pre class="r"><code>d &lt;- data.frame(conc = seq(0, 1.2, length = 100))
d$yhat &lt;- predict(m, newdata = d)
p &lt;- p + geom_line(aes(y = yhat), data = d, linetype = 2)
plot(p)</code></pre>
<p><img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /></p></li>
<li><p>Now consider a linear model that will assume a linear
relationship between reaction rate and concentration that is different
for treated versus untreated cells (i.e., an “interaction” between
substrate concentration and cell state).</p>
<pre class="r"><code>m &lt;- lm(rate ~ state + conc + conc:state, data = Puromycin)
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>                    Estimate Std. Error t value  Pr(&gt;|t|)  2.5 % 97.5 %
(Intercept)           103.49      10.53   9.832 6.914e-09  81.46 125.52
stateuntreated        -17.45      15.06  -1.158 2.611e-01 -48.98  14.08
conc                  110.42      20.46   5.397 3.301e-05  67.60 153.24
stateuntreated:conc   -21.08      32.69  -0.645 5.266e-01 -89.50  47.33</code></pre>
<p>From <code>summary</code> we can see that the model can be written as
<span class="math display">\[
E(R_i) = \beta_0 + \beta_1 u_i + \beta_2 s_i + \beta_3 u_i s_i,
\]</span> where <span class="math inline">\(s_i\)</span> represents
concentration (<code>conc</code>) and <span
class="math inline">\(u_i\)</span> is an indicator variable for when the
treatment (<code>state</code>) is “untreated” so that <span
class="math display">\[
  u_i =
  \begin{cases}
1, &amp; \text{if the $i$-th observation is of untreated cells}, \\
0, &amp; \text{otherwise}.
  \end{cases}
\]</span> This model can be written case-wise as <span
class="math display">\[
E(R_i) =
\begin{cases}
  \beta_0 + \beta_2 s_i, &amp; \text{if the $i$-th observation is of
treated cells,} \\
  \beta_0 + \beta_1 + (\beta_2 + \beta_3) s_i,&amp; \text{if the $i$-th
observation is of untreated cells.}
\end{cases}
\]</span> We can replicate this model using the <code>nls</code>
function by specifying an indicator variable in the model formula.</p>
<pre class="r"><code>m &lt;- nls(rate ~ b0 + b1*(state == &quot;untreated&quot;) + 
  b2*conc + b3*(state == &quot;untreated&quot;)*conc,
  data = Puromycin, start = list(b0 = 0, b1 = 0, b2 = 0, b3 = 0))
summary(m)$coefficients</code></pre>
<pre><code>   Estimate Std. Error t value  Pr(&gt;|t|)
b0   103.49      10.53   9.832 6.914e-09
b1   -17.45      15.06  -1.158 2.611e-01
b2   110.42      20.46   5.397 3.301e-05
b3   -21.08      32.69  -0.645 5.266e-01</code></pre>
<pre class="r"><code>d &lt;- expand.grid(conc = seq(0, 1.2, length = 100), state = c(&quot;treated&quot;,&quot;untreated&quot;))
d$yhat &lt;- predict(m, newdata = d)

p &lt;- ggplot(Puromycin, aes(x = conc, y = rate, color = state)) + 
  geom_point() + geom_line(aes(y = yhat), data = d) + 
  labs(x = &quot;Substrate Concentration (ppm)&quot;,
    y = &quot;Reaction Rate (counts/min)&quot;, color = &quot;Cell State&quot;) + 
  theme_minimal() + theme(legend.position = c(0.8,0.2))
plot(p)</code></pre>
<p><img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-7-1.png" width="100%" style="display: block; margin: auto;" />
Since there are only two levels of <code>state</code> we could also use
the <code>ifelse</code> function to produce the same results as using
the indicator variable.</p>
<pre class="r"><code>m &lt;- nls(rate ~ ifelse(state == &quot;treated&quot;, b0 + b2*conc, b0 + b1 + (b2 + b3)*conc),
  data = Puromycin, start = list(b0 = 0, b1 = 0, b2 = 0, b3 = 0))
summary(m)$coefficients</code></pre>
<pre><code>   Estimate Std. Error t value  Pr(&gt;|t|)
b0   103.49      10.53   9.832 6.914e-09
b1   -17.45      15.06  -1.158 2.611e-01
b2   110.42      20.46   5.397 3.301e-05
b3   -21.08      32.69  -0.645 5.266e-01</code></pre>
<p>We can also use the <code>case_when</code> function from the
<strong>dplyr</strong> package.</p>
<pre class="r"><code>library(dplyr)
m &lt;- nls(rate ~ case_when(
  state == &quot;treated&quot; ~ b0 + b2*conc, 
  state == &quot;untreated&quot; ~ b0 + b1 + (b2 + b3)*conc,
), data = Puromycin, start = list(b0 = 0, b1 = 0, b2 = 0, b3 = 0))
summary(m)$coefficients</code></pre>
<pre><code>   Estimate Std. Error t value  Pr(&gt;|t|)
b0   103.49      10.53   9.832 6.914e-09
b1   -17.45      15.06  -1.158 2.611e-01
b2   110.42      20.46   5.397 3.301e-05
b3   -21.08      32.69  -0.645 5.266e-01</code></pre>
<p>Obviously this is a poor model for the <code>Puromycin</code> data
since expected reaction rate does not appear to be a linear function of
substrate concentration. Instead we would like to have a model where
there the Michaelis-Menten model describes the relationship between the
expected reaction rate and substrate concentration, but <em>differently
for each state</em> so that the <span
class="math inline">\(\alpha\)</span> and <span
class="math inline">\(\lambda\)</span> parameters can depend on the
state. Estimate this model using the <code>nls</code> function, noting
that there are many different ways that this model could be
parameterized. Plot the model as well with the raw data.</p>
<p><strong>Solution</strong>: Here is one way we might specify such a
model.</p>
<pre class="r"><code>m1 &lt;- nls(rate ~ ifelse(state == &quot;treated&quot;, alphat * conc / (lambdat + conc),
  alphau * conc / (lambdau + conc)), data = Puromycin,
  start = list(alphat = 200, lambdat = 0.1, alphau = 200, lambdau = 0.1))
cbind(summary(m1)$coefficients, confint(m1))</code></pre>
<pre><code>         Estimate Std. Error t value  Pr(&gt;|t|)      2.5%     97.5%
alphat  212.68373   6.608094  32.185 4.876e-18 198.88883 227.45563
lambdat   0.06412   0.007877   8.141 1.293e-07   0.04856   0.08354
alphau  160.28001   6.896011  23.242 2.041e-15 145.85285 176.28021
lambdau   0.04771   0.008281   5.761 1.496e-05   0.03159   0.06966</code></pre>
<p>This model can be written as <span class="math display">\[
E(Y_i) =
   \begin{cases}
   \alpha_t s_i/(\lambda_t + s_i), &amp; \text{if the $i$-th observation
is of treated cells}, \\
   \alpha_u s_i/(\lambda_u + s_i), &amp; \text{if the $i$-th observation
is of untreated cells}.
   \end{cases}
\]</span> An alternative paramterization that includes a parameter for
the “effect” of treating the cells is <span class="math display">\[
E(Y_i) =
   \begin{cases}
   (\alpha + \delta_{\alpha})s_i/(\lambda + \delta_{\lambda} + s_i),
&amp; \text{if the $i$-th observation is of treated cells}, \\
   \alpha s_i/(\lambda + s_i), &amp; \text{if the $i$-th observation is
of untreated cells}.
   \end{cases}
\]</span> Note that we can establish a relationship between the
parameters in the two models: <span class="math inline">\(\alpha =
\alpha_u\)</span>, <span class="math inline">\(\lambda =
\lambda_u\)</span>, <span class="math inline">\(\delta_{\alpha} =
\alpha_t - \alpha_u\)</span> and <span
class="math inline">\(\delta_{\lambda} = \lambda_t - \lambda_u\)</span>.
This latter model can be estimated as follows.</p>
<pre class="r"><code>m2 &lt;- nls(rate ~ ifelse(state == &quot;treated&quot;,
  (alpha + deltaa) * conc / (lambda + deltal + conc),
  alpha * conc / (lambda + conc)), data = Puromycin,
  start = list(alpha = 200, lambda = 0.1, deltaa = 0, deltal = 0))
cbind(summary(m2)$coefficients, confint(m2))</code></pre>
<pre><code>        Estimate Std. Error t value  Pr(&gt;|t|)      2.5%     97.5%
alpha  160.28001   6.896011  23.242 2.041e-15 145.85285 176.28021
lambda   0.04771   0.008281   5.761 1.496e-05   0.03159   0.06966
deltaa  52.40373   9.551014   5.487 2.713e-05  31.33677  73.09295
deltal   0.01641   0.011429   1.436 1.672e-01  -0.01043   0.04187</code></pre>
<p>There are several other ways we might parameterize the model and
specify it in <code>nls</code>. But for plotting purposes the
parameterization does not matter.</p>
<pre class="r"><code>d &lt;- expand.grid(conc = seq(0, 1.2, length = 100), state = c(&quot;treated&quot;,&quot;untreated&quot;))
d$yhat &lt;- predict(m1, newdata = d)

p &lt;- ggplot(Puromycin, aes(x = conc, y = rate, color = state)) +
  geom_point() + geom_line(aes(y = yhat), data = d) +
  labs(x = &quot;Substrate Concentration (ppm)&quot;,
    y = &quot;Reaction Rate (counts/min)&quot;) +
  labs(color = &quot;Cell State&quot;) +
  theme_minimal() + theme(legend.position = c(0.8,0.2))
plot(p)</code></pre>
<p><img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-12-1.png" width="100%" style="display: block; margin: auto;" /></p></li>
<li><p>There are several potentially useful inferences we might make
here. One is the values of the two parameters for the Michaelis-Menten
model <em>for each state</em>. Another is the difference in the
parameters <em>between states</em>. Depending on how the model was
parameterized in the previous question, some of these could be found
simply by using <code>summary</code> and <code>confint</code>, while
others might require using <code>lincon</code> unless the model is
reparameterized. Produce estimates, standard errors, and confidence
intervals for the six quantities described above.</p>
<p><strong>Solution</strong>: First consider inferences for the two
parameters of the Micahelis-Menten model for each treatment condition.
These are the parameters of the first parameterization used above.</p>
<pre class="r"><code>cbind(summary(m1)$coefficients, confint(m1))</code></pre>
<pre><code>         Estimate Std. Error t value  Pr(&gt;|t|)      2.5%     97.5%
alphat  212.68373   6.608094  32.185 4.876e-18 198.88883 227.45563
lambdat   0.06412   0.007877   8.141 1.293e-07   0.04856   0.08354
alphau  160.28001   6.896011  23.242 2.041e-15 145.85285 176.28021
lambdau   0.04771   0.008281   5.761 1.496e-05   0.03159   0.06966</code></pre>
<p>If we were using the second parameterization, we could obtain
estimates of the parameters from the untreated cells from
<code>summary</code> and <code>confint</code>, but would have to use
something like <code>lincon</code> to to estimate a function of the
model parameters. Recall the relationships between the parameters in the
two models: <span class="math inline">\(\alpha = \alpha_u\)</span>,
<span class="math inline">\(\lambda = \lambda_u\)</span>, <span
class="math inline">\(\delta_{\alpha} = \alpha_t - \alpha_u\)</span> and
<span class="math inline">\(\delta_{\lambda} = \lambda_t -
\lambda_u\)</span>. Thus <span class="math inline">\(\alpha_t = \alpha +
\delta_{\alpha}\)</span> and <span class="math inline">\(\lambda_t =
\lambda + \delta_{\lambda}\)</span>.</p>
<pre class="r"><code>library(trtools)
cbind(summary(m2)$coefficients, confint(m2))</code></pre>
<pre><code>        Estimate Std. Error t value  Pr(&gt;|t|)      2.5%     97.5%
alpha  160.28001   6.896011  23.242 2.041e-15 145.85285 176.28021
lambda   0.04771   0.008281   5.761 1.496e-05   0.03159   0.06966
deltaa  52.40373   9.551014   5.487 2.713e-05  31.33677  73.09295
deltal   0.01641   0.011429   1.436 1.672e-01  -0.01043   0.04187</code></pre>
<pre class="r"><code>lincon(m2, a = c(1, 0, 1, 0)) # lambdat  </code></pre>
<pre><code>            estimate    se lower upper tvalue df    pvalue
(1,0,1,0),0    212.7 6.608 198.9 226.5  32.19 19 4.876e-18</code></pre>
<pre class="r"><code>lincon(m2, a = c(0, 1, 0, 1)) # lambdat </code></pre>
<pre><code>            estimate       se   lower   upper tvalue df    pvalue
(0,1,0,1),0  0.06412 0.007877 0.04763 0.08061  8.141 19 1.293e-07</code></pre>
<p>Now if we want to estimate the difference in the parameters of the
Michaelis-Menten model between the treated and untreated states, we
could get that from the second parameterization because those
differences are <span class="math inline">\(\delta_{\alpha}\)</span> and
<span class="math inline">\(\delta_{\lambda}\)</span>.</p>
<pre class="r"><code>cbind(summary(m2)$coefficients, confint(m2))</code></pre>
<pre><code>        Estimate Std. Error t value  Pr(&gt;|t|)      2.5%     97.5%
alpha  160.28001   6.896011  23.242 2.041e-15 145.85285 176.28021
lambda   0.04771   0.008281   5.761 1.496e-05   0.03159   0.06966
deltaa  52.40373   9.551014   5.487 2.713e-05  31.33677  73.09295
deltal   0.01641   0.011429   1.436 1.672e-01  -0.01043   0.04187</code></pre>
<p>But if we were using the first parameterization we would again need
to use something like <code>lincon</code> since <span
class="math inline">\(\delta_{\alpha} = \alpha_t - \alpha_u\)</span> and
<span class="math inline">\(\delta_{\lambda} = \lambda_t -
\lambda_u\)</span>.</p>
<pre class="r"><code>lincon(m1, a = c(1,0,-1,0)) # delta_alpha</code></pre>
<pre><code>             estimate    se lower upper tvalue df    pvalue
(1,0,-1,0),0     52.4 9.551 32.41 72.39  5.487 19 2.713e-05</code></pre>
<pre class="r"><code>lincon(m1, a = c(0,1,0,-1)) # delta_lambda</code></pre>
<pre><code>             estimate      se     lower   upper tvalue df pvalue
(0,1,0,-1),0  0.01641 0.01143 -0.007508 0.04033  1.436 19 0.1672</code></pre>
<p>Note that when estimating the same quantity we obtain the same
estimates and standard errors from either parameterization from
<code>summary</code> and <code>lincon</code>. The confidence intervals,
however, are slightly different because <code>confint</code> and
<code>lincon</code> use different methods of obtaining approximate
confidence intervals.</p></li>
</ol>
</div>
<div id="heteroscedasticity-in-the-daphnia-data" class="section level2">
<h2>Heteroscedasticity in the Daphnia Data</h2>
<p>The data frame <code>daphniastrat</code> from the
<strong>trtools</strong> package features data from a survey of water
fleas where the number of water fleas were counted in one liter samples
of water taken from three different layers of a lake.</p>
<pre class="r"><code>library(trtools) # for daphniastrat
library(ggplot2) 
p &lt;- ggplot(daphniastrat, aes(x = layer, y = count)) + 
  geom_dotplot(binaxis = &quot;y&quot;, binwidth = 1, stackdir = &quot;center&quot;) + 
  labs(x = &quot;Layer&quot;, y = &quot;Number of Daphnia&quot;) + theme_minimal()
plot(p)</code></pre>
<p><img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-17-1.png" width="100%" style="display: block; margin: auto;" />
We used the following linear model for these data.</p>
<pre class="r"><code>m &lt;- lm(count ~ layer, data = daphniastrat)
summary(m)$coefficients</code></pre>
<pre><code>                 Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)         19.50     0.7271  26.820 4.727e-28
layerthermocline    -8.20     1.2593  -6.512 7.293e-08
layerhypolimnion   -17.77     1.1106 -15.997 1.784e-19</code></pre>
<p>But heteroscedasticity is evident in the plot of the raw data above
and also in a plot of the studentized residuals.</p>
<pre class="r"><code>daphniastrat$yhat &lt;- predict(m)
daphniastrat$rest &lt;- rstudent(m)
p &lt;- ggplot(daphniastrat, aes(x = yhat, y = rest, color = layer)) + 
  geom_count() + theme_minimal() + 
  labs(x = &quot;Predicted Value&quot;, y = &quot;Studentized Residual&quot;, color = &quot;Layer&quot;)
plot(p)</code></pre>
<p><img src="lecture-02-24-2023_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;" />
Note that <code>geom_count</code> is a variant of
<code>geom_point</code> that makes the point size proportional to the
number of points at a particular position, which is useful here.</p>
<p>Heteroscedasticty is quite common when the response variable is a
count. Typically the variance of the counts increases with the expected
count. Here we will consider a couple of ways of dealing with this
heteroscedasticty.</p>
<ol style="list-style-type: decimal">
<li><p>We might assume that the variance varies by layer with the
expected count, so that <span class="math display">\[
  \text{Var}(Y_i) =
  \begin{cases}
\sigma_e^2, &amp; \text{if the $i$-th observation is from the epilimnion
layer}, \\
\sigma_t^2, &amp; \text{if the $i$-th observation is from the
thermocline layer}, \\
\sigma_h^2, &amp; \text{if the $i$-th observation is from the
hypolimnion layer}.
  \end{cases}
\]</span> If so, then our weights should be specified such that <span
class="math display">\[
  w_i \propto
  \begin{cases}
1/\sigma_e^2, &amp; \text{if the $i$-th observation is from the
epilimnion layer}, \\
1/\sigma_t^2, &amp; \text{if the $i$-th observation is from the
thermocline layer}, \\
1/\sigma_h^2, &amp; \text{if the $i$-th observation is from the
hypolimnion layer}.
  \end{cases}
\]</span> We do not know <span
class="math inline">\(\sigma_e^2\)</span>, <span
class="math inline">\(\sigma_t^2\)</span>, and <span
class="math inline">\(\sigma_h^2\)</span>, but they could be
<em>estimated</em> using the sample variances <span
class="math inline">\(s_e^2\)</span>, <span
class="math inline">\(s_t^2\)</span>, and <span
class="math inline">\(s_h^2\)</span>, respectively, which we can easily
compute since we have multiple observations from each layer. Estimate
the model using weighted least squares with weights computed as
described above. The sample standard deviations can be computed and used
to add weights to the data frame using functions from the
<strong>dplyr</strong> package as demonstrated with the
<code>CancerSurvival</code> data in lecture on <a
href="lecture-02-17-2023.html">February 17th</a>.</p>
<p><strong>Solution</strong>: First we compute the weights using
functions from the <strong>dplyr</strong> package.</p>
<pre class="r"><code>library(dplyr)
daphniastrat &lt;- daphniastrat %&gt;% group_by(layer) %&gt;% mutate(w = 1 / var(count))</code></pre>
<p>Then we estimate the model using weighted least squares.</p>
<pre class="r"><code>m &lt;- lm(count ~ layer, data = daphniastrat, weights = w)
summary(m)$coefficients</code></pre>
<pre><code>                 Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)         19.50     0.7997  24.385 2.035e-26
layerthermocline    -8.20     1.5190  -5.398 2.896e-06
layerhypolimnion   -17.77     0.9392 -18.918 3.617e-22</code></pre></li>
<li><p>Assuming again that the variance of the counts vary by layer so
that <span class="math display">\[
  \text{Var}(Y_i) =
  \begin{cases}
\sigma_e^2, &amp; \text{if the $i$-th observation is from the epilimnion
layer}, \\
\sigma_t^2, &amp; \text{if the $i$-th observation is from the
thermocline layer}, \\
\sigma_h^2, &amp; \text{if the $i$-th observation is from the
hypolimnion layer},
  \end{cases}
\]</span> another approach would be to use a <em>parametric model</em>
that estimates the usual parameters of the regression model (i.e., <span
class="math inline">\(\beta_0\)</span>, <span
class="math inline">\(\beta_1\)</span>, and <span
class="math inline">\(\beta_3\)</span>) and the three variances above
<em>simultaneously</em>. Do this using the <code>gls</code> function
from the <strong>nlme</strong> package as demonstrated in lecture on <a
href="lecture-02-22-2023.html">February 22nd</a>.</p>
<p><strong>Solution</strong>: Here is how we would estimate this
model.</p>
<pre class="r"><code>library(nlme) # for gls function
m &lt;- gls(count ~ layer, data = daphniastrat,
  weights = varIdent(form = ~ 1 | layer), method = &quot;ML&quot;)
summary(m)</code></pre>
<pre><code>Generalized least squares fit by maximum likelihood
  Model: count ~ layer 
  Data: daphniastrat 
    AIC   BIC logLik
  235.1 245.9 -111.5

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | layer 
 Parameter estimates:
 epilimnion thermocline hypolimnion 
     1.0000      1.1115      0.5286 

Coefficients:
                  Value Std.Error t-value p-value
(Intercept)       19.50    0.8068  24.170       0
layerthermocline  -8.20    1.5030  -5.456       0
layerhypolimnion -17.77    0.9452 -18.796       0

 Correlation: 
                 (Intr) lyrthr
layerthermocline -0.537       
layerhypolimnion -0.854  0.458

Standardized residuals:
    Min      Q1     Med      Q3     Max 
-1.6261 -0.5937 -0.1434  0.4303  3.0123 

Residual standard error: 3.486 
Degrees of freedom: 45 total; 42 residual</code></pre>
<p>The model above was estimated using <em>maximum likelihood</em> (ML).
But another method is to use what is called <em>restricted maximum
likelihood</em> (REML) which is the default method. It is interesting to
note that for this model, this REML effectively equivalent to the
approach used in the previous problem.</p>
<pre class="r"><code>library(nlme) # for gls function
m &lt;- gls(count ~ layer, data = daphniastrat,
  weights = varIdent(form = ~ 1 | layer), method = &quot;ML&quot;)
summary(m)</code></pre>
<pre><code>Generalized least squares fit by maximum likelihood
  Model: count ~ layer 
  Data: daphniastrat 
    AIC   BIC logLik
  235.1 245.9 -111.5

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | layer 
 Parameter estimates:
 epilimnion thermocline hypolimnion 
     1.0000      1.1115      0.5286 

Coefficients:
                  Value Std.Error t-value p-value
(Intercept)       19.50    0.8068  24.170       0
layerthermocline  -8.20    1.5030  -5.456       0
layerhypolimnion -17.77    0.9452 -18.796       0

 Correlation: 
                 (Intr) lyrthr
layerthermocline -0.537       
layerhypolimnion -0.854  0.458

Standardized residuals:
    Min      Q1     Med      Q3     Max 
-1.6261 -0.5937 -0.1434  0.4303  3.0123 

Residual standard error: 3.486 
Degrees of freedom: 45 total; 42 residual</code></pre>
<p>We will discuss maximum likelihood and perhaps restricted maximum
likelihood later in the course.</p></li>
<li><p>With counts it is often assumed that the variance is proportional
to the expected response — i.e., <span
class="math inline">\(\text{Var}(Y_i) \propto E(Y_i)\)</span>. Assuming
that is true here, estimate the model using <em>iteratively weighted
least squares</em> as was demonstrated in lecture on <a
href="lecture-02-22-2023.html">February 22nd</a>.</p>
<p><strong>Solution</strong>: We can program the iteratively weighted
least squares algorithm as follows.</p>
<pre class="r"><code>daphniastrat$w &lt;- 1
for (i in 1:5) {
  m &lt;- lm(count ~ layer, data = daphniastrat, weights = w)
  daphniastrat$w &lt;- 1 / predict(m)
}
summary(m)</code></pre>
<pre><code>
Call:
lm(formula = count ~ layer, data = daphniastrat, weights = w)

Weighted Residuals:
   Min     1Q Median     3Q    Max 
-1.874 -0.684 -0.113  0.340  4.000 

Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)         19.50       1.13   17.24  &lt; 2e-16 ***
layerthermocline    -8.20       1.66   -4.93  1.3e-05 ***
layerhypolimnion   -17.77       1.20  -14.85  &lt; 2e-16 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Residual standard error: 1.15 on 42 degrees of freedom
Multiple R-squared:  0.86,  Adjusted R-squared:  0.853 
F-statistic:  128 on 2 and 42 DF,  p-value: &lt;2e-16</code></pre>
<p>Note how the estimates do not change. For this particular model the
algorithm only needs to go through one iteration to compute the weights.
This is because the predicted values do not depend on the weights in
this particular model.</p></li>
</ol>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>See the Wikipedia entry on <a
href="https://en.wikipedia.org/wiki/Michaelis-Menten_kinetics">Michaelis-Menten</a>
for details if you are interested. A related model is the <a
href="https://en.wikipedia.org/wiki/Beverton-Holt_model">Beverton-Holt</a>
population dynamics model that is frequently used in fisheries
research.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The interpretation of <span
class="math inline">\(\alpha\)</span> can be seen by taking the limit of
<span class="math inline">\(\alpha s/(\lambda + s)\)</span> as <span
class="math inline">\(s \rightarrow \infty\)</span>, and the
interpretation of <span class="math inline">\(\lambda\)</span> can be
shown by replacing <span class="math inline">\(s\)</span> with <span
class="math inline">\(\lambda\)</span> in <span
class="math inline">\(\alpha s/(\lambda + s)\)</span> which gives <span
class="math inline">\(\alpha/2\)</span>.<a href="#fnref2"
class="footnote-back">↩︎</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
