---
output:
  html_document:
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "04-22-2022"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{array}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "", message = FALSE, out.width = "100%", fig.align = "center", fig.width = 9, cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages, echo = FALSE}
library(tidyverse)
library(kableExtra)
library(trtools)
```

```{r utilities, echo = FALSE}
source("../../utilities.R")
```

```{r options, echo = FALSE}
options(digits = 4, width = 90)
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

<!-- To do: Clean this up by removing some of the redundant contrast and emmeans statements. Just include enough to be informative. These are not as necessary now given that emmeans is introduced earlier in the course. -->

## The Incidental Parameter Problem

Some kinds of designs result in a "factor" with a relatively large number of levels, where each level corresponds to an experimental/observational unit. This can arise for a variety of reasons. Such designs include *repeated measures*, *longitudinal data*, *panel data*, *multilevel data*, *pseudo-replication*, *within-subjects factors*, *dependent samples*, and *clustered data* to name a few (these are not mutually exclusive). Having a factor with a large number of levels can cause complications. This is known in econometrics as the "incidental parameter problem."

**Example**: Consider a study of the running times of three routes from home to second base on a baseball diamond.
```{r, echo = FALSE, fig.asp = 0.9, out.width = "60%"}
library(Hmisc)

f <- function(x, y, ...) {
  tmp <- bezier(x,y)
  lines(tmp$x, tmp$y, ...)
}

par(mai = c(0,0,0,0))

xs <- 0.7
ys <- 0.7

plot.new()
plot.window( xlim=c(-5,6)/xs, ylim=c(0,10)/ys)
lines(x = c(0,5)/xs, y = c(0,5)/ys)
lines(x = c(0,-5)/xs, y = c(0,5)/ys)
lines(x = c(5,0)/xs, y = c(5,10)/ys)
lines(x = c(0,-5)/xs, y = c(10,5)/ys)

# home plate
lines(x = c(0.25,0.25)/xs, y = c(0.25,0.5)/ys)
lines(x = -c(0.25,0.25)/xs, y = c(0.25,0.5)/ys)
lines(x = c(-0.25,0.25)/xs, y = c(0.5,0.5)/ys)

# first base
lines(x = c(4.75, 4.5)/xs, y = c(4.75, 5)/ys)
lines(x = c(4.5,4.75)/xs, y = c(5,5.25)/ys)

# second base
lines(x = c(0, 0.25)/xs, y = c(9.5,9.75)/ys)
lines(x = -c(0, 0.25)/xs, y = c(9.5,9.75)/ys)

# third base
lines(x = -c(4.75, 4.5)/xs, y = c(4.75, 5)/ys)
lines(x = -c(4.5,4.75)/xs, y = c(5,5.25)/ys)

# round
f(x = c(3,4,6,5)/xs, y = c(3,4,4,5)/ys, lty = 2)

# narrow
f(x = c(0, 3, 5, 5)/xs, y = c(0, 2.5, 3.5, 5)/ys, lty = 3)
f(x = c(0, 3, 5, 5)/xs, y = c(10, 10-2.5, 10-3.5, 10-5)/ys, lty = 3)

# wide
f(x = c(0,3.5,6.5,5)/xs, y = c(0,3,3.5,5)/ys, lty = 4)

legend(3/xs, 1.5/ys, bty = "n", lty = 2:4, legend = c("round","narrow","wide"))
```
```{r}
library(trtools)
head(baserun)
```
There is a considerable "effect" for the player. Players who are relatively fast/slow on one route tend to also be relatively fast/slow on the other routes.
```{r, fig.height = 2.5}
p <- ggplot(baserun, aes(x = round, y = narrow)) + theme_minimal()
p <- p + geom_point() + xlim(4.9,6.3) + ylim(4.95,6.3)
p1 <- p

p <- ggplot(baserun, aes(x = round, y = wide)) + theme_minimal()
p <- p + geom_point() + xlim(4.9,6.3) + ylim(4.95,6.3)
p2 <- p

p <- ggplot(baserun, aes(x = narrow, y = wide)) + theme_minimal()
p <- p + geom_point() + xlim(4.9,6.3) + ylim(4.95,6.3)
p3 <- p

cowplot::plot_grid(p1, p2, p3, align = "h", ncol = 3)
```
These data are in what is sometimes called "wide form" where there are multiple observations per unit (player) in a single row. For plotting and modeling it is often useful to "reshape" the data into "long form" with one observation of the response variable (running time) per row.
```{r}
library(dplyr)
library(tidyr)
baselong <- baserun %>% mutate(player = factor(letters[1:n()])) %>% 
  pivot_longer(cols = c(round, narrow, wide), 
    names_to = "route", values_to = "time")
head(baselong)
p <- ggplot(baselong, aes(x = route, y = time)) +
  geom_line(aes(group = player), size = 0.25, alpha = 0.5) +
  geom_point() + theme_minimal() + 
  labs(x = "Route Type", y = "Time (sec)")
plot(p)
```
Again note that there appears to be a "player effect" in that the players show similar results over the routes. 

What *could* we do (but not necessarily what we *should* do) in modeling these data.

We could ignore the effect of player.
```{r}
m <- lm(time ~ route, data = baselong)
summary(m)$coefficients
```
Or we could model the effect of player as a factor.
```{r}
m <- lm(time ~ route + player, data = baselong)
summary(m)$coefficients
```
Or maybe we could do something else?

**Example**: Consider the following data from a meta-analysis of 26 studies of the effect of nicotine gum on smoking cessation.
```{r, message = FALSE}
library(HSAUR3) # for the data
head(smoking)
```
Here `qt` and `tc` are the total number of subjects in the treatment and control groups, respectively, and `tt` and `tc` are the total number of subjects in the treatment and control groups, respectively. 

These data require some rearranging prior to plotting and analysis. (Note: I'm using `dplyr::select` rather than just `select` because of a conflict with a function of the same name with another package I have loaded.)
```{r, fig.height = 5}
library(dplyr)  
library(tidyr) 
quitsmoke <- smoking
quitsmoke$study <- rownames(quitsmoke)
quitsmoke.quits <- quitsmoke %>% dplyr::select(study, qt, qc) %>% 
  rename(gum = qt, control = qc) %>%
  pivot_longer(cols = c(gum,control), 
    names_to = "treatment", values_to = "quit")
head(quitsmoke.quits)
quitsmoke.total <- quitsmoke %>% dplyr::select(study, tt, tc) %>% 
  rename(gum = tt, control = tc) %>%
  pivot_longer(cols = c(gum,control), names_to = "treatment", values_to = "total")
head(quitsmoke.total)
quitsmoke <- full_join(quitsmoke.quits, quitsmoke.total) %>% mutate(study = factor(study)) %>% arrange(study)
head(quitsmoke)
p <- ggplot(quitsmoke, aes(x = study, y = quit/total, 
  size = total, fill = treatment)) + geom_point(pch = 21) + 
  coord_flip() + guides(size = "none") +
  scale_fill_manual(values = c("White","Black")) + theme_minimal() + 
  labs(x = NULL, y = "Proportion of Patients Quitting", 
    fill = "Treatment:") + theme(legend.position = "top")
plot(p)
```
The studies may vary considerably in terms of (a) the proportion of subjects that quit overall and (b) the effectiveness of the gum treatment relative to the control condition. 

What *could* we do (but not necessarily what we *should* do) in modeling these data.

We could ignore the effect of study.
```{r}
m <- glm(cbind(quit, total - quit) ~ treatment, 
  family = binomial, data = quitsmoke)
summary(m)$coefficients
```
Or we could model the main effect of study.
```{r}
m <- glm(cbind(quit, total - quit) ~ treatment + study, 
  family = binomial, data = quitsmoke)
summary(m)$coefficients
```
We could also model an interaction of the treatment with the study. 
```{r}
m <- glm(cbind(quit, total - quit) ~ treatment * study, 
  family = binomial, data = quitsmoke)
summary(m)$coefficients
```
Or maybe we could do something else?

**Example**: Consider the following data from a study of the growth of Sitka spruce trees under two experimental conditions.
```{r, message = FALSE}
library(MASS)
head(Sitka, 10) # note that size is on log scale
p <- ggplot(Sitka, aes(x = Time, y = exp(size))) + 
  geom_line(aes(group = tree), alpha = 0.75, size = 0.1) + 
  facet_wrap(~ treat) + geom_point(size = 0.5) + 
  labs(y = "Size (height times squared diameter)", 
    x = "Days Since January 1, 1988") + theme_minimal()
plot(p)
```
Note that trees vary considerably in terms of their growth trajectories.

What *could* we do (but not necessarily what we *should* do) in modeling these data.

We could ignore the effect of tree.
```{r}
m <- lm(exp(size) ~ Time * treat, data = Sitka)
summary(m)$coefficients
```
Or we could model the effect of tree.
```{r}
Sitka$tree <- factor(Sitka$tree)
m <- lm(exp(size) ~ Time * treat + Time * tree, data = Sitka)
summary(m)$coefficients
```
Or maybe we could do something else?

## Marginal Models and Generalized Estimating Equations

A marginal model *ignores* the many-leveled factor. One approach to estimating such models is to use what can be viewed as an extension of quasi-likelihood called *generalized estimating equations* (GEE). This approach actually involves two parts.

1. Estimate the model using generalized estimating equations. This uses an iterative generalized least squares that uses an estimated "working" correlation structure. This can be viewed as an extension of the iteratively weighted least squares algorithm we used earlier. 

0. Compute *robust* estimates of standard errors to account for heteroscedasticity and correlations among observations. These are designed to deal with the fact that our observations are not independent.

**Example**: Consider two approaches to the `baserun` data: ignoring the player effect entirely and a marginal model with inferences based on GEE.
```{r}
library(geepack)

# generalized linear model, but same as lm(time ~ route, data = baselong)
m.glm <- glm(time ~ route, family = gaussian(link = identity), data = baselong)

# generalized estimating equations
m.gee <- geeglm(time ~ route, family = gaussian(link = identity),
  id = player, corstr = "exchangeable", data = baselong)
```
Note: The data *must* be sorted by the `id` variable, and the `id` variable must be a *factor* or a *number* (not *character*).

Comparing inferences for the model parameters.
```{r}
summary(m.glm)$coefficients
summary(m.gee)
```
Comparing inferences for the expected time for each route.
```{r}
library(emmeans)

emmeans(m.glm, ~route)
emmeans(m.gee, ~route)
trtools::contrast(m.glm, a = list(route = c("narrow","round","wide")))
trtools::contrast(m.gee, a = list(route = c("narrow","round","wide")))
```
Comparing inferences for the *differences* in expected time between routes.
```{r}
pairs(emmeans(m.glm, ~route), adjust = "none", infer = TRUE)
pairs(emmeans(m.gee, ~route), adjust = "none", infer = TRUE)
trtools::contrast(m.glm, 
  a = list(route = c("narrow","narrow","round")),
  b = list(route = c("round","wide","wide")),
  cnames = c("narrow - round","narrow - wide","round - wide"))
trtools::contrast(m.gee, 
  a = list(route = c("narrow","narrow","round")),
  b = list(route = c("round","wide","wide")),
  cnames = c("narrow - round","narrow - wide","round - wide"))
```

**Example**: Consider two approaches to the `smoking` data: ignoring the study effect entirely and a marginal model with inferences based on GEE.
```{r}
head(quitsmoke)
m.glm <- glm(cbind(quit, total - quit) ~ treatment,
  family = binomial, data = quitsmoke)
m.gee <- geeglm(cbind(quit, total - quit) ~ treatment, 
  family = binomial, data = quitsmoke,
  id = study, corstr = "exchangeable")
```
Comparing inferences for the model parameters.
```{r}
summary(m.glm)$coefficients
summary(m.gee)
```
Estimating the probability of quitting.
```{r}
emmeans(m.glm, ~treatment, type = "response")
emmeans(m.gee, ~treatment, type = "response")
trtools::contrast(m.glm, a = list(treatment = c("control","gum")),
  tf = plogis, cnames = c("control","gum"))
trtools::contrast(m.gee, a = list(treatment = c("control","gum")),
  tf = plogis, cnames = c("control","gum"))
```
Estimating the odds ratio for the effect of the gum treatment.
```{r}
pairs(emmeans(m.glm, ~treatment, type = "response"), 
  reverse = TRUE, infer = TRUE)
pairs(emmeans(m.gee, ~treatment, type = "response"), 
  reverse = TRUE, infer = TRUE)
trtools::contrast(m.glm, tf = exp,
  a = list(treatment = "gum"),
  b = list(treatment = "control"))
trtools::contrast(m.gee, tf = exp,
  a = list(treatment = "gum"),
  b = list(treatment = "control"))
```

**Example**: Consider two approaches to the `Sitka` data.
```{r}
m.glm <- glm(exp(size) ~ Time * treat,
  family = gaussian(link = identity), data = Sitka)
m.gee <- geeglm(exp(size) ~ Time * treat, 
  family = gaussian(link = identity), data = Sitka,
  id = tree, corstr = "exchangeable")
```
Comparing inferences for the model parameters.
```{r}
summary(m.glm)$coefficients
summary(m.gee)
```
Estimating the growth rate in each treatment condition.
```{r}
trtools::contrast(m.glm,
  a = list(Time = 250, treat = c("control","ozone")),
  b = list(Time = 150, treat = c("control","ozone")),
  cnames = c("control","ozone"))
trtools::contrast(m.gee,
  a = list(Time = 250, treat = c("control","ozone")),
  b = list(Time = 150, treat = c("control","ozone")),
  cnames = c("control","ozone"))
# Note: We can estimate the growth rates (per day) 
# using emtrends from the emmeans package.
emtrends(m.glm, ~ treat, var = "Time")
emtrends(m.gee, ~ treat, var = "Time")
```
Comparing the growth rates between the treatment conditions. 
```{r}
trtools::contrast(m.glm,
  a = list(Time = 250, treat = "control"),
  b = list(Time = 150, treat = "control"),
  u = list(Time = 250, treat = "ozone"),
  v = list(Time = 150, treat = "ozone"))
trtools::contrast(m.gee,
  a = list(Time = 250, treat = "control"),
  b = list(Time = 150, treat = "control"),
  u = list(Time = 250, treat = "ozone"),
  v = list(Time = 150, treat = "ozone"))
pairs(emtrends(m.glm, ~ treat, var = "Time"))
pairs(emtrends(m.gee, ~ treat, var = "Time"))
```

## Limitations of Marginal Models and GEE

1. Performs best when the data are relatively "shallow" meaning that there are many units (e.g., players, studies, or trees) but relatively few observations per unit (e.g., routes, treatment conditions, time points).

0. Difficult to use with "unbalanced" data where not every unit is observed at the same "points" (e.g., routes, treatments, time points).

0. Inefficient if the (working) correlation structure is a poor approximation. 

0. Limited to "marginal inferences" in that it cannot tell us much about the variation among units (in contrast to models with "random effects" which we will discuss later).
