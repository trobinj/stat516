<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Categorical Response Variables, Marginal and Mixed Effect Models, and Review</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics 436/516</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="lectures.html">Lectures</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Categorical Response Variables, Marginal
and Mixed Effect Models, and Review</h1>
<h3 class="subtitle">Statistics 516, Homework 5 (Solutions)</h3>

</div>


<p>You can also download a <a href="hw5-solutions.pdf">PDF</a> copy of
this homework assignment.</p>
<div id="dental-fissure-growth-data" class="section level2">
<h2>Dental Fissure Growth Data</h2>
<p>The data frame <code>potthoffroy</code> in the <strong>mice</strong>
package is from a study of the growth of the distance from the center of
the pituitary gland to the pteryomaxillary fissure in boys and girls.<a
href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The
pituitary-pteryomaxillary distance was measured four times at ages 8,
10, 12, and 14 in several boys and girls. These longitudinal data are
stored in wide form.</p>
<pre class="r"><code>library(mice)
head(potthoffroy)</code></pre>
<pre><code>  id sex   d8  d10  d12  d14
1  1   F 21.0 20.0 21.5 23.0
2  2   F 21.0 21.5 24.0 25.5
3  3   F 20.5 24.0 24.5 26.0
4  4   F 23.5 24.5 25.0 26.5
5  5   F 21.5 23.0 22.5 23.5
6  6   F 20.0 21.0 21.0 22.5</code></pre>
<p>For plotting and modeling we need to put them into long form. This is
done below. Also a quantitative age variable is created from the column
labels of the wide form data.</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
dental &lt;- potthoffroy %&gt;% rename(subject = id) %&gt;% 
  pivot_longer(cols = c(d8,d10,d12,d14), names_to = &quot;obs&quot;, values_to = &quot;distance&quot;) %&gt;% 
  mutate(age = as.numeric(substr(obs, 2, nchar(obs)))) %&gt;% dplyr::select(-obs)
head(dental)</code></pre>
<pre><code># A tibble: 6 × 4
  subject sex   distance   age
    &lt;int&gt; &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;
1       1 F         21       8
2       1 F         20      10
3       1 F         21.5    12
4       1 F         23      14
5       2 F         21       8
6       2 F         21.5    10</code></pre>
<p>The plot below shows the observations with line segments connecting
the observations from the same subject.</p>
<pre class="r"><code>library(ggplot2)
p &lt;- ggplot(dental, aes(x = age, y = distance)) + theme_minimal() + 
  geom_line(aes(group = subject), alpha = 0.25) + geom_point() + 
  facet_wrap(~ sex) + labs(x = &quot;Age (years)&quot;, y = &quot;Distance (mm)&quot;)
plot(p)</code></pre>
<p><img src="hw5-solutions_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" />
These data were featured in the lecture on <a
href="lecture-04-25-2022.html">fixed effects models</a>.<a href="#fn2"
class="footnote-ref" id="fnref2"><sup>2</sup></a> The fixed effects
approach is not useful here for making inferences regarding sex, so you
will consider some other approaches that are more useful. When using the
<code>geeglm</code> and <code>lmer</code> functions you might find it
useful that these data are very similar in structure to the
<code>Sitka</code> data featured in lecture where we have
<code>age</code> instead of <code>Time</code>, <code>sex</code> instead
of <code>ozone</code>, and <code>subject</code> instead of
<code>tree</code>. Note that unlike the <code>Sitka</code> data we do
not need to transform the response variable or the time/age variable.
For each of the problems below report the <code>summary</code> output so
that I can verify that you specified and estimated the model
correctly.</p>
<ol style="list-style-type: decimal">
<li><p>Estimate a linear model using the <code>lm</code> function with
distance as the response variable and age and <code>sex</code> as the
explanatory variables, with an interaction. Note that this is arguably
not an appropriate model here as it does not account for the lack of
independence of observations from the same subject, but you will use it
for comparison. Using either the <code>contrast</code> function or
functions from the <strong>emmeans</strong> package, estimate (a) the
difference in the expected distance between boys and girls at ages of 8,
10, 12, and 14, (b) the rate of change in the expected distance per year
for boys and for girls, and (c) the difference in the rate of change in
the expected distance per year between boys and girls.</p>
<p><strong>Solution</strong>: We can estimate the model as follows.</p>
<pre class="r"><code>m &lt;- lm(distance ~ sex * age, data = dental)
summary(m)$coefficients</code></pre>
<pre><code>            Estimate Std. Error t value  Pr(&gt;|t|)
(Intercept)  17.3727     1.7080 10.1712 2.788e-17
sexM         -1.0321     2.2188 -0.4652 6.428e-01
age           0.4795     0.1522  3.1515 2.122e-03
sexM:age      0.3048     0.1977  1.5421 1.261e-01</code></pre>
<p>Here I will show how to make the various inferences based on this
models using both the <code>contrast</code> function and the
<strong>emmeans</strong> package, but in the later problems I will only
use one or the other. Here are the comparisons between boys and girls at
four ages.</p>
<pre class="r"><code>trtools::contrast(m,
  a = list(sex = &quot;M&quot;, age = c(8,10,12,14)),
  b = list(sex = &quot;F&quot;, age = c(8,10,12,14)),
  cnames = paste(c(8,10,12,14), &quot;years&quot;))</code></pre>
<pre><code>         estimate     se    lower upper tvalue  df    pvalue
8 years     1.407 0.7396 -0.06012 2.873  1.902 104 5.997e-02
10 years    2.016 0.4842  1.05604 2.976  4.164 104 6.465e-05
12 years    2.626 0.4842  1.66570 3.586  5.423 104 3.827e-07
14 years    3.236 0.7396  1.76886 4.702  4.375 104 2.897e-05</code></pre>
<p>This can also be done using the <strong>emmeans</strong> package.</p>
<pre class="r"><code>library(emmeans)
pairs(emmeans(m, ~sex|age, at = list(age = c(8,10,12,14))), 
  infer = TRUE, reverse = TRUE)</code></pre>
<pre><code>age =  8:
 contrast estimate    SE  df lower.CL upper.CL t.ratio p.value
 M - F        1.41 0.740 104  -0.0601     2.87   1.902  0.0600

age = 10:
 contrast estimate    SE  df lower.CL upper.CL t.ratio p.value
 M - F        2.02 0.484 104   1.0560     2.98   4.164  0.0001

age = 12:
 contrast estimate    SE  df lower.CL upper.CL t.ratio p.value
 M - F        2.63 0.484 104   1.6657     3.59   5.423  &lt;.0001

age = 14:
 contrast estimate    SE  df lower.CL upper.CL t.ratio p.value
 M - F        3.24 0.740 104   1.7689     4.70   4.375  &lt;.0001

Confidence level used: 0.95 </code></pre>
<p>We can estimate the rate of change in the expected distance for boys
and girls as follows.</p>
<pre class="r"><code>trtools::contrast(m, 
  a = list(sex = c(&quot;F&quot;,&quot;M&quot;), age = 9),
  b = list(sex = c(&quot;F&quot;,&quot;M&quot;), age = 8),
  cnames = c(&quot;girls&quot;,&quot;boys&quot;))</code></pre>
<pre><code>      estimate     se  lower  upper tvalue  df    pvalue
girls   0.4795 0.1522 0.1778 0.7813  3.152 104 2.122e-03
boys    0.7844 0.1262 0.5342 1.0346  6.217 104 1.069e-08</code></pre>
<pre class="r"><code>emtrends(m, ~sex, var = &quot;age&quot;, infer = TRUE)</code></pre>
<pre><code> sex age.trend    SE  df lower.CL upper.CL t.ratio p.value
 F       0.479 0.152 104    0.178    0.781   3.152  0.0021
 M       0.784 0.126 104    0.534    1.035   6.217  &lt;.0001

Confidence level used: 0.95 </code></pre>
<p>And here is the comparison of the rates of change between boys and
girls.</p>
<pre class="r"><code>trtools::contrast(m, 
  a = list(sex = &quot;M&quot;, age = 9),
  b = list(sex = &quot;M&quot;, age = 8),
  u = list(sex = &quot;F&quot;, age = 9),
  v = list(sex = &quot;F&quot;, age = 8))</code></pre>
<pre><code> estimate     se    lower  upper tvalue  df pvalue
   0.3048 0.1977 -0.08715 0.6968  1.542 104 0.1261</code></pre>
<pre class="r"><code>pairs(emtrends(m, ~sex, var = &quot;age&quot;), infer = TRUE, reverse = TRUE)</code></pre>
<pre><code> contrast estimate    SE  df lower.CL upper.CL t.ratio p.value
 M - F       0.305 0.198 104  -0.0872    0.697   1.542  0.1261

Confidence level used: 0.95 </code></pre></li>
<li><p>Estimate a <em>marginal</em> linear model using the
<code>geeglm</code> function from the <strong>geepack</strong> package
with <code>distance</code> as the response variable and age and sex as
the explanatory variables, with an interaction. Note that subject is
your <code>id</code> variable and your correlation structure should be
specified as exchangeable as was done in lecture. Using this model make
the same inferences that you did in the previous problem using the
<code>contrast</code> function or the <strong>emmeans</strong> package.
Note that the syntax for these inferences should be the same as what you
used in the previous problem.</p>
<p><strong>Solution</strong>: We can estimate the model as follows.</p>
<pre class="r"><code>library(geepack)
m &lt;- geeglm(distance ~ sex * age, data = dental,
  family = gaussian(link = identity), 
  id = subject, corstr = &quot;exchangeable&quot;)
summary(m)</code></pre>
<pre><code>
Call:
geeglm(formula = distance ~ sex * age, family = gaussian(link = identity), 
    data = dental, id = subject, corstr = &quot;exchangeable&quot;)

 Coefficients:
            Estimate Std.err   Wald Pr(&gt;|W|)    
(Intercept)  17.3727  0.7252 573.87  &lt; 2e-16 ***
sexM         -1.0321  1.3778   0.56   0.4538    
age           0.4795  0.0631  57.70  3.1e-14 ***
sexM:age      0.3048  0.1169   6.80   0.0091 ** 
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation structure = exchangeable 
Estimated Scale Parameters:

            Estimate Std.err
(Intercept)     4.91    1.01
  Link = identity 

Estimated Correlation Parameters:
      Estimate Std.err
alpha    0.618   0.131
Number of clusters:   27  Maximum cluster size: 4 </code></pre>
<p>Here are the comparisons between boys and girls at four ages.</p>
<pre class="r"><code>trtools::contrast(m,
  a = list(sex = &quot;M&quot;, age = c(8,10,12,14)),
  b = list(sex = &quot;F&quot;, age = c(8,10,12,14)),
  cnames = paste(c(8,10,12,14), &quot;years&quot;))</code></pre>
<pre><code>         estimate    se  lower upper tvalue  df   pvalue
8 years      1.41 0.774 -0.128  2.94   1.82 104 0.071989
10 years     2.02 0.740  0.549  3.48   2.73 104 0.007525
12 years     2.63 0.778  1.084  4.17   3.38 104 0.001031
14 years     3.24 0.878  1.494  4.98   3.68 104 0.000367</code></pre>
<p>We can estimate the rate of change in the expected distance for boys
and girls as follows.</p>
<pre class="r"><code>emtrends(m, ~sex, var = &quot;age&quot;, infer = TRUE)</code></pre>
<pre><code> sex age.trend     SE  df asymp.LCL asymp.UCL z.ratio p.value
 F       0.480 0.0631 Inf     0.356     0.603   7.600  &lt;.0001
 M       0.784 0.0983 Inf     0.592     0.977   7.980  &lt;.0001

Covariance estimate used: vbeta 
Confidence level used: 0.95 </code></pre>
<p>And here is the comparison of the rates of change between boys and
girls.</p>
<pre class="r"><code>pairs(emtrends(m, ~sex, var = &quot;age&quot;), infer = TRUE, reverse = TRUE)</code></pre>
<pre><code> contrast estimate    SE  df asymp.LCL asymp.UCL z.ratio p.value
 M - F       0.305 0.117 Inf    0.0758     0.534   2.608  0.0091

Confidence level used: 0.95 </code></pre></li>
<li><p>Estimate a linear <em>mixed effects</em> model using the
<code>lmer</code> function from the <strong>lme4</strong> package with
distance as the response variable and age and <code>sex</code> as the
explanatory variables, with an interaction. Specify a random “main
effect” for subject. Using this model make the same inferences that you
did in the previous problems using the <code>contrast</code> function or
the <strong>emmeans</strong> package. Note that the syntax for these
inferences should be the same as what you used in the previous
problem.</p>
<p><strong>Solution</strong>: We can estimate the model as follows.</p>
<pre class="r"><code>library(lme4)
m &lt;- lmer(distance ~ sex * age + (1 | subject), data = dental)
summary(m)</code></pre>
<pre><code>Linear mixed model fit by REML [&#39;lmerMod&#39;]
Formula: distance ~ sex * age + (1 | subject)
   Data: dental

REML criterion at convergence: 434

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-3.598 -0.455  0.016  0.502  3.686 

Random effects:
 Groups   Name        Variance Std.Dev.
 subject  (Intercept) 3.30     1.82    
 Residual             1.92     1.39    
Number of obs: 108, groups:  subject, 27

Fixed effects:
            Estimate Std. Error t value
(Intercept)  17.3727     1.1835   14.68
sexM         -1.0321     1.5374   -0.67
age           0.4795     0.0935    5.13
sexM:age      0.3048     0.1214    2.51

Correlation of Fixed Effects:
         (Intr) sexM   age   
sexM     -0.770              
age      -0.869  0.669       
sexM:age  0.669 -0.869 -0.770</code></pre>
<p>Here are the comparisons between boys and girls at four ages.</p>
<pre class="r"><code>trtools::contrast(m,
  a = list(sex = &quot;M&quot;, age = c(8,10,12,14)),
  b = list(sex = &quot;F&quot;, age = c(8,10,12,14)),
  cnames = paste(c(8,10,12,14), &quot;years&quot;))</code></pre>
<pre><code>         estimate    se  lower upper tvalue  df   pvalue
8 years      1.41 0.844 -0.248  3.06   1.67 Inf 0.095637
10 years     2.02 0.771  0.505  3.53   2.61 Inf 0.008925
12 years     2.63 0.771  1.115  4.14   3.41 Inf 0.000660
14 years     3.24 0.844  1.581  4.89   3.83 Inf 0.000126</code></pre>
<p>We can estimate the rate of change in the expected distance for boys
and girls as follows.</p>
<pre class="r"><code>emtrends(m, ~sex, var = &quot;age&quot;, infer = TRUE)</code></pre>
<pre><code> sex age.trend     SE df lower.CL upper.CL t.ratio p.value
 F       0.480 0.0935 79    0.293    0.666   5.130  &lt;.0001
 M       0.784 0.0775 79    0.630    0.939  10.120  &lt;.0001

Degrees-of-freedom method: kenward-roger 
Confidence level used: 0.95 </code></pre>
<p>And here is the comparison of the rates of change between boys and
girls.</p>
<pre class="r"><code>pairs(emtrends(m, ~sex, var = &quot;age&quot;), infer = TRUE, reverse = TRUE)</code></pre>
<pre><code> contrast estimate    SE df lower.CL upper.CL t.ratio p.value
 M - F       0.305 0.121 79   0.0631    0.547   2.511  0.0141

Degrees-of-freedom method: kenward-roger 
Confidence level used: 0.95 </code></pre></li>
<li><p>Compare the inferences you obtained in the three problems above,
paying particular attention to the estimates and their standard errors.
Discuss briefly the similarities and differences in the inferences for
the three approaches.</p>
<p><strong>Solution</strong>: When comparing boys and girls at different
ages we do not see any real differences in the estimates. Using a
marginal or mixed model produces somewhat higher standard errors at ages
10 and 12. When estimating the rates of change we get substantially
smaller standard errors from the marginal and mixed models, although the
point estimates are very similar. This is also the case when we compare
the rates of change between boys and girls. For a study like this it
could be important to account for the effect of subject in your
inferences by using either the marginal or mixed model. Failing to
account for such effects as in the first model estimating using
<code>lm</code> can lead to biased standard errors.</p></li>
</ol>
</div>
<div id="swedish-speed-limit-study-revisited-again"
class="section level2">
<h2>Swedish Speed Limit Study — Revisited, Again</h2>
<p>Once again consider the data from the <a
href="hw3-solutions.html">third</a> and <a
href="hw4-solutions.html">fourth</a> homework assignments (review the
study description given in the third homework assignment).</p>
<pre class="r"><code>library(SMPracticals)
library(dplyr)
library(tidyr)
limitstudy &lt;- limits %&gt;% 
  rename(limit_1961 = lim1, limit_1962 = lim2, y_1961 = y1, y_1962 = y2) %&gt;%
  pivot_longer(cols = -day, names_to = c(&quot;.value&quot;, &quot;year&quot;), names_sep = &quot;_&quot;) %&gt;%
  mutate(limit = factor(limit, levels = c(0,1), labels = c(&quot;no&quot;,&quot;yes&quot;)))
head(limitstudy)</code></pre>
<pre><code># A tibble: 6 × 4
  day   year  limit     y
  &lt;fct&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt;
1 1     1961  no        9
2 1     1962  no        9
3 2     1961  no       11
4 2     1962  no       20
5 3     1961  no        9
6 3     1962  no       15</code></pre>
<p>Here is a plot of the number of accidents for each year and day.</p>
<pre class="r"><code>library(ggplot2)
p &lt;- ggplot(limitstudy, aes(x = day, y = y, color = limit)) + 
  theme_minimal() + geom_point() + facet_grid(year ~ .) + 
  scale_x_discrete(breaks = seq(1, 92, by = 7)) + 
  labs(x = &quot;Day&quot;, y = &quot;Number of Accidents&quot;, color = &quot;Speed\nLimit&quot;)
plot(p)</code></pre>
<p><img src="hw5-solutions_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;" />
As I discussed in the third homework assignment, there may be an effect
of the factor <code>day</code>. This is because the days are matched in
the sense that a given day in 1961 is the same day of the week and month
as the day with the same level in 1962 (e.g., if a given day is a Sunday
in 1961 it is also a Sunday in 1962). The accident rate may vary by day
due to differences in, for example, traffic (e.g., work days versus
weekends and holidays). Plotting the residuals from a Poisson regression
model shows some evidence of an association between days that is not
captured by the model.</p>
<pre class="r"><code>m &lt;- glm(y ~ limit + year, family = poisson, data = limitstudy)
limitstudy$residuals &lt;- rstudent(m)

d &lt;- limitstudy %&gt;% dplyr::select(day, year, residuals) %&gt;% 
  pivot_wider(names_from = year, values_from = residuals)
p &lt;- ggplot(d, aes(x = `1961`, y = `1962`)) + theme_minimal() + 
  geom_count() + scale_size_continuous(breaks = 1:2, range = c(1,2.5))
plot(p)</code></pre>
<p><img src="hw5-solutions_files/figure-html/unnamed-chunk-20-1.png" width="100%" style="display: block; margin: auto;" />
Here you will extend your Poisson regression model to account for the
lack of independence of observations made on the same day in 1961 and in
1962. For each model report the output of <code>summary</code> so that I
can verify that you specified and estimated the model correctly.</p>
<ol style="list-style-type: decimal">
<li><p>Estimate a <em>marginal</em> Poisson regression model using the
<code>geeglm</code> function with the number of accidents as your
response variables, and limit and year as explanatory variable (with no
interaction). Note that day will be your <code>id</code> variable and
you should specify an exchangeable correlation structure.</p>
<p><strong>Solution</strong>: We can estimate the model as follows.</p>
<pre class="r"><code>library(geepack)
m.gee &lt;- geeglm(y ~ limit + year, data = limitstudy,
  family = poisson, id = day, corstr = &quot;exchangeable&quot;)
summary(m.gee)</code></pre>
<pre><code>
Call:
geeglm(formula = y ~ limit + year, family = poisson, data = limitstudy, 
    id = day, corstr = &quot;exchangeable&quot;)

 Coefficients:
            Estimate Std.err    Wald Pr(&gt;|W|)    
(Intercept)   3.1811  0.0412 5974.94  &lt; 2e-16 ***
limityes     -0.2671  0.0473   31.82  1.7e-08 ***
year1962     -0.0402  0.0381    1.11     0.29    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation structure = exchangeable 
Estimated Scale Parameters:

            Estimate Std.err
(Intercept)     3.33   0.483
  Link = identity 

Estimated Correlation Parameters:
      Estimate Std.err
alpha    0.659  0.0567
Number of clusters:   92  Maximum cluster size: 2 </code></pre></li>
<li><p>Estimate a <em>mixed effects</em> Poisson regression model using
the <code>glmer</code> function with the number of accidents as your
response variables, and limit and year as explanatory variable (with no
interaction). Specify your model with a random main effect for day.</p>
<p><strong>Solution</strong>: We can estimate the model as follows.</p>
<pre class="r"><code>library(lme4)
m.glmer &lt;- glmer(y ~ limit + year + (1 | day), 
  family = poisson, data = limitstudy)
summary(m.glmer)</code></pre>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod
]
 Family: poisson  ( log )
Formula: y ~ limit + year + (1 | day)
   Data: limitstudy

     AIC      BIC   logLik deviance df.resid 
    1243     1256     -617     1235      180 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.1262 -0.6149 -0.0521  0.5667  1.6729 

Random effects:
 Groups Name        Variance Std.Dev.
 day    (Intercept) 0.0942   0.307   
Number of obs: 184, groups:  day, 92

Fixed effects:
            Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)   3.1334     0.0398   78.74  &lt; 2e-16 ***
limityes     -0.2655     0.0413   -6.44  1.2e-10 ***
year1962     -0.0383     0.0341   -1.12     0.26    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation of Fixed Effects:
         (Intr) limtys
limityes -0.190       
year1962 -0.284 -0.359</code></pre></li>
<li><p>For each of the two models you estimated above, use either the
<code>contrast</code> function or functions from the
<strong>emmeans</strong> package to estimate (a) the expected number of
accidents with and without a posted speed limit each year and (b) the
rate ratio describing the relationship between whether or not a speed
limit was posted and the expected number of accidents (like you did in
the previous two homework assignments). Compare your estimates and
standard errors to what you got when you used a Poisson regression model
in the third homework assignment (using <code>family = poisson</code>,
not <code>family = quasipoisson</code>) in terms of the estimates and
either standard errors or confidence intervals for the rate ratios.
Briefly discuss similarities and differences between the three
models.</p>
<p><strong>Solution</strong>: For comparison I will also estimate the
Poisson regression model here again.</p>
<pre class="r"><code>m.glm &lt;- glm(y ~ limit + year, family = poisson, data = limitstudy)</code></pre>
<p>Now consider the estimated expected number of accidents each year
with and without a posted speed limit.</p>
<pre class="r"><code>library(emmeans)
emmeans(m.glm, ~limit*year, type = &quot;response&quot;)</code></pre>
<pre><code> limit year rate    SE  df asymp.LCL asymp.UCL
 no    1961 23.7 0.543 Inf      22.6      24.8
 yes   1961 19.6 0.704 Inf      18.3      21.0
 no    1962 22.2 0.637 Inf      21.0      23.5
 yes   1962 18.4 0.547 Inf      17.4      19.5

Confidence level used: 0.95 
Intervals are back-transformed from the log scale </code></pre>
<pre class="r"><code>emmeans(m.gee, ~limit*year, type = &quot;response&quot;)</code></pre>
<pre><code> limit year rate    SE  df asymp.LCL asymp.UCL
 no    1961 24.1 0.991 Inf      22.2      26.1
 yes   1961 18.4 1.016 Inf      16.5      20.5
 no    1962 23.1 1.157 Inf      21.0      25.5
 yes   1962 17.7 0.824 Inf      16.2      19.4

Covariance estimate used: vbeta 
Confidence level used: 0.95 
Intervals are back-transformed from the log scale </code></pre>
<pre class="r"><code>emmeans(m.glmer, ~limit*year, type = &quot;response&quot;)</code></pre>
<pre><code> limit year rate    SE  df asymp.LCL asymp.UCL
 no    1961 22.9 0.913 Inf      21.2      24.8
 yes   1961 17.6 0.908 Inf      15.9      19.5
 no    1962 22.1 0.982 Inf      20.2      24.1
 yes   1962 16.9 0.766 Inf      15.5      18.5

Confidence level used: 0.95 
Intervals are back-transformed from the log scale </code></pre>
<p>The estimates are similar but not identical across the three
approaches. The standard errors are noticeably smaller when using the
generalized linear model. We might be concerned about underestimating
the standard errors by failing to account for the effect of day. Now
consider the rate ratio for the effect of limit.</p>
<pre class="r"><code>pairs(emmeans(m.glm, ~limit|year, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>year = 1961:
 contrast ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 no / yes  1.21 0.0428 Inf      1.13      1.29    1   5.330  &lt;.0001

year = 1962:
 contrast ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 no / yes  1.21 0.0428 Inf      1.13      1.29    1   5.330  &lt;.0001

Confidence level used: 0.95 
Intervals are back-transformed from the log scale 
Tests are performed on the log scale </code></pre>
<pre class="r"><code>pairs(emmeans(m.gee, ~limit|year, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>year = 1961:
 contrast ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 no / yes  1.31 0.0618 Inf      1.19      1.43    1   5.640  &lt;.0001

year = 1962:
 contrast ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 no / yes  1.31 0.0618 Inf      1.19      1.43    1   5.640  &lt;.0001

Confidence level used: 0.95 
Intervals are back-transformed from the log scale 
Tests are performed on the log scale </code></pre>
<pre class="r"><code>pairs(emmeans(m.glmer, ~limit|year, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>year = 1961:
 contrast ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 no / yes   1.3 0.0538 Inf       1.2      1.41    1   6.440  &lt;.0001

year = 1962:
 contrast ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 no / yes   1.3 0.0538 Inf       1.2      1.41    1   6.440  &lt;.0001

Confidence level used: 0.95 
Intervals are back-transformed from the log scale 
Tests are performed on the log scale </code></pre>
<p>The generalized linear model produces a somewhat smaller estimate of
the rate ratio than the marginal or mixed model. We may be
underestimating the rate ratio by failing to account for the effect of
day. The standard errors are fairly similar.</p></li>
</ol>
</div>
<div id="audit-study-of-discrimination-in-hiring"
class="section level2">
<h2>Audit Study of Discrimination in Hiring</h2>
<p>The data frame <code>resume</code> in the <strong>qss</strong>
package are from an <a
href="https://en.wikipedia.org/wiki/Audit_study">audit study</a> of
hiring discrimination based on perceived gender and race.<a href="#fn3"
class="footnote-ref" id="fnref3"><sup>3</sup></a> Resumes were sent in
response to job advertisements, and the researchers recorded whether or
not the job application resulted in a call-back. The applicants were
fictitious with randomly-assigned names that were selected so that they
would be likely identified as white or African-American, and as female
or male.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>
Use the command</p>
<pre class="r"><code>devtools::install_github(&quot;kosukeimai/qss-package&quot;, build_vignettes = TRUE)</code></pre>
<p>to install the <strong>qss</strong> package. Note that you will need
to have the <strong>devtools</strong> package installed to do this, but
you should have it installed already since it is necessary to install
<strong>trtools</strong>.</p>
<pre class="r"><code>library(qss)
data(resume)
head(resume)</code></pre>
<pre><code>  firstname    sex  race call
1   Allison female white    0
2   Kristen female white    0
3   Lakisha female black    0
4   Latonya female black    0
5    Carrie female white    0
6       Jay   male white    0</code></pre>
<p>For plotting and modeling it is useful to aggregate the data to show
the number of call backs and the total number of resumes for each
combination of name, sex, and race.</p>
<pre class="r"><code>library(dplyr)
resumeagg &lt;- resume %&gt;% group_by(firstname, sex, race) %&gt;% 
  summarize(callbacks = sum(call), applications = n()) %&gt;% 
  mutate(sexrace = interaction(sex, race, sep = &quot; and &quot;))
head(resumeagg)</code></pre>
<pre><code># A tibble: 6 × 6
# Groups:   firstname, sex [6]
  firstname sex    race  callbacks applications sexrace         
  &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;        &lt;int&gt; &lt;fct&gt;           
1 Aisha     female black         4          180 female and black
2 Allison   female white        22          232 female and white
3 Anne      female white        20          242 female and white
4 Brad      male   white        10           63 male and white  
5 Brendan   male   white         5           65 male and white  
6 Brett     male   white         4           59 male and white  </code></pre>
<p>Note the use of the <code>interaction</code> function here to create
a new variable <code>sexrace</code> for every combination of the
variables <code>sex</code> and <code>race</code>. This is used in the
plot below. The plot shows the proportion of job applications that
received a call-back for each name.<a href="#fn5" class="footnote-ref"
id="fnref5"><sup>5</sup></a></p>
<pre class="r"><code>library(ggplot2)
p &lt;- ggplot(resumeagg, aes(x = firstname, y = callbacks/applications)) + 
  theme_minimal() + coord_flip() + geom_point() + 
  facet_grid(sexrace ~ ., scales = &quot;free_y&quot;) + 
  labs(y = &quot;Proportion of Applications Receiving Call-Back&quot;, x = NULL)
plot(p)</code></pre>
<p><img src="hw5-solutions_files/figure-html/unnamed-chunk-29-1.png" width="100%" style="display: block; margin: auto;" />
The focus here would be on the relationship between the probability (or
odds) of a call-back as a function of the likely perceived race and
gender of the applicant. But there may be an effect of the <em>name</em>
as well. The name may have an effect because (a) some names may be more
or less likely to be perceived as from an applicant of a certain race or
gender, and (b) names may differ in terms of other perceptions such as
social class. Here you will consider some methods for accounting for the
effect of name while making inferences about the effect of (likely
perceived) gender and race. Be sure to report the output of
<code>summary</code> for each model so that I can verify that you
specified and estimated the model correctly.</p>
<ol style="list-style-type: decimal">
<li><p>Estimate a logistic regression model using the <code>glm</code>
function that you can use to obtain odds ratios for the effect of gender
and race on the odds that an application will get a call-back. Include
an interaction between gender and race. Note that this model may not be
appropriate since it does not account for an effect of name, but it will
be used for comparison.</p>
<p><strong>Solution</strong>: Here is how to estimate the logistic
regression model.</p>
<pre class="r"><code>m.glm &lt;- glm(cbind(callbacks, applications - callbacks) ~ sex * race,
  family = binomial, data = resumeagg)
summary(m.glm)$coefficients</code></pre>
<pre><code>                  Estimate Std. Error  z value  Pr(&gt;|z|)
(Intercept)        -2.6453     0.0926 -28.5787 1.24e-179
sexmale            -0.1370     0.2043  -0.6704  5.03e-01
racewhite           0.4361     0.1208   3.6092  3.07e-04
sexmale:racewhite   0.0165     0.2632   0.0629  9.50e-01</code></pre></li>
<li><p>Estimate a <em>marginal</em> logistic regression model using the
<code>geeglm</code> function that you can use to obtain odds ratios for
the effect of gender and race on the odds that an application will get a
call-back. Include an interaction between gender and race. Use first
name as your <code>id</code> variable and specify an exchangeable
correlation structure. The data will first need to be sorted by
<code>firstname</code> for using with the <code>geeglm</code> function.
You can do this using</p>
<pre class="r"><code>resumeagg &lt;- resumeagg %&gt;% arrange(firstname)
resumeagg</code></pre>
<pre><code># A tibble: 36 × 6
# Groups:   firstname, sex [36]
   firstname sex    race  callbacks applications sexrace         
   &lt;chr&gt;     &lt;chr&gt;  &lt;chr&gt;     &lt;int&gt;        &lt;int&gt; &lt;fct&gt;           
 1 Aisha     female black         4          180 female and black
 2 Allison   female white        22          232 female and white
 3 Anne      female white        20          242 female and white
 4 Brad      male   white        10           63 male and white  
 5 Brendan   male   white         5           65 male and white  
 6 Brett     male   white         4           59 male and white  
 7 Carrie    female white        22          168 female and white
 8 Darnell   male   black         2           42 male and black  
 9 Ebony     female black        20          208 female and black
10 Emily     female white        18          227 female and white
# … with 26 more rows</code></pre>
<p><em>before</em> estimating the model.</p>
<p><strong>Solution</strong>: This problem was dropped.</p></li>
<li><p>Estimate a <em>mixed effects</em> logistic regression model using
the <code>glmer</code> function that you can use to obtain odds ratios
for the effect of gender and race on the odds that an application will
get a call-back. Include an interaction between gender and race. Specify
a random main effect for first name in your model. Report the output of
<code>summary</code> for this model.</p>
<p><strong>Solution</strong>: The model can be estimated as follows.</p>
<pre class="r"><code>library(lme4)
m.glmer &lt;- glmer(cbind(callbacks, applications - callbacks) ~ sex * race + (1 | firstname),
  family = binomial, data = resumeagg)
summary(m.glmer)</code></pre>
<pre><code>Generalized linear mixed model fit by maximum likelihood (Laplace Approximation) [glmerMod
]
 Family: binomial  ( logit )
Formula: cbind(callbacks, applications - callbacks) ~ sex * race + (1 |      firstname)
   Data: resumeagg

     AIC      BIC   logLik deviance df.resid 
     186      194      -88      176       31 

Scaled residuals: 
   Min     1Q Median     3Q    Max 
-2.257 -0.601 -0.213  1.011  1.878 

Random effects:
 Groups    Name        Variance Std.Dev.
 firstname (Intercept) 0.00649  0.0806  
Number of obs: 36, groups:  firstname, 36

Fixed effects:
                  Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)        -2.6495     0.0976  -27.15  &lt; 2e-16 ***
sexmale            -0.1353     0.2080   -0.65  0.51531    
racewhite           0.4390     0.1272    3.45  0.00056 ***
sexmale:racewhite   0.0135     0.2690    0.05  0.95991    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Correlation of Fixed Effects:
            (Intr) sexmal racwht
sexmale     -0.463              
racewhite   -0.762  0.354       
sexml:rcwht  0.360 -0.774 -0.473</code></pre></li>
<li><p>Use either the <code>contrast</code> function or functions from
the <strong>emmeans</strong> package to estimate the odds ratios for the
effects of gender and race for each of the three models you estimated.
Note that since there is an interaction you should have two odds ratios
for each explanatory variable (i.e., the odds ratios for the effect
gender will be computed for each race, and the odds ratio for race will
be computed for each gender). Focusing on the estimates and either the
standard errors or confidence intervals for the odds ratios, briefly
describe how these odds ratios compare across the three models.</p>
<p><strong>Solution</strong>: Here are the odds ratios for the effect of
gender for each model.</p>
<pre class="r"><code>library(emmeans)
pairs(emmeans(m.glm, ~sex|race, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>race = black:
 contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 female / male       1.15 0.234 Inf     0.768      1.71    1   0.670  0.5030

race = white:
 contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 female / male       1.13 0.187 Inf     0.815      1.56    1   0.726  0.4680

Confidence level used: 0.95 
Intervals are back-transformed from the log odds ratio scale 
Tests are performed on the log odds ratio scale </code></pre>
<pre class="r"><code>pairs(emmeans(m.glmer, ~ sex|race, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>race = black:
 contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 female / male       1.14 0.238 Inf     0.762      1.72    1   0.651  0.5150

race = white:
 contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 female / male       1.13 0.192 Inf     0.809      1.58    1   0.715  0.4750

Confidence level used: 0.95 
Intervals are back-transformed from the log odds ratio scale 
Tests are performed on the log odds ratio scale </code></pre>
<p>And here are the odds ratios for the effect of race for each
model.</p>
<pre class="r"><code>pairs(emmeans(m.glm, ~race|sex, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>sex = female:
 contrast      odds.ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 black / white      0.647 0.0781 Inf     0.510     0.819    1  -3.610  0.0003

sex = male:
 contrast      odds.ratio     SE  df asymp.LCL asymp.UCL null z.ratio p.value
 black / white      0.636 0.1487 Inf     0.402     1.006    1  -1.940  0.0529

Confidence level used: 0.95 
Intervals are back-transformed from the log odds ratio scale 
Tests are performed on the log odds ratio scale </code></pre>
<pre class="r"><code>pairs(emmeans(m.glmer, ~ race|sex, type = &quot;response&quot;), infer = TRUE)</code></pre>
<pre><code>sex = female:
 contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 black / white      0.645 0.082 Inf     0.502     0.827    1  -3.450  0.0006

sex = male:
 contrast      odds.ratio    SE  df asymp.LCL asymp.UCL null z.ratio p.value
 black / white      0.636 0.151 Inf     0.400     1.012    1  -1.910  0.0562

Confidence level used: 0.95 
Intervals are back-transformed from the log odds ratio scale 
Tests are performed on the log odds ratio scale </code></pre>
<p>Interestingly in this particular case the point estimates and
standard errors for the odds ratios are fairly similar for the
generalized linear and the generalized linear mixed models.</p></li>
</ol>
</div>
<div id="a-sequential-model-for-vaccine-efficacy"
class="section level2">
<h2>A Sequential Model for Vaccine Efficacy</h2>
<p>An <a
href="https://www.covid-datascience.com/post/israeli-data-how-can-efficacy-vs-severe-disease-be-strong-when-60-of-hospitalized-are-vaccinated">article</a>
published on <a
href="https://www.covid-datascience.com">covid-datascience.com</a>
discussed some misunderstandings about data on the efficacy of the
COVID-19 vaccine in Israel.<a href="#fn6" class="footnote-ref"
id="fnref6"><sup>6</sup></a> One issue was that the apparent efficacy of
the vaccine is underestimated if one fails to account for age. The
reason is that older people were much more likely to be vaccinated, but
older people are also more likely to develop a severe infection
requiring hospitalization. Here the variable age is an example of what
is sometimes called a <em>suppressor variable</em> because it reduces
the apparent effect of another explanatory variable if it is not also
included as an explanatory variable. For this problem I have created a
fictional data set that demonstrates this phenomenon.</p>
<pre class="r"><code>vaccine &lt;- data.frame(
  age = c(&quot;&lt;50&quot;,&quot;&lt;50&quot;,&quot;50+&quot;,&quot;50+&quot;),
  vaccine = c(&quot;n&quot;,&quot;y&quot;,&quot;n&quot;,&quot;y&quot;),
  uninfected = c(7932, 9635, 800, 8516),
  infected = c(1817, 514, 193, 456),
  hospitalized = c(96, 6, 19, 15)
)
vaccine</code></pre>
<pre><code>  age vaccine uninfected infected hospitalized
1 &lt;50       n       7932     1817           96
2 &lt;50       y       9635      514            6
3 50+       n        800      193           19
4 50+       y       8516      456           15</code></pre>
<p>These data are in aggregated form, showing the number of subjects for
each combination of age (less than 50 or 50 or more years in age) and
vaccination (yes or no) classified as uninfected, infected with
COVID-19, and hospitalized due to COVID-19. Note that people who are
hospitalized are also infected, so the infected category is only for
people who are infected but not hospitalized. For each model you
estimate below, report the output of <code>summary</code> so that I can
verify that you specified and estimated the model correctly.</p>
<ol style="list-style-type: decimal">
<li><p>Estimate <em>two</em> logistic regression models using the
<code>glm</code> function: one model for the probability that someone
will get COVID-19 (i.e., classified as <code>infected</code> or
<code>hospitalized</code> versus <code>uninfected</code>) and another
for the probability that someone who gets infected will be hospitalized
(i.e., <code>hospitalized</code> versus <code>infected</code>). Use only
whether or not someone was vaccinated as your explanatory variable. Note
that since the data are in aggregate form you can specify the “response
variable” in <code>glm</code> as
<code>cbind(infected + hospitalized, uninfected)</code> for the first
model, and <code>cbind(hospitalized, infected)</code> for the second
model. Estimate the odds ratio for the effect of vaccine for each model,
and write a sentence that summarizes how to interpret each odds
ratio.</p>
<p><strong>Solution</strong>: Here are the two logistic regression
models with odds ratios.</p>
<pre class="r"><code>m1 &lt;- glm(cbind(infected + hospitalized, uninfected) ~ vaccine,
  family = binomial, data = vaccine)
summary(m1)$coefficients</code></pre>
<pre><code>            Estimate Std. Error z value  Pr(&gt;|z|)
(Intercept)    -1.41     0.0242   -58.4  0.00e+00
vacciney       -1.49     0.0406   -36.8 1.77e-296</code></pre>
<pre class="r"><code>exp(cbind(coef(m1), confint(m1)))</code></pre>
<pre><code>                  2.5 % 97.5 %
(Intercept) 0.243 0.232  0.255
vacciney    0.224 0.207  0.243</code></pre>
<pre class="r"><code>m2 &lt;- glm(cbind(hospitalized, infected) ~ vaccine,
  family = binomial, data = vaccine)
summary(m2)$coefficients</code></pre>
<pre><code>            Estimate Std. Error z value  Pr(&gt;|z|)
(Intercept)   -2.861     0.0959  -29.84 1.23e-195
vacciney      -0.972     0.2405   -4.04  5.33e-05</code></pre>
<pre class="r"><code>exp(cbind(coef(m2), confint(m2)))</code></pre>
<pre><code>                    2.5 % 97.5 %
(Intercept) 0.0572 0.0472 0.0687
vacciney    0.3784 0.2299 0.5931</code></pre>
<p>From the estimated odds ratios we can conclude that (a) the odds that
a vaccinated person will become infected is about 88% less than someone
who is not vaccinated, and (b) the odds that an infected vaccinated
person will require hospitalization is about 62% less than someone who
is not vaccinated.</p></li>
<li><p>Estimate a <em>sequential</em> regression model using the
<code>vglm</code> function from the <strong>VGAM</strong> package with
the status as your three-category response variable (i.e., uninfected,
infected, or hospitalized, in that order) and vaccine as your only
explanatory variable. You should find that the parameter estimates
correspond to what you obtained with the two logistic regression models
in the previous problem.</p>
<p><strong>Solution</strong>: Here is how to estimate the sequential
model.</p>
<pre class="r"><code>library(VGAM)
m &lt;- vglm(cbind(uninfected, infected, hospitalized) ~ vaccine,
  family = cratio(link = &quot;logitlink&quot;), data = vaccine)
summary(m)</code></pre>
<pre><code>
Call:
vglm(formula = cbind(uninfected, infected, hospitalized) ~ vaccine, 
    family = cratio(link = &quot;logitlink&quot;), data = vaccine)

Coefficients: 
              Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept):1  -1.4132     0.0242  -58.42  &lt; 2e-16 ***
(Intercept):2  -2.8610     0.0959  -29.84  &lt; 2e-16 ***
vacciney:1     -1.4945     0.0406  -36.80  &lt; 2e-16 ***
vacciney:2     -0.9718     0.2405   -4.04  5.3e-05 ***
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

Names of linear predictors: logitlink(P[Y&gt;1|Y&gt;=1]), logitlink(P[Y&gt;2|Y&gt;=2])

Residual deviance: 11.5 on 4 degrees of freedom

Log-likelihood: -31.4 on 4 degrees of freedom

Number of Fisher scoring iterations: 4 

Warning: Hauck-Donner effect detected in the following estimate(s):
&#39;(Intercept):2&#39;</code></pre>
<p>Note that the parameter estimates are the same as when using the two
logistic regression models.</p></li>
<li><p>Estimate the sequential regression model but now including age as
a second explanatory variable (do not include an interaction between
vaccine and age). Report and interpret in a sentence the odds ratios for
the effect of vaccination on (a) infection, and (b) hospitalization of
an infected person.</p>
<p><strong>Solution</strong>: Here is how to estimate the sequential
model, now including age as an explanatory variable.</p>
<pre class="r"><code>m &lt;- vglm(cbind(uninfected, infected, hospitalized) ~ vaccine + age,
  family = cratio(link = &quot;logitlink&quot;), data = vaccine)
trtools::lincon(m) # more compact output</code></pre>
<pre><code>              estimate     se   lower  upper tvalue  df    pvalue
(Intercept):1  -1.4181 0.0247 -1.4665 -1.370 -57.46 Inf  0.00e+00
(Intercept):2  -2.9563 0.1032 -3.1586 -2.754 -28.65 Inf 1.61e-180
vacciney:1     -1.5142 0.0451 -1.6027 -1.426 -33.55 Inf 8.98e-247
vacciney:2     -1.2786 0.2640 -1.7961 -0.761  -4.84 Inf  1.28e-06
age50+:1        0.0516 0.0511 -0.0485  0.152   1.01 Inf  3.12e-01
age50+:2        0.7177 0.2257  0.2753  1.160   3.18 Inf  1.48e-03</code></pre>
<pre class="r"><code>trtools::lincon(m, tf = exp) # exponentiate for odds ratios</code></pre>
<pre><code>              estimate  lower  upper
(Intercept):1    0.242 0.2307 0.2542
(Intercept):2    0.052 0.0425 0.0637
vacciney:1       0.220 0.2014 0.2403
vacciney:2       0.278 0.1659 0.4672
age50+:1         1.053 0.9526 1.1640
age50+:2         2.050 1.3169 3.1902</code></pre>
<p>Now controlling for age, we find that vaccination reduces the odds of
infection by about 78% (about the same as when not accounting for age),
and reduces the odds of hospitalization after infection by about 71% (a
larger effect then when not accounting for age). The variable age was
suppressing the effect of vaccination on the odds of hospitalization
after infection.</p></li>
</ol>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Potthoff, R. F., &amp; Roy, S. N. (1964). A generalized
multivariate analysis of variance model useful especially for growth
curve problems. <em>Biometrika</em>, <em>51(3)</em>, 313–326.<a
href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>These data have appeared in many articles and books, and
are included in several R packages. In lecture I used the data frame
form the <strong>heavy</strong> package, but this package requires
compilation of some C code which may not be able to do if you do not
have a compiler installed.<a href="#fnref2"
class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Bertrand, M. &amp; Mullainathan, S. (2004). Are Emily
and Greg more employable than Lakisha and Jamal? A field experiment on
labor market discrimination. <em>American Economic Review</em>,
<em>94</em>, 991–1013.<a href="#fnref3"
class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>This study is actually a bit more complicated because
the researchers also manipulated other characteristics of the resumes
such as education, experience, awards, and other information that was
included or omitted from the resume. Also the data include information
about the jobs for which the “candidates” applied such as skill and
experience requirements, and the type of industry. For the purpose of
this exercise we will ignore these other variables.<a href="#fnref4"
class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The <code>scales = "free_y"</code> argument lets the
scale of the variable (here <code>firstname</code>) to be “free” for
each facet. If it was omitted then every name would be listed for every
value of <code>sexrace</code>, but that is not necessary here since only
certain names go with each value of <code>sexrace</code> (i.e., the name
factor is <em>nested</em> within the combinations of the sex and race
factors). Try removing the argument and see what happens to the plot to
better understand what it does.<a href="#fnref5"
class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p><a
href="https://en.wikipedia.org/wiki/Vaccine_efficacy">Vaccine
efficacy</a> is an example of what we could a <em>marginal effect</em>
in a binomial regression model. It is the (estimated) percent reduction
in the probability of an infection from vaccination.<a href="#fnref6"
class="footnote-back">↩︎</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
