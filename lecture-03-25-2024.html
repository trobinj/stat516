<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Monday, Mar 25</title>

<script src="site_libs/header-attrs-2.26/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Statistics 436/516</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="lectures.html">Lectures</a>
</li>
<li>
  <a href="resources.html">Resources</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Monday, Mar 25</h1>

</div>


<p>You can also download a <a href="lecture-03-25-2024.pdf">PDF</a> copy
of this lecture.</p>
<div id="distributions-for-over-dispersion" class="section level2">
<h2>Distributions for Over-dispersion</h2>
<p>One way to model over-dispersion is to assume a model of the form
<span class="math display">\[
  g[E(Y_i)] = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik} +
\zeta_i,
\]</span> where <span class="math inline">\(\zeta_i\)</span> is an
<em>unobserved</em> unit-specific random quantity that represents one or
more unobserved explanatory variables that vary over units.</p>
<div id="the-negative-binomial-distribution" class="section level3">
<h3>The Negative Binomial Distribution</h3>
<p>Suppose that <span class="math inline">\(Y_i\)</span> has a Poisson
distribution <em>conditional</em> on <span
class="math inline">\(\zeta_i\)</span>, and <span
class="math inline">\(e^{\zeta_i}\)</span> has a <em>gamma</em>
distribution such that <span class="math inline">\(E(e^{\gamma_i}) =
1\)</span> and <span class="math inline">\(\text{Var}(e^{\gamma_i}) =
\alpha &gt; 0\)</span>. The <em>marginal</em> distribution of <span
class="math inline">\(Y_i\)</span> is then a <em>negative binomial
distribution</em>, with mean structure <span class="math display">\[
  g[E(Y_i)] = \eta_i,
\]</span> and variance structure <span class="math display">\[
  \text{Var}(Y_i) = E(Y_i) + \alpha E(Y_i)^2 \ge E(Y_i).
\]</span> The Poisson distribution is a special case where <span
class="math inline">\(\alpha = 0\)</span>. This variance structure
<em>does not</em> have the form <span class="math display">\[
  \text{Var}(Y_i) = \phi V[E(Y_i)]
\]</span> unless <span class="math inline">\(\alpha\)</span> is known
(which it normally is not), so this model is not a traditional GLM. But
we can make inferences using maximum likelihood.</p>
<p><strong>Example</strong>: Consider our model for the trawl fishing
data. Here we will consider a negative binomial regression model.</p>
<pre class="r"><code>library(COUNT)
data(fishing)

library(MASS) # for the glm.nb function (note there is no family argument)

m &lt;- glm.nb(totabund ~ period * meandepth + offset(log(sweptarea)),
  link = log, data = fishing)

d &lt;- expand.grid(sweptarea = 1, period = levels(fishing$period), 
  meandepth = seq(800, 5000, length = 100))
d$yhat &lt;- predict(m, newdata = d, type = &quot;response&quot;)

p &lt;- ggplot(fishing, aes(x = meandepth, y = totabund/sweptarea)) + 
  geom_point(alpha = 0.5) + facet_wrap(~ period) + theme_minimal() + 
  labs(x = &quot;Mean Trawl Depth (meters)&quot;,
    y = &quot;Fish Caught Per Square Meter Trawled&quot;) + 
  geom_line(aes(y = yhat), data = d)
plot(p)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-2-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(m) # note that what glm.nb calls theta equals 1/alpha</code></pre>
<pre><code>
Call:
glm.nb(formula = totabund ~ period * meandepth + offset(log(sweptarea)), 
    data = fishing, link = log, init.theta = 1.961162176)

Coefficients:
                           Estimate Std. Error z value Pr(&gt;|z|)    
(Intercept)               -3.25e+00   1.59e-01  -20.40   &lt;2e-16 ***
period2000-2002           -6.19e-01   2.73e-01   -2.27    0.023 *  
meandepth                 -1.04e-03   5.92e-05  -17.58   &lt;2e-16 ***
period2000-2002:meandepth  7.95e-05   1.01e-04    0.79    0.432    
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for Negative Binomial(1.961) family taken to be 1)

    Null deviance: 471.79  on 146  degrees of freedom
Residual deviance: 159.31  on 143  degrees of freedom
AIC: 1763

Number of Fisher Scoring iterations: 1

              Theta:  1.961 
          Std. Err.:  0.219 

 2 x log-likelihood:  -1752.713 </code></pre>
<pre class="r"><code>plot(predict(m), rstudent(m), main = &quot;Residual Plot&quot;)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-2-2.png" width="100%" style="display: block; margin: auto;" />
Interestingly inferences based on the negative binomial model are very
similar to those obtained using quasi-likelihood assuming the variance
structure <span class="math inline">\(V(Y_i) = \phi E(Y_i)^2\)</span>.
Here are the parameter estimates, standard errors, and confidence
intervals.</p>
<pre class="r"><code>m.negbn &lt;- glm.nb(totabund ~ period * meandepth + offset(log(sweptarea)),
  link = log, data = fishing)
m.quasi &lt;- glm(totabund ~ period * meandepth + offset(log(sweptarea)),
  family = quasi(link = &quot;log&quot;, variance = &quot;mu^2&quot;), data = fishing)
cbind(summary(m.negbn)$coefficients, confint(m.negbn))</code></pre>
<pre><code>                            Estimate Std. Error  z value  Pr(&gt;|z|)      2.5 %     97.5 %
(Intercept)               -3.249e+00  1.592e-01 -20.4044 1.529e-92 -3.5603979 -2.9274102
period2000-2002           -6.187e-01  2.726e-01  -2.2695 2.324e-02 -1.1815413 -0.0436165
meandepth                 -1.041e-03  5.923e-05 -17.5844 3.245e-69 -0.0011578 -0.0009213
period2000-2002:meandepth  7.955e-05  1.013e-04   0.7855 4.322e-01 -0.0001333  0.0002952</code></pre>
<pre class="r"><code>cbind(summary(m.quasi)$coefficients, confint(m.quasi))</code></pre>
<pre><code>                            Estimate Std. Error  t value  Pr(&gt;|t|)      2.5 %     97.5 %
(Intercept)               -3.250e+00  1.592e-01 -20.4180 3.187e-44 -3.5609660 -2.9294775
period2000-2002           -6.041e-01  2.720e-01  -2.2212 2.791e-02 -1.1672726 -0.0287948
meandepth                 -1.041e-03  5.866e-05 -17.7403 5.988e-38 -0.0011552 -0.0009217
period2000-2002:meandepth  7.272e-05  9.992e-05   0.7278 4.679e-01 -0.0001381  0.0002870</code></pre>
<p>Here are the estimates of the rate ratios for period at several
different depths.</p>
<pre class="r"><code>library(trtools)
contrast(m.negbn, 
  a = list(meandepth = c(1000,2000,3000,4000,5000), period = &quot;2000-2002&quot;, sweptarea = 1),
  b = list(meandepth = c(1000,2000,3000,4000,5000), period = &quot;1977-1989&quot;, sweptarea = 1),
  cnames = c(&quot;1000m&quot;,&quot;2000m&quot;,&quot;3000m&quot;,&quot;4000m&quot;,&quot;5000m&quot;), tf = exp)</code></pre>
<pre><code>      estimate  lower  upper
1000m   0.5832 0.4017 0.8468
2000m   0.6315 0.4868 0.8193
3000m   0.6838 0.5184 0.9020
4000m   0.7404 0.4928 1.1125
5000m   0.8017 0.4494 1.4301</code></pre>
<pre class="r"><code>contrast(m.quasi, 
  a = list(meandepth = c(1000,2000,3000,4000,5000), period = &quot;2000-2002&quot;, sweptarea = 1),
  b = list(meandepth = c(1000,2000,3000,4000,5000), period = &quot;1977-1989&quot;, sweptarea = 1),
  cnames = c(&quot;1000m&quot;,&quot;2000m&quot;,&quot;3000m&quot;,&quot;4000m&quot;,&quot;5000m&quot;), tf = exp)</code></pre>
<pre><code>      estimate  lower  upper
1000m   0.5878 0.4046 0.8540
2000m   0.6321 0.4869 0.8206
3000m   0.6798 0.5173 0.8935
4000m   0.7311 0.4905 1.0897
5000m   0.7863 0.4458 1.3867</code></pre>
<p>Here are the tests (likelihood ratio and <span
class="math inline">\(F\)</span>) for the “effect” of period. The null
model assumes that expected abundance per unit area trawled is the same
each period at a given depth. Put another way, the null model assumes
that the rate ratio for period is one for all depths.</p>
<pre class="r"><code>m.negbn.null &lt;- glm.nb(totabund ~ meandepth + offset(log(sweptarea)),
  link = log, data = fishing)
anova(m.negbn.null, m.negbn)</code></pre>
<pre><code>Likelihood ratio tests of Negative Binomial Models

Response: totabund
                                        Model theta Resid. df    2 x log-lik.   Test    df LR stat.
1          meandepth + offset(log(sweptarea)) 1.832       145           -1764                      
2 period * meandepth + offset(log(sweptarea)) 1.961       143           -1753 1 vs 2     2    11.11
   Pr(Chi)
1         
2 0.003872</code></pre>
<pre class="r"><code>m.quasi.null &lt;- glm(totabund ~ meandepth + offset(log(sweptarea)),
  family = quasi(link = &quot;log&quot;, variance = &quot;mu^2&quot;), data = fishing)
anova(m.quasi.null, m.quasi, test = &quot;F&quot;)</code></pre>
<pre><code>Analysis of Deviance Table

Model 1: totabund ~ meandepth + offset(log(sweptarea))
Model 2: totabund ~ period * meandepth + offset(log(sweptarea))
  Resid. Df Resid. Dev Df Deviance    F Pr(&gt;F)   
1       145       90.5                           
2       143       84.5  2     5.94 5.74  0.004 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Note: When using <code>anova</code> for a negative binomial model
(estimated using the <code>glm.nb</code> function) we omit the
<code>test = "LRT"</code> option which we use for generalized linear
models. Somewhat confusingly, the <code>anova</code> function will do a
likelihood ratio test for a <code>glm.nb</code> object, but will throw
an error if we try to change the test type (even if we ask for a
likelihood ratio test).</p>
</div>
</div>
<div id="heteroscedastic-consistent-robust-standard-errors"
class="section level2">
<h2>Heteroscedastic Consistent (Robust) Standard Errors</h2>
<p>An alternative is to accept that the specified variance structure is
incorrect and estimate standard errors in a way that provides
<em>consistent</em> estimates despite the misspecification of the
variance structure.<a href="#fn1" class="footnote-ref"
id="fnref1"><sup>1</sup></a></p>
<p>Note: I needed to specify the data set as
<code>trtools::rotifer</code> below as there is a data set of the same
name in another package that was loaded earlier. It’s actually the same
data but in a different format from the data frame in the
<strong>trtools</strong> package.</p>
<p><strong>Example</strong>: Consider the logistic regression model for
the <code>rotifer</code> data from the <strong>trtools</strong>
package.</p>
<pre class="r"><code>m &lt;- glm(cbind(y, total - y) ~ species + density + species:density,
  family = binomial, data = trtools::rotifer)</code></pre>
<p>Here are the parameter estimates and standard errors, with and
without using the robust standard error estimates.</p>
<pre class="r"><code>library(sandwich) # for the vcovHC function
library(lmtest)   # for coeftest and coefci functions
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>                  Estimate Std. Error  z value   Pr(&gt;|z|)    2.5 %   97.5 %
(Intercept)       -114.352      4.034 -28.3454 9.534e-177 -122.420 -106.598
speciespm            4.629      6.598   0.7016  4.830e-01   -8.464   17.431
density            108.746      3.857  28.1910 7.535e-175  101.332  116.460
speciespm:density   -3.077      6.329  -0.4862  6.268e-01  -15.354    9.487</code></pre>
<pre class="r"><code>cbind(coeftest(m, vcov = vcovHC), coefci(m, vcov = vcovHC))</code></pre>
<pre><code>                  Estimate Std. Error z value  Pr(&gt;|z|)   2.5 % 97.5 %
(Intercept)       -114.352      18.31 -6.2449 4.240e-10 -150.24 -78.46
speciespm            4.629      29.91  0.1548 8.770e-01  -53.99  63.25
density            108.746      17.50  6.2137 5.175e-10   74.44 143.05
speciespm:density   -3.077      28.82 -0.1068 9.150e-01  -59.57  53.42</code></pre>
<p>An alternative to using <code>coeftest</code> and <code>coefci</code>
is <code>lincon(m, fcov = vcovHC)</code>. Now compare our inferences for
the odds ratios for the effect of a 0.01 increase in density.</p>
<pre class="r"><code>contrast(m,
  a = list(density = 0.02, species = c(&quot;kc&quot;,&quot;pm&quot;)),
  b = list(density = 0.01, species = c(&quot;kc&quot;,&quot;pm&quot;)),
  cnames = c(&quot;kc&quot;,&quot;pm&quot;), tf = exp)</code></pre>
<pre><code>   estimate lower upper
kc    2.967 2.751 3.200
pm    2.877 2.607 3.174</code></pre>
<pre class="r"><code>contrast(m,
  a = list(density = 0.02, species = c(&quot;kc&quot;,&quot;pm&quot;)),
  b = list(density = 0.01, species = c(&quot;kc&quot;,&quot;pm&quot;)),
  cnames = c(&quot;kc&quot;,&quot;pm&quot;), tf = exp, fcov = vcovHC)</code></pre>
<pre><code>   estimate lower upper
kc    2.967 2.105 4.181
pm    2.877 1.836 4.507</code></pre>
<p>For comparison consider also the results when using
quasi-likelihood.</p>
<pre class="r"><code>m &lt;- glm(cbind(y, total - y) ~ species + density + species:density,
  family = quasibinomial, data = trtools::rotifer)
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>                  Estimate Std. Error t value  Pr(&gt;|t|)   2.5 % 97.5 %
(Intercept)       -114.352      14.95 -7.6472 4.736e-09 -146.02 -87.01
speciespm            4.629      24.46  0.1893 8.509e-01  -46.15  51.31
density            108.746      14.30  7.6056 5.358e-09   82.60 139.02
speciespm:density   -3.077      23.46 -0.1312 8.964e-01  -47.81  45.70</code></pre>
<pre class="r"><code>contrast(m,
  a = list(density = 0.02, species = c(&quot;kc&quot;,&quot;pm&quot;)),
  b = list(density = 0.01, species = c(&quot;kc&quot;,&quot;pm&quot;)),
  cnames = c(&quot;kc&quot;,&quot;pm&quot;), tf = exp)</code></pre>
<pre><code>   estimate lower upper
kc    2.967 2.220 3.965
pm    2.877 1.973 4.195</code></pre>
<p>Recall that heteroscedastic consistent standard errors are best used
with generous sample sizes. For modest sample sizes (such as this
experiment) quasi-likelihood is probably better.</p>
</div>
<div id="generalized-linear-models-revisited" class="section level2">
<h2>Generalized Linear Models Revisited</h2>
<p>Recall that a generalized linear model (GLM) has the form <span
class="math display">\[
  g[E(Y_i)] = \underbrace{\beta_0 + \beta_1 x_{i1} + \beta_1 x_{i2} +
\cdots + \beta_k x_{ik}}_{\eta_i},
\]</span> where <span class="math inline">\(g\)</span> is the <em>link
function</em> and <span class="math inline">\(\eta_i\)</span> is the
<em>linear predictor</em> or <em>systematic component</em>. This is the
<em>mean structure</em> of the model.</p>
<p>The <em>variance structure</em> of a GLM is <span
class="math display">\[
  \text{Var}(Y_i) = \phi V[E(Y_i)],
\]</span> where <span class="math inline">\(\phi\)</span> is a
<em>dispersion parameter</em> and <span class="math inline">\(V\)</span>
is the <em>variance function</em>.</p>
<p>If we define <span class="math inline">\(h = g^{-1}\)</span> so that
<span class="math inline">\(E(Y_i) = h(\eta_i)\)</span> we can write a
GLM concisely as <span class="math display">\[\begin{align}
  E(Y_i) &amp; = h(\eta_i) \\
  \text{Var}(Y_i) &amp; = \phi V[h(\eta_i)]
\end{align}\]</span> to define the <em>mean structure</em> and a
<em>variance structure</em> for <span
class="math inline">\(Y_i\)</span>, respectively, by specifying the mean
and variance of <span class="math inline">\(Y_i\)</span> to be functions
of <span class="math inline">\(x_{i1}, x_{i2}, \dots,
x_{ik}\)</span>.</p>
<p>The specification of a generalized linear model therefore requires
three components.</p>
<ol style="list-style-type: decimal">
<li><p>The <em>systematic component</em> <span
class="math inline">\(\eta_i = \beta_0 + \beta_1 x_{i1} + \beta_1 x_{i2}
+ \cdots + \beta_k x_{ik}\)</span>.</p></li>
<li><p>The <em>link function</em> <span class="math inline">\(g\)</span>
for the mean structure <span class="math inline">\(g[E(Y_i)] =
\eta_i\)</span>.</p></li>
<li><p>The <em>distribution</em> of the response variable <span
class="math inline">\(Y_i\)</span>, which implies the variance structure
<span class="math inline">\(\text{Var}(Y_i) = \phi V[E(Y_i)]\)</span>,
or we can specify the variance structure <em>directly</em>.</p></li>
</ol>
<p>Four common distributions from the exponential family of
distributions (normal/Gaussian, Poisson, gamma, and inverse-Gaussian)
imply variance structures of the form <span class="math display">\[
  \text{Var}(Y_i) = \phi E(Y_i)^p
\]</span> The values of <span class="math inline">\(p\)</span> are <span
class="math inline">\(p\)</span> = 0 (normal/Gaussian), <span
class="math inline">\(p\)</span> = 1 (Poisson if <span
class="math inline">\(\phi = 1\)</span>), <span
class="math inline">\(p\)</span> = 2 (gamma), and <span
class="math inline">\(p\)</span> = 3 (inverse-Gaussian). Also note that
when using quasi-likelihood we can use other values of <span
class="math inline">\(p\)</span> via the <code>tweedie</code> function
from the <strong>statmod</strong> package.</p>
</div>
<div id="glms-for-gamma-distributed-response-variables"
class="section level2">
<h2>GLMs for Gamma-Distributed Response Variables</h2>
<p>If <span class="math inline">\(Y_i\)</span> has a <em>gamma</em>
distribution then <span class="math inline">\(Y_i\)</span> is a positive
and continuous random variable, and <span
class="math inline">\(\text{Var}(Y_i) = \phi E(Y_i)^2\)</span>. Such
models are sometimes suitable for response variables that are bounded
below by zero and right-skewed. Common link functions include the
<em>log</em> and <em>inverse</em> functions. With a log link function we
have a mean structure like that for Poisson regression where <span
class="math display">\[
  \log E(Y_i) = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots +
\beta_k x_{ik},
\]</span> or <span class="math display">\[
  E(Y_i) = \exp(\beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots +
\beta_k x_{ik}),
\]</span> so the effects of explanatory variables and contrasts can be
interpreted by applying the exponential function <span
class="math inline">\(e^x\)</span> and interpreting the effects as
multiplicative factors or percent increase/decrease or percent
larger/smaller.</p>
<p><strong>Example</strong>: Consider again the cancer survival time
data.</p>
<pre class="r"><code>library(Stat2Data)
data(CancerSurvival)
CancerSurvival$Organ &lt;- with(CancerSurvival, reorder(Organ, Survival, mean))
p &lt;- ggplot(CancerSurvival, aes(x = Organ, y = Survival)) +
  geom_jitter(height = 0, width = 0.25) + 
  labs(y = &quot;Survival Time (Days)&quot;) + theme_classic()
plot(p)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-10-1.png" width="100%" style="display: block; margin: auto;" />
A gamma model might be appropriate here. First consider a model with a
log link function.</p>
<pre class="r"><code>m &lt;- glm(Survival ~ Organ, family = Gamma(link = log), data = CancerSurvival)
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>             Estimate Std. Error t value  Pr(&gt;|t|)    2.5 % 97.5 %
(Intercept)    5.3546     0.2504 21.3854 1.773e-29  4.90101  5.889
OrganStomach   0.3013     0.3804  0.7923 4.314e-01 -0.44036  1.068
OrganColon     0.7709     0.3541  2.1772 3.348e-02  0.06991  1.472
OrganOvary     1.4302     0.4902  2.9174 4.987e-03  0.52462  2.486
OrganBreast    1.8867     0.3995  4.7228 1.479e-05  1.11572  2.702</code></pre>
<p>We might compare the survival times to the type of cancer with lowest
expected survival time.</p>
<pre class="r"><code>contrast(m, tf = exp,
  a = list(Organ = c(&quot;Stomach&quot;,&quot;Colon&quot;,&quot;Ovary&quot;,&quot;Breast&quot;)),
  b = list(Organ = &quot;Bronchus&quot;), 
  cnames = paste(c(&quot;Stomach&quot;,&quot;Colon&quot;,&quot;Ovary&quot;,&quot;Breast&quot;), &quot;/&quot;, &quot;Bronchus&quot;, sep = &quot;&quot;))</code></pre>
<pre><code>                 estimate  lower  upper
Stomach/Bronchus    1.352 0.6314  2.893
Colon/Bronchus      2.162 1.0644  4.391
Ovary/Bronchus      4.180 1.5671 11.147
Breast/Bronchus     6.597 2.9663 14.673</code></pre>
<p>Now suppose we specify the same variance structure directly. Note
that the results are <em>identical</em>.</p>
<pre class="r"><code>m &lt;- glm(Survival ~ Organ, family = quasi(link = log, variance = &quot;mu^2&quot;), data = CancerSurvival)
cbind(summary(m)$coefficients, confint(m))</code></pre>
<pre><code>             Estimate Std. Error t value  Pr(&gt;|t|)    2.5 % 97.5 %
(Intercept)    5.3546     0.2504 21.3854 1.773e-29  4.90101  5.889
OrganStomach   0.3013     0.3804  0.7923 4.314e-01 -0.44036  1.068
OrganColon     0.7709     0.3541  2.1772 3.348e-02  0.06991  1.472
OrganOvary     1.4302     0.4902  2.9174 4.987e-03  0.52462  2.486
OrganBreast    1.8867     0.3995  4.7228 1.479e-05  1.11572  2.702</code></pre>
<pre class="r"><code>contrast(m, tf = exp,
  a = list(Organ = c(&quot;Stomach&quot;,&quot;Colon&quot;,&quot;Ovary&quot;,&quot;Breast&quot;)),
  b = list(Organ = &quot;Bronchus&quot;), 
  cnames = paste(c(&quot;Stomach&quot;,&quot;Colon&quot;,&quot;Ovary&quot;,&quot;Breast&quot;), &quot;/&quot;, &quot;Bronchus&quot;, sep = &quot;&quot;))</code></pre>
<pre><code>                 estimate  lower  upper
Stomach/Bronchus    1.352 0.6314  2.893
Colon/Bronchus      2.162 1.0644  4.391
Ovary/Bronchus      4.180 1.5671 11.147
Breast/Bronchus     6.597 2.9663 14.673</code></pre>
<p>Naturally we should check the residuals to see if the variance
structure is reasonable.</p>
<pre class="r"><code>plot(predict(m), rstandard(m), main = &quot;Residual Plot&quot;)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-14-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Example</strong>: Consider the following observations of dry
weight (in grams) and rostro-carinal length (in mm) of a species of
barnacles sampled from the inter-tidal zones near Punta Lens and Punta
de la Barca along the Atlantic coast of Spain.</p>
<pre class="r"><code>library(npregfast)
head(barnacle)</code></pre>
<pre><code>    DW   RC     F
1 0.14  9.5 barca
2 0.00  2.4 barca
3 0.42 13.1 barca
4 0.01  3.7 barca
5 0.03  5.6 barca
6 1.56 18.6 barca</code></pre>
<pre class="r"><code>p &lt;- ggplot(barnacle, aes(x = RC, y = DW))
p &lt;- p + geom_point(alpha = 0.25) + facet_wrap(~ F) + theme_minimal()
p &lt;- p + labs(x = &quot;Rostro-Carinal Length (mm)&quot;, y = &quot;Dry Weight (g)&quot;)
plot(p)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-15-1.png" width="100%" style="display: block; margin: auto;" />
A common allometric regression model would have the form <span
class="math display">\[
  E(Y_i) = ax_i^b
\]</span> where <span class="math inline">\(Y_i\)</span> is the dry
weight for the <span class="math inline">\(i\)</span>-th observation,
and <span class="math inline">\(x_i\)</span> is the rostro-carinal
length for the <span class="math inline">\(i\)</span>-th observation. We
can also write this as <span class="math display">\[
  \log E(Y_i) = \log a + b\log x_i
\]</span> or, equivalently, <span class="math display">\[
    E(Y_i) = \exp(\log a + b\log x_i)
\]</span><br />
or <span class="math display">\[
  E(Y_i) = \exp(\beta_0 + \beta_1 \log x_i)
\]</span> where <span class="math inline">\(\beta_0 = \log a\)</span>
and <span class="math inline">\(\beta_1 = b\)</span>. This is basically
a log-linear model since we can write <span class="math display">\[
  \log E(Y_i) = \beta_0 + \beta_1 \log x_i.
\]</span> Because dry weight is continuous and positive, with the
variability appearing to increase with the expected dry weight, we might
specify a gamma distribution for dry weight.</p>
<pre class="r"><code>barnacle &lt;- subset(barnacle, DW &gt; 0) # remove observations of zero weight to avoid errors
m &lt;- glm(DW ~ F + log(RC) + F:log(RC), family = Gamma(link = log), data = barnacle)
summary(m)$coefficients</code></pre>
<pre><code>              Estimate Std. Error  t value  Pr(&gt;|t|)
(Intercept)   -8.06129    0.03898 -206.786 0.0000000
Flens         -0.15688    0.05724   -2.741 0.0061837
log(RC)        2.84234    0.01585  179.296 0.0000000
Flens:log(RC)  0.07884    0.02315    3.405 0.0006744</code></pre>
<pre class="r"><code>d &lt;- expand.grid(F = c(&quot;barca&quot;,&quot;lens&quot;), RC = seq(2.3, 24, length = 100))
d$yhat &lt;- predict(m, newdata = d, type = &quot;response&quot;)
p &lt;- p + geom_line(aes(y = yhat), color = &quot;red&quot;, data = d)
plot(p)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-16-1.png" width="100%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># effect of a 20% increase in RC
contrast(m, tf = exp,
    a = list(F = c(&quot;barca&quot;,&quot;lens&quot;), RC = 6),
    b = list(F = c(&quot;barca&quot;,&quot;lens&quot;), RC = 5), 
    cnames = c(&quot;barca&quot;,&quot;lens&quot;))</code></pre>
<pre><code>      estimate lower upper
barca    1.679 1.670 1.689
lens     1.703 1.693 1.714</code></pre>
<pre class="r"><code># comparing the two locations at different values of RC
contrast(m, tf = exp,
    a = list(F = &quot;lens&quot;, RC = c(10,15,20)),
    b = list(F = &quot;barca&quot;, RC = c(10,15,20)),
    cnames = c(&quot;10mm&quot;,&quot;15mm&quot;,&quot;20mm&quot;))</code></pre>
<pre><code>     estimate lower upper
10mm    1.025 1.004 1.046
15mm    1.058 1.034 1.083
20mm    1.083 1.048 1.118</code></pre>
<p>Checking the residuals.</p>
<pre class="r"><code>plot(predict(m), rstudent(m), main = &quot;Residual Plot&quot;)
abline(-2,0)
abline(2,0)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-17-1.png" width="100%" style="display: block; margin: auto;" />
Note: Eliminating a couple of observations due to having a zero dry
weight is not of much consequence here since there are so many
observations. But if there were fewer observations this would not be a
good idea. A better approach would be to just specify the same model
using <code>quasi</code>. Note that using <code>quasi</code> with
<code>variance = "mu^2"</code> is effectively equivalent to using
<code>family = gamma</code>.</p>
<pre class="r"><code>m &lt;- glm(DW ~ F + log(RC) + F:log(RC), data = barnacle,
  family = quasi(link = &quot;log&quot;, variance = &quot;mu^2&quot;))
summary(m)$coefficients</code></pre>
<pre><code>              Estimate Std. Error  t value  Pr(&gt;|t|)
(Intercept)   -8.06129    0.03898 -206.786 0.0000000
Flens         -0.15688    0.05724   -2.741 0.0061837
log(RC)        2.84234    0.01585  179.296 0.0000000
Flens:log(RC)  0.07884    0.02315    3.405 0.0006744</code></pre>
<pre class="r"><code># effect of a 20% increase in RC
contrast(m, tf = exp,
    a = list(F = c(&quot;barca&quot;,&quot;lens&quot;), RC = 6),
    b = list(F = c(&quot;barca&quot;,&quot;lens&quot;), RC = 5), 
    cnames = c(&quot;barca&quot;,&quot;lens&quot;))</code></pre>
<pre><code>      estimate lower upper
barca    1.679 1.670 1.689
lens     1.703 1.693 1.714</code></pre>
<pre class="r"><code># comparing the two locations at different values of RC
contrast(m, tf = exp,
    a = list(F = &quot;lens&quot;, RC = c(10,15,20)),
    b = list(F = &quot;barca&quot;, RC = c(10,15,20)),
    cnames = c(&quot;10mm&quot;,&quot;15mm&quot;,&quot;20mm&quot;))</code></pre>
<pre><code>     estimate lower upper
10mm    1.025 1.004 1.046
15mm    1.058 1.034 1.083
20mm    1.083 1.048 1.118</code></pre>
<p>Checking the residuals.</p>
<pre class="r"><code>plot(predict(m), rstudent(m), main = &quot;Residual Plot&quot;)
abline(-2,0)
abline(2,0)</code></pre>
<p><img src="lecture-03-25-2024_files/figure-html/unnamed-chunk-19-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Inverse-gaussian GLMs are similar. There the variance increases a bit
faster with the expected response. To estimate such a model use
<code>family = inverse.gaussian</code>. An equivalent model is to use
<code>quasi</code> with <code>variance = mu^3</code>.</p>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Consistency is a rather technical condition, but roughly
speaking a <em>consistent estimator</em> is one such that its sampling
distribution becomes increasingly concentrated around the value being
estimated as <span class="math inline">\(n\)</span> increases.<a
href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
