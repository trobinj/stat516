---
output:
  html_document:
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "03-30-2022"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{array}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "", message = FALSE, out.width = "100%", fig.align = "center", fig.width = 9, cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages, echo = FALSE}
library(tidyverse)
library(kableExtra)
library(trtools)
```

```{r utilities, echo = FALSE}
source("../../utilities.R")
```

```{r options, echo = FALSE}
options(digits = 4, width = 90)
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

## Alternative Link Functions

Recall that a link function $g$ in a generalized linear model (or extensions thereof) is a function so that
$$
  g[E(Y)] = \eta \ \ \text{where} \ \ \eta = \beta_0 + \beta_1x_1 + \cdots + \beta_kx_k.
$$
This gives us the mean structure
$$
  E(Y) = g^{-1}(\eta). 
$$
Note: To keep the notation clean I will omit the observation index $i$.

It is useful to distinguish between two families of link functions: those for binomial regression and those for regression models for positive (or non-negative) response variables.

## Alternative Link Functions for Binomial Regression

### Logit Link Function

Let $Y$ be a proportion or binary response variable. The logit link function is defined as
$$
	g[E(Y)] = \log\left[\frac{E(Y)}{1-E(Y)}\right],
$$
which implies the mean structure
$$
	E(Y) = \frac{e^{\eta}}{1+e^{\eta}}.
$$
Properties:

1. "Symmetric" in the sense that $g(z) = -g(1-z)$. Whether we model the probability of one event or the other is only a choice of parameterization. 

2. Allows (easy) use of odds ratios. 

3. Connects logistic regression to a variety of models (e.g., multinomial regression) and designs (e.g., case-control studies). 

Known as `logit` in functions like `glm`. The inverse function $e^z/(1 + e^z)$ is known to R as `plogis`. This is the default link function for the `binomial` family. 

**Example**: It is useful to note the "symmetry" of the model in that we can model either the event or its complement.
```{r}
library(trtools) # for bliss data

# modeling the probability of beetle death
m <- glm(cbind(dead, exposed - dead) ~ concentration, 
  family = binomial(link = logit), data = bliss)
summary(m)$coefficients
# modeling the probability of beetle survival
m <- glm(cbind(exposed - dead, dead) ~ concentration, 
  family = binomial(link = logit), data = bliss)
summary(m)$coefficients
```

<!-- ### Probit Link Function -->

<!-- Defined as -->
<!-- $$ -->
<!-- 	g[E(Y_i)] = F^{-1}[E(Y_i)]  -->
<!-- $$ -->
<!-- which implies the mean structure -->
<!-- $$ -->
<!--   E(Y_i) = F(\eta_i), -->
<!-- $$ -->
<!-- where $F(z) = P(Z \le z)$ is the *(cumulative) distribution function* for a standard normal random variable $Z \sim N(0, 1)$.  -->

<!-- The probit link function is known as `probit` in functions like `glm`. The inverse is known to R as `pnorm`. -->

<!-- Properties: -->

<!-- 1. Symmetric in the sense that $g(z) = -g(1-z)$. -->

<!-- 2. Very similar to the logit link function --- often indistinguishable empirically.  -->

<!-- 3. Used in "probit analysis" where the response is assumed to depend on an unobserved normally-distributed response $Z_i$. Let $Z_i \sim N(\mu_i,\sigma)$ be an *unobserved* (latent) response, where -->
<!-- $$ -->
<!--   E(Z_i) = \mu_i = \beta_0 + \beta_1 x_i -->
<!-- $$ -->
<!-- and let $Y_i = I(Z_i > c)$ such that. -->
<!-- $$ -->
<!--   Y_i = -->
<!--   \begin{cases} -->
<!--     1, & \text{$Z_i > c$}, \\ -->
<!--     0, & \text{$Z_i \le c$}. -->
<!--   \end{cases} -->
<!-- $$ -->
<!-- This then implies that $P(Y_i = 1) = F(\eta_i)$ where $\eta_i =\beta_0^* + \beta_1^* x_i$, $\beta_0^* = (\beta_0 - c)/\sigma$, and $\beta_1^* = \beta_1/\sigma$.  -->

<!--       If we assume a different distribution for $Z_i$, however, then we get a different link function because $F$ depends on the distribution. For example, if we assume that $Z_i$ has a *logistic* distribution, then we get the logit link function (which is where we get the name "logistic regression").  -->

<!-- **Example**: Suppose we have the normal linear model -->
<!-- $$ -->
<!--     E(Z_i) = \beta_0 + \beta_1 x_i, -->
<!-- $$ -->
<!-- where $\text{Var}(Z_i) = 1$. We can make inferences concerning this model using $Y_i = I(Z_i > 0)$ in a binomial regression model with the probit link function.  -->
<!-- ```{r} -->
<!-- set.seed(101) # to reproduce results -->
<!-- n <- 1000     # sample size -->
<!-- b0 <- 0       # "intercept" parameter -->
<!-- b1 <- 1       # "slope" parameter -->
<!-- c <- 0        # "threshold" -->
<!-- sigma <- 1    # response standard deviation -->

<!-- # simulate data -->
<!-- d <- data.frame(x = seq(-2, 2, length = n)) -->
<!-- d$z <- rnorm(n, b0 + b1*d$x, sigma) -->

<!-- # normal/linear regression -->
<!-- m <- lm(z ~ x, data = d) # could also use glm with family = gaussian -->
<!-- cbind(summary(m)$coefficients, confint(m)) -->
<!-- ``` -->
<!-- Now consider a binary response $Y_i = I(Z_i > c)$. Because $c$ = 0 and $\sigma$ = 1 then $\beta_0^* = \beta_0$ and $\beta_1^* = \beta_1$ for easy comparison. -->
<!-- ```{r} -->
<!-- d$y <- ifelse(d$z > c, 1, 0) -->

<!-- # binomial regression with probit link function -->
<!-- m <- glm(y ~ x, family = binomial(link = probit), data = d) -->
<!-- cbind(summary(m)$coefficients, confint(m)) -->
<!-- ``` -->
<!-- Note the similarities (and differences) in the inferences. -->

<!-- We could do something similar with a logistic distribution and the logit link function. -->
<!-- ```{r} -->
<!-- set.seed(123) # to reproduce results -->
<!-- n <- 1000     # sample size -->
<!-- b0 <- 0       # "intercept" parameter -->
<!-- b1 <- 1       # "slope" parameter -->
<!-- c <- 0        # "threshold" -->
<!-- scale <- 1    # "scale" parameter of logistic distribution -->

<!-- # simulate data -->
<!-- d <- data.frame(x = seq(-2, 2, length = n)) -->
<!-- d$z <- rlogis(n, b0 + b1*d$x, scale) -->
<!-- d$y <- ifelse(d$z > c, 1, 0) -->

<!-- # binomial regression with logit link function -->
<!-- m <- glm(y ~ x, family = binomial(link = logit), data = d) -->
<!-- cbind(summary(m)$coefficients, confint(m)) -->
<!-- ``` -->

### Complementary Log-Log Link Function

Defined as
$$
	g[E(Y)] = \log[-\log[1-E(Y)]],
$$
which implies the mean structure
$$
	E(Y_i) = 1 - e^{-e^{\eta_i}}.
$$
Known as `cloglog` to functions like `glm`. 

Properties: 

1. Not symmetric. Approaches 1 faster than 0.

2. Variety of applications in bio-assay, epidemiology, and survival analysis. 

3. Can be used when the observed response is assumed to depend on an underlying Poisson-distributed count. Let $Z$ be an *unobserved* response with a *Poisson* distribution with mean $e^{\eta}$, and let
$$
  Y_i =
  \begin{cases}
    1, & \text{if $Z > 0$}, \\
    0, & \text{if $Z = 0$}.
  \end{cases}
$$
Because
$$
  P(Z = z) = \frac{\lambda^z e^{-\lambda}}{z!}
$$
then
$$
  P(Y = 1) = 1 - P(Z = 0) = 1 - e^{-\lambda}.
$$
Assuming a Poisson regression model such that $\eta = \exp(\beta_0 + \beta_1 x_1 + \cdots + \beta_k x_k)$ then 
$$
    P(Y = 1) = 1 - e^{-e^{\eta}}.
$$

    **Example**: Suppose have the Poisson regression model 
$$
    E(Z_i) = \exp(\beta_0 + \beta_1 x_i),
$$
but we only observe if the count is greater than zero so what we observe is the binary response
$$
  Y_i =
  \begin{cases}
    1, & \text{if $Z_i > 0$}, \\
    0, & \text{if $Z_i = 0$}.
  \end{cases}
$$
We can make inferences concerning this model using $Y_i$ in a binomial regression model with the complementary log-log link function.
    ```{r}
    set.seed(123) # to reproduce results
    n <- 1000 # sample size
    b0 <- 0 
    b1 <- 1 

    # simulate data
    d <- data.frame(x = seq(-2, 2, length = n))
    d$z <- rpois(n, lambda = exp(b0 + b1*d$x))

    # Poisson regression
    m <- glm(z ~ x, family = poisson, data = d)
    cbind(summary(m)$coefficients, confint(m))

    d$y <- ifelse(d$z > 0, 1, 0) # create binary response

    # binomial regression with complementary log-log link function
    m <- glm(y ~ x, family = binomial(link = cloglog), data = d)
    cbind(summary(m)$coefficients, confint(m))
    ```
    Note the similarities (and differences) in the inferences.

### Log-Log Link Function

Defined as
$$
	g[E(Y)] = \log[-\log E(Y)]
$$
which implies the mean structure
$$
  E(Y) = e^{-e^{\eta}}.
$$
Properties: 

1. Not symmetric. Approaches 1 slower than it approaches 0.

2. Not usually available in software, but is available as `loglog` from the **trtools** package. 

3. Related to the complementary log-log link function in that if the probability of an event occurring is modeled using a complementary log-log link function, then the probability of an event *not* occurring can be modeled using the log-log link function.

    **Example**: The following two models are equivalent.
    ```{r}
    library(trtools) # for bliss data and loglog link function
    
    m <- glm(cbind(dead, exposed - dead) ~ concentration, 
      family = binomial(link = loglog), data = bliss)
    summary(m)$coefficients
    m <- glm(cbind(exposed - dead, dead) ~ concentration, 
      family = binomial(link = cloglog), data = bliss)
    summary(m)$coefficients
    ```

## Comparison of Link Functions for Binomial Regression

**Example**: Consider again the `bliss` data. The link function is specified through `family = binomial(link = X)` where `X` is `logit`, `cloglog`, and `loglog`. Note that we can use these link functions for other "families" such as `quasi` and `quasibinomial`. 

```{r, echo = FALSE, message = FALSE, fig.height = 4, fig.width = 8}
mydat <- data.frame(concentration = seq(min(bliss$concentration)-10, 
    max(bliss$concentration)+10, length = 100))

myreg <- glm(cbind(dead,exposed-dead) ~ concentration, data = bliss, 
             family = binomial(link = logit)) # logit

mydat$yhat.logit <- predict(myreg, newdata = mydat, type = "response")

myreg <- glm(cbind(dead,exposed-dead) ~ concentration, data = bliss,
             family = binomial(link = cloglog)) # comp. log-log

mydat$yhat.cloglog <- predict(myreg, newdata = mydat, type = "response")

myreg <- glm(cbind(dead,exposed-dead) ~ concentration, data = bliss,
             family = binomial(link = loglog)) # log-log

mydat$yhat.loglog <- predict(myreg, newdata = mydat, type = "response")

p <- ggplot(bliss, aes(x = concentration, y = dead/exposed)) + geom_point()
p <- p + geom_line(aes(y = yhat.logit), data = mydat) + ylim(0,1)
p1 <- p + ggtitle("Logit") + theme_classic()

p <- ggplot(bliss, aes(x = concentration, y = dead/exposed)) + geom_point()
p <- p + geom_line(aes(y = yhat.cloglog), data = mydat) + ylim(0,1)
p2 <- p + ggtitle("Complementary Log-Log") + theme_classic()

p <- ggplot(bliss, aes(x = concentration, y = dead/exposed)) + geom_point()
p <- p + geom_line(aes(y = yhat.loglog), data = mydat) + ylim(0,1)
p3 <- p + ggtitle("Log-Log") + theme_classic()

cowplot::plot_grid(p1, p2, p3, ncol = 3)
```
There are other link functions available in R including `probit` and `cauchit`. In theory, there are an infinity of link functions that could be considered. But here we will consider some nicely motivated link functions that have been used in practice. 

## Natural Response

Logistic regression has the mean structure
$$
	E(Y) = \frac{e^{\eta}}{1 + e^{\eta}},
$$
such that $E(Y) \rightarrow 1$ as $\eta \rightarrow \infty$ and $E(Y) \rightarrow 0$ as $\eta \rightarrow -\infty$. And recall that $E(Y)$ is also the *probability* of the event. In some cases it may not be true that $E(Y) \rightarrow 0$ as $\eta \rightarrow -\infty$.

For simplicity, consider the case where $Y$ is a binary response so that $Y = 0$ or $Y = 1$. Let $N$ be the event that we observe a *natural response* and $\bar{N}$ the event that we do not observe a natural response. Then
$$
  P(Y = 1) = P(Y = 1|N)P(N) + P(Y = 1|\bar{N})P(\bar{N}) = 
  P(N) + P(Y = 1|\bar{N})P(\bar{N}),
$$
noting that $P(Y=1|N) = 1$. If we let $P(N) = \gamma$ and assume that the "non-natural" response follows a logistic regression model so that
$$
  P(Y = 1|\bar{N}) = \frac{e^{\eta}}{1 + e^{\eta}},
$$
then
$$
  P(Y = 1) = \gamma + (1-\gamma)\frac{e^{\eta}}{1 + e^{\eta}},
$$
noting that $P(\bar{N}) = 1 - P(N) = 1 - \gamma$. In general we can write
$$
  E(Y) = \gamma + (1-\gamma)\frac{e^{\eta}}{1 + e^{\eta}},
$$

or 
$$
  \log\left[\frac{E(Y)-\gamma}{1 - E(Y)}\right]  = \eta.
$$
This effectively requires us to modify the *link function* if $\gamma > 0$. For making inferences we must consider two cases: (1) $\gamma$ is *known* and can be specified as part of the link function, and (2) $\gamma$ is *unknown* and must be estimated as an additional parameter. Also note that we can have a natural response variants of other link functions.

**Example**: Consider again the `bliss` data. Suppose we *know* that $\gamma$ = 0.1 (i.e., there is a probability of 0.1 that a beetle will die *naturally* during the experiment and not due to exposure to carbon disulphide).
```{r, message = FALSE}
m <- glm(cbind(dead, exposed - dead) ~ concentration, 
  data = bliss, family = binomial)
summary(m)$coefficients
```
Using the natural response link function sometimes requires starting values. An easy way to specify them is to take estimates when using the logit link function.
```{r}
m.nr <- glm(cbind(dead, exposed - dead) ~ concentration, data = bliss, 
  family = binomial(link = logitnr(0.1)), start = c(-14.8, 0.25))
summary(m.nr)$coefficients
```
The interpretation of an odds ratio for this model would be for the odds of death *due to carbon disulphide* (rather than "natural causes"). 
```{r}
d <- data.frame(concentration = seq(40, 80, length = 100))
d$yhat <- predict(m, newdata = d, type = "response")
d$yhat.nr <- predict(m.nr, newdata = d, type = "response")

p <- ggplot(bliss, aes(x = concentration, y = dead/exposed)) + 
  geom_point() + ylim(0,1) + labs(x = "Concentration", y = "Proportion") + 
  geom_line(aes(y = yhat), data = d) + theme_classic() + 
  geom_line(aes(y = yhat.nr), data = d, linetype = 2) + 
  geom_hline(yintercept = 0.1, color = grey(0.5))
plot(p)
```
When $\gamma$ is unknown the model is no longer a traditional GLM because there is an unknown parameter in the link function. But we can make inferences using maximum likelihood. This requires a bit of programming. 

**Example**: Consider again the `bliss` data and model with the logit link function with a natural response. The log-likelihood function is
$$
	\log L  = \sum_{i=1}^n \log \left[\frac{m_i!}{r_i!(m_i-r_i)!}p_i^{r_i}(1-p_i)^{m_i-r_i}\right]
$$
where
$$
	p_i = \gamma + (1 - \gamma)\frac{e^{\eta_i}}{1 + e^{\eta_i}} \ \ \text{and} \ \ \eta_i = \beta_0 + \beta_1 d_i,
$$
where $d_i$ is dose. 

We can program the *negative* log-likelihood function.
```{r}
nloglik <- function(beta0, beta1, gamma) {
  eta <- beta0 + beta1 * concentration
  prb <- gamma + (1 - gamma) * plogis(eta)
  return(-sum(dbinom(dead, exposed, prb, log = TRUE)))
}
```
Now we can use another function (`mle2`) that will solve the maximization (minimization) problem. 
```{r, message = FALSE}
library(bbmle)
m <- mle2(nloglik, data = bliss, method = "L-BFGS-B",
  start = list(beta0 = -15, beta1 = 0.25, gamma = 0.1),
  lower = list(beta0 = -Inf, beta1 = -Inf, gamma = 0),
  upper = list(beta0 =  Inf, beta1 =  Inf, gamma = 1))
summary(m)
trtools::lincon(m, a = c(0,1,0), tf = exp, fest = coef, fcov = vcov) # odds ratio
```
We can also consider a variation on the "natural response" link function where the *upper* asymptote is $\delta < 1$, or both lower and upper asymptotes of $0 < \gamma < \delta < 1$. The model is then
$$
  E(Y) = \gamma + (\delta - \gamma)\frac{e^{\eta}}{1 + e^{\eta}}.
$$
A model with just an upper asymptote of $\delta < 1$ would be 
$$
  E(Y) = \delta\frac{e^{\eta}}{1 + e^{\eta}}.
$$
An example of an application with an upper asymptote of $\delta$ < 0 might be seed germination (some seeds are "duds" and will never germinate). In the **trtools** package there is a link function called `logitnnr` which works like `logitnr` except it specifies an *upper* asymptote of $\delta < 0$. 

## Specialty Link Functions

### Logistic-Exposure Link Function

Suppose that the probability of "survival" each time unit (e.g., day) is $\pi$, and assume that 
$$
  \pi = \frac{e^{\eta}}{1 + e^{\eta}},
$$
where $\eta = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k$ as in a logistic regression model. But we do not observe survival for each time unit, only if there is survival for at least $t$ units. Let $Y$ = 1 if there is survival for at least $t$ units, and $Y$ = 0 otherwise. Then it can be shown that
$$
  E(Y) = P(Y = 1) = \left(\frac{e^{\eta}}{1 + e^{\eta}}\right)^t.
$$
This implies the *logistic-exposure* link function
$$
  \log\left[\frac{E(Y)^{1/t}}{1 + E(Y)^{1/t}}\right] = \eta.
$$
I have added this link function to **trtools** as `logitexp`. 

**Example**: Suppose we have the following data.
```{r}
library(dplyr)
set.seed(123)

b0 <- 2
b1 <- 1

d <- data.frame(x = seq(0, 3, length = 1000)) %>%
  mutate(days = sample(1:10, n(), replace = TRUE)) %>% 
  mutate(y = rbinom(n(), 1, plogis(b0 + b1*x)^days))
head(d)
```
We can estimate the logistic-exposure model as follows.
```{r}
library(trtools) # for logitexp link function
m <- glm(y ~ x, family = binomial(link = logitexp(exposure = d$days)), data = d)
cbind(summary(m)$coefficients, confint(m))
```

### Logistic Regression for Composite Sampling Designs

Suppose $Z$ has a binomial distribution consistent with a logistic regression model so that 
$$
  E(Z/m) = \frac{e^{\eta}}{1 + e^{\eta}},
$$
where $\eta = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k$. But we only observe $Y$ where
$$
  Y = 
  \begin{cases}
  1, & \text{if $Z > 0$}, \\
  0, & \text{if $Z = 0$}.
  \end{cases}
$$
This implies that
$$
  E(Y) = P(Y = 1) = 1 - (1 - \pi)^m,
$$
where $\pi = E(Z/m)$. Then the link function for $Y$ is
$$
  \log[(1-\pi)^{1/m}-1] = \eta.
$$
This can be applied in *composite sampling designs* where a composite of $m$ samples (e.g., blood, water, soil) will test positive *collectively* if any one of them would test positive *individually*. 

**Example**: Suppose we have the following data.
```{r}
library(dplyr)
set.seed(123)

d <- data.frame(m = sample(c(25,50,100,400), 100, replace = TRUE)) %>% 
  mutate(x = seq(-2, 2, length = n())) %>% 
  mutate(z = rbinom(n(), m, plogis(-5 + x/5)))
head(d)
```
And assume that the model for $Z$ is a logistic regression model.
```{r}
m <- glm(cbind(z, m - z) ~ x, family = binomial(link = logit), data = d)
summary(m)$coefficients
```
But now suppose we only observe $Y$ as defined above.
```{r}
d <- d %>% mutate(y = ifelse(z > 0, 1, 0))
head(d)
```
The model for $Y$ is a binomial regression model with the link function given above.
```{r}
library(trtools) # for the logitcomp link function
m <- glm(y ~ x, family = binomial(link = logitcomp(d$m)), data = d)
summary(m)$coefficients
```

### Logistic Regression for Classification Error

Suppose that $Z$ is a binary variable that is an indicator variable for the presence of a disease such that 
$$
  Z = 
  \begin{cases}
  1, & \text{if the subject has the disease}, \\
  0, & \text{if the subject does not have the disease}.
  \end{cases}
$$
But assume we do not observe $Z$ but instead observe only $Y$ which is an indicator variable for a *diagnostic test* for the disease such that 
$$
  Y = 
  \begin{cases}
  1, & \text{if the subject tests positive for the disease}, \\
  0, & \text{if the subject tests negative for the disease}.
  \end{cases}
$$
Diagnostic test accuracy is defined in terms of the *sensitivity* and *specificity* of the test, where
$$
  \text{sensitivity} = P(\text{test positive}|\text{disease}) = P(Y = 1|Z = 1)
$$
and 
$$
  \text{specificity} = P(\text{test negative}|\text{no disease}) = P(Y = 0|Z = 0).
$$
This implies that
$$
  P(Y = 1) = \underbrace{P(Y = 1|Z = 1)}_{\text{sensitivity}}P(Z = 1) + [1 - \underbrace{P(Y = 0|Z = 0)}_{\text{specificity}}]P(Z = 0).
$$
So if the model for the disease is a binary logistic regression model such that
$$
  E(Z) = P(Z = 1) = \frac{e^{\eta}}{1 + e^{\eta}},
$$
where $\eta = \beta_0 + \beta_1 x_1 + \cdots + \beta_k x_k$, then we have that the model for the test result is 
$$
  E(Y) = P(Y = 1) = \text{sensitivity} \times \frac{e^{\eta}}{1 + e^{\eta}} + (1 - \text{specificity})\left(1 - \frac{e^{\eta}}{1 + e^{\eta}}\right).
$$
The link function can then be written as
$$
  \log\left[\frac{E(Y) - (1 - \text{specificity})}{\text{sensitivity} - E(Y)}\right] = \eta.
$$
**Example**: Suppose we have the following data.
```{r}
library(dplyr)
set.seed(111)

d <- data.frame(x = seq(-3, 3, length = 1000)) %>%
  mutate(z = rbinom(n(), 1, plogis(x)))
head(d)
tail(d)
```
Here is a model for the disease indicator.
```{r}
m <- glm(z ~ x, family = binomial(link = logit), data = d)
summary(m)$coefficients
```
But suppose we have to use a diagnostic test with a sensitivity of 0.8 and a specificity of 0.9. Here is the data with the diagnostic test result.
```{r}
d <- d %>% 
  mutate(y = rbinom(n(), 1, ifelse(z == 1, 0.8, 1 - 0.9)))
head(d)
tail(d)
```
Here is the model using the diagnostic test as the response variable.
```{r}
library(trtools) # for logiterr link function
m <- glm(y ~ x, family = binomial(link = logiterr(0.8,0.9)), data = d)
summary(m)$coefficients
```

## Link Functions for Positive (or Non-Negative) Responses

The "power" family of link functions is defined as
$$
  g[E(Y)] =
  \begin{cases}
    E(Y)^q, & \text{if $q \neq 0$}, \\
    \log E(Y) & \text{if $q = 0$},
  \end{cases}
$$
so that
$$
  E(Y) = 
  \begin{cases}
    \eta^{1/q}, & \text{if $q \neq 0$}, \\
    e^{\eta}, & \text{if $q = 0$}. 
  \end{cases}
$$
This includes several common link functions such as log ($q$ = 0), identity ($q$ = 1), reciprocal ($q$ = -1), and square root ($q$ = 0.5). These can be specified as `link = log`, `link = identity`, `link = reciprocal`, and `link = sqrt`, respectively. Alternatively you can use `family = tweedie(link = q, variance = p)` for any value of $q$ (recall that `tweedie` is from the **statmod** package).

**Example**: Here are models with different power link functions for the `ceriodaphniastrain` data.
```{r, echo = FALSE}
library(trtools)
library(statmod)

ceriodaphniastrain$strainf <- factor(ceriodaphniastrain$strain, 
   levels = c(1,2), labels = c("a","b"))

d <- expand.grid(concentration = seq(0, 1.75, length = 100), strainf = c("a","b"))

m <- glm(count ~ concentration + strainf, family = tweedie(link.power = -1, var.power = 0), data = ceriodaphniastrain)
d$yhat1 <- predict(m, newdata = d, type = "response")

m <- glm(count ~ concentration + strainf, family = tweedie(link.power =  0, var.power = 0), data = ceriodaphniastrain)
d$yhat2 <- predict(m, newdata = d, type = "response")

m <- glm(count ~ concentration + strainf, family = tweedie(link.power = 0.5, var.power = 0), data = ceriodaphniastrain)
d$yhat3 <- predict(m, newdata = d, type = "response")

m <- glm(count ~ concentration + strainf, family = tweedie(link.power = 1, var.power = 0), data = ceriodaphniastrain)
d$yhat4 <- predict(m, newdata = d, type = "response")

d <- d %>% pivot_longer(cols = c(yhat1,yhat2,yhat3,yhat4), names_to = "power", values_to = "yhat") %>%
   mutate(power = factor(power, labels = paste("q =", c(-1,0,0.5,1))))

p <- ggplot(ceriodaphniastrain, aes(x = concentration, y = count, color = strainf)) + geom_point(alpha = 0.5) + theme_minimal()
p <- p + geom_line(aes(y = yhat), data = d) + facet_wrap(~ power, ncol = 4)
p <- p + labs(x = "Concentration", y = "Organisms", color = "Strain")
p <- p + theme(legend.position = c(0.7,0.7))
plot(p)
```

One could try to *estimate* the power of the link function using maximum likelihood (much like we did for the natural response link function). But in that case it is useful to use the link function
$$
    g[E(Y)] =
    \begin{cases}
        \frac{E(Y)^q - 1}{q}, & \text{if $q \neq 0$}, \\
        \log E(Y),            & \text{if $q = 0$}
    \end{cases}
$$
to make the function continuous with respect to $q$. This particular form uses the fact that
$$
    \lim_{q \rightarrow 0} \frac{E(Y)^q - 1}{q} = \log E(Y).
$$
It can be shown that this is a reparameterization of the power link function given above, but this form is better for numerical reasons when trying to estimate $q$ as a parameter.




