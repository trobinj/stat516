---
output:
  html_document:
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "03-04-2022"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{array}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "", message = FALSE, out.width = "100%", fig.align = "center", fig.width = 9, cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"))
```

```{r packages, echo = FALSE}
library(ggplot2)
library(trtools)
library(dplyr)
library(tidyr)
```

```{r utilities, echo = FALSE}
source("../../utilities.R")
```

```{r options, echo = FALSE}
options(digits = 4, width = 90)
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`

<!-- Note: This lecture needs more. It doesn't last 50 minutes. I'm thinking about adding the Minnesota radon study at the end. -->

## Poisson Regression for Rates

The $i$-th observed *rate* $R_i$ can be written as
$$
	R_i = C_i/S_i,
$$
where $C_i$ is a *count* and $S_i$ is the "size" of the interval in which the counts are observed. Examples include fish per minute, epileptic episodes per day, or defects per (square) meter. In some cases $S_i$ is referred to as the "exposure" of the $i$-th observation. 

Assume that the count $C_i$ has a Poisson distribution and that
$$
  E(C_i) = S_i \underbrace{\exp(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik})}_{\lambda_i},
$$
where $\lambda_i$ is the expected count *per unit* (e.g., per minute) so that $S_i\lambda_i$ is then the expected count per $S_i$ (e.g., per hour if $S_i$ = 60, per day if $S_i$ = 1440, or per second if $S_i$ = 1/60). The expected *rate* is then
$$
  E(R_i) = E(C_i/S_i) = E(C_i)/S_i = \exp(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik}),
$$
if we treat exposure as *fixed* (like we do $x_{i1}, x_{i2}, \dots, x_{ik}$). But rather than using $R_i$ as the response variable we can use $C_i$ as the response variable in a Poisson regression model where
$$
  E(C_i) = S_i \exp(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik})
         =  \exp(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik} + \log S_i),
$$
and where $\log S_i$ is an "offset" variable (i.e., basically an explanatory variable where it's $\beta_j$ is "fixed" at one). 

Note: If $S_i$ is a *constant* for all observations so that $S_i = S$ then we can write the model as 
$$
  E(C_i) = \exp(\beta_0 + \beta_1 x_{i1} + \cdots + \beta_k x_{ik} + \log S_i) =
  \exp(\beta_0^* + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}),
$$
where $\beta_0^* = \log(S) + \beta_0$ so that the offset is "absorbed" into $\beta_0$, and we do not need to be concerned about it. Including an offset is only necessary if $S_i$ is not the same for all observations.

## Variance of Rates

Using rates as response variables in a linear or nonlinear model without accounting for $S_i$ is not advisable because of heteroscedasticity due to unequal $S_i$.

Note that $E(C_i) = S_iE(R_i)$ and that $\text{Var}(C_i) = S_iE(R_i)$ if $C_i$ has a Poisson distribution. The variance of $R_i$ is then
$$
  \text{Var}(R_i) = \text{Var}(C_i/S_i) = \text{Var}(C_i)/S_i^2 = E(S_iR_i)/S_i^2 = S_iE(R_i)/S_i^2 = E(R_i)/S_i,
$$
if we treat $S_i$ as fixed. So the variance of a rate is *inversely proportional* to $S_i$. For example, suppose $E(R_i) = E(R_{i'}) = 0.5$, but $S_i = 2$ and $S_{i'} = 100$ so that $R_i = C_i/2$ and $R_{i'} = C_{i'}/100$. Then 
$$
  \text{Var}(R_i) = 0.5/2 = 0.25 > \text{Var}(R_{i'}) = 0.5/100 = 0.005.
$$
For this reason it is usually not advised to use rates as response variables without either (a) using an appropriate offset variable in Poisson regression or a related model or (b) using weights of $w_i = S_i/E(R_i)$ (via iteratively weighted least squares with weights of $w_i = S_i/\hat{y}_i$). 

## Modeling Rates with Poisson Regression

Software for GLMs (and sometimes linear models) will often permit specification of an offset variable. In R this is done using `offset` in the model formula. 

**Example**: Consider the following data from an observational study of auto accidents. 
```{r, message = FALSE}
library(trtools)
head(accidents)
p <- ggplot(accidents, aes(x = location, y = accidents/years)) +
  geom_point(aes(size = years, color = treatment)) + 
  labs(x = "Location", y = "Accidents per Year", 
    size = "Years", color = "Treatment") + theme_classic()
plot(p)
m <- glm(accidents ~ location + treatment + offset(log(years)), 
  data = accidents, family = poisson)
cbind(summary(m)$coefficients, confint(m))
exp(cbind(coef(m), confint(m)))
```
When using `contrast` we do need to specify the offset. Think of it as another explanatory variable.
```{r}
contrast(m,
  a = list(treatment = "before", location = letters[1:8], years = 1),
  b = list(treatment = "after", location = letters[1:8], years = 1),
  cnames = letters[1:8], tf = exp)
contrast(m,
  a = list(treatment = "after", location = letters[1:8], years = 1),
  b = list(treatment = "before", location = letters[1:8], years = 1),
  cnames = letters[1:8], tf = exp)
```
We also need to specify the offset when computing estimated expected rates. 
```{r}
d <- expand.grid(treatment = c("before","after"), 
  location = letters[1:8], years = 1)
d$yhat <- predict(m, newdata = d, type = "response")
d
p <- p + geom_point(aes(y = yhat, color = treatment), data = d)
p <- p + geom_line(aes(y = yhat, group = treatment, color = treatment), data = d)
plot(p)
```

## Computing Estimated Expected Rates

Using `predict` will produce estimated expected rates. Confidence intervals for estimating expected counts can be obtained using either `contrast` or `glmint`. We can estimate the expected number of accidents per year at each location before treatment.
```{r}
contrast(m, a = list(treatment = "before", location = letters[1:8], years = 1),
  cnames = paste("before at", letters[1:8]), tf = exp)
```
We can also estimate the expected number of accidents per *decade*. 
```{r}
contrast(m, a = list(treatment = "before", location = letters[1:8], years = 10),
  cnames = paste("before at", letters[1:8]), tf = exp)
```
Alternatively the `glmint` function can be used, which is more convenient for producing plots. 
```{r, warning = TRUE}
d <- expand.grid(treatment = c("before","after"), 
  location = letters[1:8], years = 1)
glmint(m, newdata = d)
cbind(d, glmint(m, newdata = d))
d <- cbind(d, glmint(m, newdata = d))
p <- ggplot(accidents, aes(x = location)) + 
  geom_point(aes(y = accidents/years, size = years), shape = 21, fill = "white") + 
  facet_wrap(~ treatment) + theme_minimal() + 
  labs(x = "Location", y = "Accidents per Year", size = "Years") + 
  geom_errorbar(aes(ymin = low, ymax = upp), data = d) + 
  geom_point(aes(y = fit), data = d)
plot(p)
p <- ggplot(accidents, aes(x = location, color = treatment)) + 
  geom_point(aes(y = accidents/years, size = years), 
    position = position_dodge(width = 0.6), shape = 21, fill = "white") + 
  labs(x = "Location", y = "Accidents per Year", 
    size = "Years", color = "Treatment") + theme_minimal() + 
  geom_errorbar(aes(ymin = low, ymax = upp), data = d, 
    position = position_dodge(width = 0.6), width = 0.5) + 
  geom_point(aes(y = fit), data = d, position = position_dodge(width = 0.6))
plot(p)
```

**Example**: Consider the following data from a study that investigated the possible effect of the development of a commercial fishery on deep sea fish abundance. The figure below shows the number of fish per square meter of swept area from 147 trawls by mean depth in meters, and by whether the trawl was during one of two periods. The 1977-1989 period was from before the development of a commercial fishery, and the period 2000-2002 was when the fishery was active.
```{r}
library(COUNT)
data(fishing)
head(fishing)
p <- ggplot(fishing, aes(x = meandepth, y = totabund/sweptarea)) +
  geom_point(alpha = 0.5) + facet_wrap(~ period) + theme_minimal() +
  labs(x = "Mean Trawl Depth (meters)",
    y = "Fish Caught Per Square Meter Trawled")
plot(p)
```
An appropriate model for these data might be as follows.
```{r}
m <- glm(totabund ~ period * meandepth + offset(log(sweptarea)),
  family = poisson, data = fishing)
summary(m)$coefficients
d <- expand.grid(sweptarea = 1, period = c("1977-1989","2000-2002"), 
  meandepth = seq(800, 5000, length = 100))
d$yhat <- predict(m, newdata = d, type = "response")

p <- p + geom_line(aes(y = yhat), data = d)
plot(p)
```
What is the expected number of fish per square meter in 1977-1989 at depths of 1000, 2000, 3000, 4000, and 5000 meters? What is it in 2000-2002?
```{r}
contrast(m, 
  a = list(sweptarea = 1, 
    meandepth = c(1000,2000,3000,4000,5000), period = "1977-1989"),
  cnames = c("1000m","2000m","3000m","4000m","5000m"), tf = exp)
contrast(m, 
  a = list(sweptarea = 1,
    meandepth = c(1000,2000,3000,4000,5000), period = "2000-2002"),
  cnames = c("1000m","2000m","3000m","4000m","5000m"), tf = exp)
```
Note that we can change the units of swept area very easily here. There are 10,000 square meters in a hectare. Here are the expected number of fish per hectare. 
```{r}
contrast(m, 
  a = list(sweptarea = 10000,
    meandepth = c(1000,2000,3000,4000,5000), period = "1977-1989"),
  cnames = c("1000m","2000m","3000m","4000m","5000m"), tf = exp)
contrast(m, 
  a = list(sweptarea = 10000,
    meandepth = c(1000,2000,3000,4000,5000), period = "2000-2002"),
  cnames = c("1000m","2000m","3000m","4000m","5000m"), tf = exp)
```
What is the rate ratio of fish per square meter in 2000-2002 versus 1977-1989 at 1000, 2000, 3000, 4000, and 5000 meters?
```{r}
contrast(m, 
  a = list(sweptarea = 1,
    meandepth = c(1000,2000,3000,4000,5000), period = "2000-2002"),
  b = list(sweptarea = 1,
    meandepth = c(1000,2000,3000,4000,5000), period = "1977-1989"),
  cnames = c("1000m","2000m","3000m","4000m","5000m"), tf = exp)
```
Here it is for 1977-1989 versus 2000-2002.
```{r}
contrast(m, 
  a = list(sweptarea = 1,
    meandepth = c(1000,2000,3000,4000,5000), period = "1977-1989"),
  b = list(sweptarea = 1,
    meandepth = c(1000,2000,3000,4000,5000), period = "2000-2002"),
  cnames = c("1000m","2000m","3000m","4000m","5000m"), tf = exp)
```
How does the expected number of fish per square meter change per 1000m of depth?
```{r}
# increasing depth by 1000m
contrast(m,
  a = list(sweptarea = 1, meandepth = 2000, period = c("1977-1989","2000-2002")),
  b = list(sweptarea = 1, meandepth = 1000, period = c("1977-1989","2000-2002")),
  cnames = c("1977-1989","2000-2002"), tf = exp)
# decreasing depth by 1000m
contrast(m,
  a = list(sweptarea = 1, meandepth = 1000, period = c("1977-1989","2000-2002")),
  b = list(sweptarea = 1, meandepth = 2000, period = c("1977-1989","2000-2002")),
  cnames = c("1977-1989","2000-2002"), tf = exp)
```
Ratios are unit-less, so we get the same rate ratios when considering fish per hectare (i.e., per 10000 square meters). 
```{r}
# increasing depth by 1000m
contrast(m,
  a = list(sweptarea = 10000, 
    meandepth = 2000, period = c("1977-1989","2000-2002")),
  b = list(sweptarea = 10000,
    meandepth = 1000, period = c("1977-1989","2000-2002")),
  cnames = c("1977-1989","2000-2002"), tf = exp)
# decreasing depth by 1000m
contrast(m,
  a = list(sweptarea = 10000,
    meandepth = 1000, period = c("1977-1989","2000-2002")),
  b = list(sweptarea = 10000,
    meandepth = 2000, period = c("1977-1989","2000-2002")),
  cnames = c("1977-1989","2000-2002"), tf = exp)
```

## Standardized Mortality Ratios

In epidemiology, the *standardized mortality ratio* (SMR) is the ratio of the *observed* number of deaths and the (estimated) *expected* number of deaths. Poisson regression with an offset can be used to model the SMR to determine if the number of deaths tends to be higher or lower than we would expect.

**Example**: Here is an example of an observational study using a Poisson regression model to investigate the relationship between lung cancer and radon exposure in counties in Minnesota. 

Note: The data manipulation and plotting is quite a bit more complicated than what you will normally see in this class, but I have included it in case you might be interested to see the code.

First we will process the data containing the observed and expected number of deaths due to lung cancer, where the latter are based on the known distribution of age and gender in the county. 
```{r}
lung <- read.table("http://faculty.washington.edu/jonno/book/MNlung.txt", 
  header = TRUE, sep = "\t") %>% 
  mutate(obs = obs.M + obs.F, exp = exp.M + exp.F) %>% 
  dplyr::select(X, County, obs, exp) %>%
  rename(county = County) %>% 
  mutate(county = tolower(county)) %>% 
  mutate(county = ifelse(county == "red", "red lake", county))
head(lung)
```
Now we will read in data to estimate the average radon exposure of residents of each county.
```{r}
radon <- read.table("http://faculty.washington.edu/jonno/book/MNradon.txt",
  header = TRUE) %>% group_by(county) %>% 
  summarize(radon = mean(radon)) %>% rename(X = county)
head(radon)
```
Next we merge the two data frames.
```{r}
radon <- left_join(lung, radon) %>% dplyr::select(-X)
head(radon)
```
For fun we can make some plots of the data by county.
```{r}
library(maps)
dstate <- map_data("state") %>% 
  filter(region == "minnesota")
dcounty <- map_data("county") %>% 
  filter(region == "minnesota") %>% 
  rename(county = subregion)
dcounty <- left_join(dcounty, radon) %>% 
  mutate(smr = obs/exp)
```

```{r}
no_axes <- theme_minimal() + theme(
  axis.text = element_blank(),
  axis.line = element_blank(),
  axis.ticks = element_blank(),
  panel.border = element_blank(),
  panel.grid = element_blank(),
  axis.title = element_blank()
)

p <- ggplot(dcounty, aes(x = long, y = lat, group = group)) + coord_fixed(1.3) +
  geom_polygon(aes(fill = exp), color = "black", size = 0.25) + 
  scale_fill_gradient(low = grey(0.95), high = grey(0.25), 
    trans = "log10", na.value = "pink") + 
  theme(legend.position = c(0.8,0.4)) + no_axes + 
  ggtitle("Expected Number of Cases") + labs(fill = "Cases")

plot(p)

p <- ggplot(dcounty, aes(x = long, y = lat, group = group)) + coord_fixed(1.3) +
  geom_polygon(aes(fill = smr), color = "black", size = 0.25) + 
  scale_fill_gradient(low = grey(0.95), high = grey(0.25), na.value = "pink") +
  theme(legend.position = c(0.8,0.4)) + no_axes +
  ggtitle("Standardized Mortality Ratio") + labs(fill = "SMR")

plot(p)

p <- ggplot(dcounty, aes(x = long, y = lat, group = group)) + coord_fixed(1.3) + 
  geom_polygon(aes(fill = radon), color = "black", size = 0.25) + 
  scale_fill_gradient(low = grey(0.95), high = grey(0.25), na.value = "pink") + 
  theme(legend.position = c(0.8,0.4)) + no_axes +
  ggtitle("Average Radon (pCi/liter)") + labs(fill = "Radon")

plot(p)
```
How does the expected SMR relate to radon? Consider the Poisson regression model
$$
  \log E(Y_i/E_i) = \beta_0 + \beta_1r_i,
$$
where $Y_i$ and $E_i$ are the observed and expected number of lung cancer deaths (or cases), respectively, in the $i$-th county, and $r_i$ is the average radon exposure in the $i$-th county. Here $Y_i/E_i$ is the SMR for the $i$-th county. We can also write this model as
$$
  \log E(Y_i) = \log E_i  + \beta_0 + \beta_1r_i,
$$
so $\log E_i$ is an *offset*.
```{r}
m <- glm(obs ~ offset(log(exp)) + radon, 
  family = poisson, data = dcounty)
summary(m)$coefficients
exp(cbind(coef(m), confint(m)))
```
We should be careful and remember the [ecological fallacy](https://en.wikipedia.org/wiki/Ecological_fallacy) which states that relationships at the group level (e.g., county) do not necessarily hold at the individual level. Radon may be related to other variables (e.g., smoking) that affect the risk of lung cancer.