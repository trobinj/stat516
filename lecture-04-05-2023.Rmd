---
output:
  html_document: 
    theme: readable
  pdf_document: default
---

```{r, echo = FALSE, message = FALSE}
library(lubridate)
date <- "04-05-2023"
weekday <- wday(mdy(date), label = TRUE, abbr = FALSE)
month <- month(mdy(date), label = TRUE)
day <- day(mdy(date))
```

---
title: `r paste(weekday, ", ", month, " ", day, sep = "")`
output:
  html_document: 
    theme: readable
  pdf_document: default
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, out.width = "100%", fig.align = "center", cache = FALSE, dev = ifelse(knitr::is_html_output(), "png", "pdf"), comment = "")
```

```{r packages, echo = FALSE}
library(tidyverse)
suppressWarnings(library(kableExtra))
```

```{r options, echo = FALSE}
options(digits = 4, width = 100)
```

`r ifelse(knitr::is_html_output(), paste("You can also download a [PDF](lecture-", date, ".pdf) copy of this lecture.", sep = ""), "")`


## Survival Analysis

In survival analysis the response variable is time-till-event defined as
$$
	T_i = T_i^{(E)} - T_i^{(0)} \ge 0,
$$
where $T_i^{(0)}$ is the starting time and $T_i^{(E)}$ is the time of the event, so that $T_i$ is the time-till-event.

Issues with modeling time-to-event:

1. Distribution of $T_i$ tends to be right-skewed and heteroscedastic with the variance increasing with $E(T_i)$.

2. Times may be *censored*. Right-censoring and interval-censoring are particularly common.

3. Time-varying covariates. Explanatory variables may change values over time. 

### Censored Observations

Censoring of a variable occurs when we only know that the response variable is within a set or range of values. Common types of censoring are right-censoring, left-censoring, and interval-censoring.

**Right-Censoring**: We only know that $T > c$ for some constant $c$. This is very common in survival analysis. It often occurs when the event has not yet happened when observations are stopped, or when the researchers lose track of an observation unit.

**Left-Censoring**: We only know that $T < c$ for some constant $c$. This may happen because the event had already happened prior to when we started observation. 

**Interval-Censoring**: We only know that $a < T < b$ for some constants $a < b$. Note that right-censoring can be viewed as a special case where $b = \infty$ and left-censoring can be viewed as a special case where $a = 0$. Interval censoring occurs in survival analysis when units are only periodically observed.

Note that censoring can occur for variables other than time to event. 
**Example**: Consider the following data from a study of the effect of normal versus extended chemotherapy on the survival of patients with acute myelogenous leukemia.
```{r}
library(survival)

leukemia$censored <- factor(leukemia$status, levels = c(0,1),
  labels = c("yes","no")) # right-censored?
leukemia
```
```{r, echo = FALSE}
library(ggplot2)

leukemia$treatment <- leukemia$x
levels(leukemia$treatment) <- c("yes","no")

p <- ggplot(leukemia, aes(x = treatment, y = time, fill = censored))
p <- p + geom_dotplot(binaxis = "y", method = "histodot",
    binwidth = 1, dotsize = 2)
p <- p + scale_fill_manual(name = "Censored?", values = c("white","black"))
p <- p + xlab("Maintained") + ylab("Remission Time (weeks)")
p <- p + theme_classic()
plot(p)
```
```{r, echo = FALSE, message = FALSE, warning = FALSE}
d <- leukemia
d$xend <- ifelse(leukemia$censored == "yes", 170, NA)
d$obs <- factor(1:23)
d$x <- relevel(d$x, ref = "Nonmaintained")
p <- ggplot(d, aes(x = time, y = obs))
p <- p + xlim(0, 170)
p <- p + geom_segment(aes(x = time, xend = xend, y = obs, yend = obs),
  arrow = arrow(length = unit(0.1, "cm")))
p <- p + geom_point(aes(fill = censored), shape = 21)
p <- p + scale_fill_manual(name = "Censored?", values = c("white","black"))
p <- p + xlab("Remission Time (weeks)") + ylab("Observation")
p <- p + facet_grid(x ~ ., scales = "free", space = "free")
p <- p + theme_minimal()
plot(p)
```
**Example**: Consider the following data from a study on the effect of temperature on the operational time of motors.
```{r, message = FALSE}
library(MASS)
head(motors) # note: cens = 0 if observation IS censored
tail(motors)
```
```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.height = 6}
library(MASS)
motors$obs <- factor(1:nrow(motors))
motors$cens <- factor(motors$cens, labels = c("yes","no"))
motors$xend <- ifelse(motors$cens == "yes", 9000, NA)
motors$temp <- factor(motors$temp, levels = rev(c("150","170","190","220")))

p <- ggplot(motors, aes(x = time, y = obs))
p <- p + xlim(0, 9000)
p <- p + geom_segment(aes(x = time, xend = xend, y = obs, yend = obs),
                      arrow = arrow(length = unit(0.1, "cm")))
p <- p + geom_point(aes(fill = cens), shape = 21)
p <- p + scale_fill_manual(name = "Censored?", values = c("white","black"))
p <- p + xlab("Time Till Failure (Hours)") + ylab("Observation")
p <- p + facet_grid(temp ~ ., scales = "free", space = "free")
p <- p + theme_minimal() + theme(axis.text.y = element_text(size = rel(0.65)))
p <- p + theme(legend.position = "bottom")
plot(p)
```

## Approaches to Modeling of Survival Data

Most regression models for *continuous* survival time can be classified as follows.

1. *Parametric models*. A specific distribution is assumed/specified for $T_i$. One or more parameters of the distribution can then be a function of one or more explanatory variables. Examples include *accelerated failure time models*, *parametric proportional hazards models*, and *parametric proportional odds models*.

2. *Semi-parametric models*. A specific distribution is not assumed/specified for $T_i$, but certain relationships between the properties of the distribution and one or more explanatory variables are assumed. Examples include *semi-parametric (Cox) proportional hazards models*, and *semi-parametric proportional odds models*.

3. *Non-parametric methods*. No or negligible assumptions, but largely limited to categorical explanatory variables.

We will also discuss *discrete* survival models where time is either divided into consecutive intervals of time, or we are modeling progression through discrete stages.

## Accelerated Failure Time (AFT) Model

An accelerated failure time model can be written as
$$
	\log T_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik} + \sigma\epsilon_i,
$$
where $\sigma$ is a *scale* parameter that determines the variability of $\log T_i$. This can also be written as
$$
	T_i = e^{\beta_0}e^{\beta_1x_{i1}}e^{\beta_2x_{i2}} \cdots e^{\beta_kx_{ik}}e^{\sigma\epsilon_i}.
$$
To complete the model specification we assume a distribution for $T_i$ (which implies a distribution for $\epsilon_i$), or a distribution for $\epsilon_i$ (which implies a distribution for $T_i$). 

Note that a AFT is essentially a *linear* model where the response variable is $Y_i = \log T_i$ is a transformation of $T_i$. This is **not** the same as a GLM using a log link function. That would be 
$$
  \log E(T_i) = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik}.
$$
However in practice the two kinds of models can produce similar results.

**Example**: Consider the following data on survival time after administration of ascorbate.
```{r}
library(Stat2Data)
data(CancerSurvival)
p <- ggplot(CancerSurvival, aes(x = Organ, y = Survival)) + 
  geom_boxplot(outlier.shape = NA) + 
  geom_jitter(width = 0.25, height = 0) +
  ylab("Survival Time (Days)") + 
  theme_classic()
plot(p)
```
Suppose we assume that $\log T_i$ has a *normal* distribution. Then we can estimate an AFT as follows.
```{r}
m <- lm(log(Survival) ~ Organ, data = CancerSurvival)
summary(m)
```
Here the `residual standard error` is the estimate of $\sigma$, computed as 
$$
  \hat\sigma = \sqrt{\frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n-k-1}},
$$
where $\hat{y}_i = \hat\beta_0 + \hat\beta_1x_{i1} + \cdots + \hat\beta_kx_{ik}$. 

Other functions for estimating an AFT model are `survreg` from the **survival** package and `flexsurvreg` from the **flexsurv** package. In both cases the distribution of $T_i$ is specified as *log-normal* (a random variable $Y_i$ has a log-normal distribution if its logarithm has a normal distribution). 
```{r}
library(survival) 
m <- survreg(Surv(Survival) ~ Organ, dist = "lognormal", data = CancerSurvival)
summary(m)
confint(m)
```
Note the use of the function `Surv` to define the response variable. This is necessary to communicate any censoring to the function (although here there is no censoring). Note also that the `Scale` is the estimate of scale parameter $\sigma$. The reason why it is different from what was obtained form `lm` is that it is a maximum likelihood estimate computed as
$$
  \hat\sigma = \sqrt{\frac{\sum_{i=1}^n (y_i - \hat{y}_i)^2}{n}}.
$$
Using `flexsurvreg` produces comparable results. 
```{r}
library(flexsurv)
m <- flexsurvreg(Surv(Survival) ~ Organ, dist = "lognormal", data = CancerSurvival)
print(m) # summary behaves differently for flexsurvreg objects --- use print instead
```
Here `sdlog` corresponds to the scale parameter $\sigma$, and `meanlog` corresponds to $\beta_0$. The `est` column gives the estimates of $\beta_1, \beta_2, \dots, \beta_k$. The `se` column is the standard error of each estimator, and the first set of columns `L95%` and `U95%` give the confidence interval of each parameter.

Note that we can obtain the same estimates (although slightly different standard errors) using a linear model for $\log T_i$.

## Interpretation of Model Parameters in AFT Models

Recall that with an AFT model we can write time-till-event as
$$
  T = e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_k} e^{\sigma \epsilon}. 
$$
We can interpret parameters and linear combinations thereof by applying the exponential function in much the same way as we do with a GLM that has a log link function.

### Quantitative Explanatory Variable

Let 
$$
  T_b = e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_k} e^{\sigma \epsilon}
$$
be time-till-event at given values of the explanatory variables. If we increase $x_1$ by one unit to $x_1 + 1$ then we get
$$
	T_a = e^{\beta_0} e^{\beta_1 (x_{1}+1)} e^{\beta_2 x_{2}} \cdots e^{\beta_p x_{p}} 
	e^{\sigma \epsilon}	 = e^{\beta_1}\underbrace{e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_p x_{p}} e^{\sigma \epsilon}}_{T_b},
$$
so $T_a/T_b = e^{\beta_1}$ and $T_a = e^{\beta_1}T_b$.  

1. If $\beta_1 < 0$ then $e^{\beta_1} < 1$ and increasing $x_1$ will "compress" time-till-event (i.e., "accelerate the passage through time") by a factor of $e^{\beta_1}$. We could also say that increasing $x_1$ by one unit reduces time-till-event by a factor of $e^{\beta_1}$, or by $(1 - e^{\beta_1}) \times 100\%$. 

0. If $\beta_1 > 0$ then $e^{\beta_1} > 1$ and increasing $x_1$ will "stretch" time-till-event (i.e., "decelerate the passage through time") by a factor of $e^{\beta_1}$. We could also say that increasing $x_1$ by one unit increases time-till-event by a factor of $e^{\beta_1}$, or by $(e^{\beta_1} - 1) \times 100\%$. 
Also note that 
$$
    E(T_b) = e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_k} E(e^{\sigma \epsilon}),
$$
and
$$
	E(T_a) = e^{\beta_0} e^{\beta_1 (x_{1} +1)} e^{\beta_2 x_{2}} \cdots e^{\beta_p x_{p}} 
	E(e^{\sigma \epsilon}) = e^{\beta_1}\underbrace{e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_p x_{p}} E(e^{\sigma \epsilon})}_{E(T_b)},
$$
so we can interpret $e^{\beta_1}$ in the same way that we do for GLMs with a log link function in terms of what happens to the expected time-till-event. 

**Example**: Consider the following data from a study of the longevity of male fruit flies in five experimental conditions. 
```{r, message = FALSE}
library(faraway)
p <- ggplot(fruitfly, aes(x = thorax, y = longevity)) + 
  geom_point() + facet_wrap(~ activity, ncol = 5) + 
  labs(x = "Thorax Length (mm)", y = "Longevity (days)") +
  theme_minimal()
plot(p)
m <- survreg(Surv(longevity) ~ activity + thorax, dist = "lognormal", data = fruitfly)
summary(m)$table
exp(cbind(coef(m), confint(m)))
```
```{r}
m <- flexsurvreg(Surv(longevity) ~ activity + thorax, dist = "lognormal", data = fruitfly)
print(m)
```
A 1mm increase in thorax length is *huge*. How about a 0.1 mm increase in thorax length? We can do this by changing the units to *tenths of a mm*. One mm is ten tenths of a mm so multiplying length by 10 will put the units into tenths of a mm.
```{r}
m <- flexsurvreg(Surv(longevity) ~ activity + I(thorax*10), dist = "lognormal", data = fruitfly)
print(m)
```

**Example**: Consider a AFT for the `motors` data.
```{r, message = FALSE, echo = 2:4}
rm(motors)
m <- survreg(Surv(time, cens) ~ temp, dist = "lognormal", data = motors)
summary(m)$table
exp(cbind(coef(m), confint(m)))
```
Note: We will discuss the specification of the censoring in the next lecture.

### Categorical Explanatory Variable

Suppose that $x_1$ is an indicator variable such that $x_1 = 1$ at a level $a$, and $x_1 = 0$ at the *reference level* $b$. Then we have that
$$
T_a = e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} e^{\sigma \epsilon} \ \ \ \text{and} \ \ \ T_b = e^{\beta_0} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} e^{\sigma \epsilon},
$$
noting that if $x_1 = 1$ then $e^{\beta_1 x_1} = e^{\beta_1}$ and if $x_1 = 0$ then $e^{\beta_1 x_1} = 1$. So 
$$
  \frac{T_a}{T_b} = \frac{e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} e^{\sigma \epsilon}}{e^{\beta_0} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} e^{\sigma \epsilon}} = e^{\beta_1}. 
$$
Similarly, $T_b/T_a = 1/e^{\beta_1} = e^{-\beta_1}$.

1. If $\beta_1 < 0$ then $e^{\beta_1} < 1$ and so the time-till-event at level $a$ is "compressed" (accelerated) relative to that at level $b$ by a factor of $e^{\beta_1}$ (i.e., progression to the event is *faster* at level $a$ than at level $b$ by a factor of $e^{\beta}_1$). We could also say that time-till-event at level $a$ is $(1-e^{\beta_1}) \times 100\%$ that of time-till-event at level $b$, or that time-till-event at level $b$ is $(e^{\beta}_1-1) \times 100\%$ that of time-till-event at level $a$. 

0. If $\beta_1 > 0$ then $e^{\beta_1} > 1$ and so the time-till-event at level $a$ is "stretched" (decelerated) relative to that at level $b$ by a factor of $e^{\beta_1}$ (i.e., progression to the event is *slower* at level $a$ than at level $b$ by a factor of $e^{\beta_1}$). We could also say that time-till-event at level $a$ is $(e^{\beta_1}-1) \times 100\%$ that of time-till-event at level $b$, or that time-till-event at level $b$ is $(1-e^{\beta}_1) \times 100\%$ that of time-till-event at level $a$. 

Furthermore, we can interpret $e^{\beta_1}$ in terms of expected values. We have that
$$
E(T_a) = e^{\beta_0} e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} E(e^{\sigma \epsilon}) \ \ \ \text{and} \ \ \ E(T_b) = e^{\beta_0} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} E(e^{\sigma \epsilon}),
$$
so 
$$
    \frac{E(T_b)}{E(T_a)} = \frac{e^{\beta_0}e^{\beta_1 x_{1}} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} E(e^{\sigma \epsilon})}{e^{\beta_0} e^{\beta_2 x_{2}} \cdots e^{\beta_k x_{k}} E(e^{\sigma \epsilon})} = e^{\beta_1}.
$$
Again, the interpretation is like that for GLMs with the log link function.

**Example**: Consider a model for some fictional lifespan data.
```{r, message = FALSE}
library(trtools)
head(lifespan)
p <- ggplot(lifespan, aes(x = years)) + facet_wrap(~ species)
p <- p + geom_histogram(boundary = 0, binwidth = 5, color = "black", fill = "white")
p <- p + labs(x = "Years", y = "Frequency") + theme_minimal()
plot(p)
m <- survreg(Surv(years) ~ species, dist = "lognormal", data = lifespan)
summary(m)$table
exp(cbind(coef(m), confint(m)))
lifespan$species <- relevel(lifespan$species, ref = "human")
m <- survreg(Surv(years) ~ species, dist = "lognormal", data = lifespan)
summary(m)$table
exp(cbind(coef(m), confint(m)))
```
For *categorical* explanatory variables (i.e., factors) we can use the **emmeans** package to obtain inferences concerning effects on time (but only for models estimated using `survreg`). 
```{r}
library(emmeans)
pairs(emmeans(m, ~species), type = "response", infer = c(TRUE,TRUE))
pairs(emmeans(m, ~species), type = "response", reverse = TRUE, infer = c(TRUE,TRUE))
```
Here we can compare the treatment conditions of the fruit fly experiment.
```{r}
m <- survreg(Surv(longevity) ~ activity + thorax, dist = "lognormal", data = fruitfly)
pairs(emmeans(m, ~activity, at = list(thorax = 0.8)), 
  type = "response", adjust = "none", infer = c(TRUE,TRUE))
pairs(emmeans(m, ~activity, at = list(thorax = 0.8)),
  type = "response", adjust = "none", reverse = TRUE, infer = c(TRUE,TRUE))
```
Note that since there is no interaction between activity and thorax the value of thorax that we use does not matter. 

Suppose there was an interaction between thorax length (in 0.1 mm units) and the treatment condition.
```{r}
m <- survreg(Surv(longevity) ~ activity * I(thorax*10), dist = "lognormal", data = fruitfly)
summary(m)$table
```
Here is how we can estimate this effect using the **emmeans** package.
```{r}
m <- survreg(Surv(longevity) ~ activity * thorax, dist = "lognormal", data = fruitfly)
pairs(emmeans(m, ~thorax|activity, at = list(thorax = c(0.5,0.4)), 
  type = "response"), infer = TRUE)
```
Unfortunately the **emmeans** package function cannot be used with a `flexsurvreg` object, but we can get the effects of thorax length through clever re-parameterization.
```{r}
m <- flexsurvreg(Surv(longevity) ~ activity + activity:I(thorax*10),
   dist = "lognormal", data = fruitfly)
print(m)
```


